<?xml version="1.0" encoding="utf-8"?>
<search> 
  
    
    <entry>
      <title>Feature Cross</title>
      <link href="/2018/12/02/Feature%20Cross/"/>
      <url>/2018/12/02/Feature%20Cross/</url>
      <content type="html"><![CDATA[<p>Feature cross is dot-product of two or more features. It transform linear features to non-linear features.</p><p>A <strong>feature cross</strong> is a synthetic feature that encodes nonlinearity in the feature space by multiplying two or more input features together.</p><p>$$<br>x_3 = x_1x_2<br>$$<br>where \(x_3\) is a new feature and it is fed to the classifier as a feature.</p><p>$$<br>y = b + w_1x_1 + w_2x_2 + w_3x_3<br>$$</p><p>Feature cross introduces non-linearity as well as richer features.</p><p>Feature crossing is usually employed in categorical features rather than continuous features.</p><p>Deep Cross Network models features cross as matrix multiplication. In the context of deep learning, sparse features are transformed to embeddings. Therefore dot-product of embeddings is actually a kind of feature crossing. It resembles SVM that apply a kernel to the original features. The original features are sparse features and the kernel is a look-up table. After that, sparse features are transformed to dense features.</p><p>Deep cross also utilizes residual connection because it adds \(x_l\) after feature crossing. And multiple layers of feature crossing is able to model higher level of feature crossing like \([x_1,x_2……x_n]\).</p><p>Detailed introduction of DCN is in Recommendation System.</p>]]></content>
      
      
    </entry>
    
    <entry>
      <title>Share_meeting</title>
      <link href="/2018/11/26/share_meeting/"/>
      <url>/2018/11/26/share_meeting/</url>
      <content type="html"><![CDATA[<p>MEMM</p><p>CRF考虑全局信息而不是局部标记，但是计算量比较大，参数多，不容易部署</p>]]></content>
      
      
    </entry>
    
    <entry>
      <title>Multi-task Learning(MTL)</title>
      <link href="/2018/11/25/Multi-task%20Learning/"/>
      <url>/2018/11/25/Multi-task%20Learning/</url>
      <content type="html"><![CDATA[<p>In normal machine learning or deep learning task, we optimize a specific metric, which loses information from other tasks that may be desirable to improve the original task. This kind of information comes from related tasks. And this kind of shared representations may be helpful to our original task because it actually utilise much more data than the original task.</p><p>Generally, as soon as you find yourself optimizing more than one loss function, you are effectively doing multi-task learning (in contrast to single-task learning). In those scenarios, it helps to think about what you are trying to do explicitly in terms of MTL and to draw insights from it.</p><p>“MTL improves generalization by leveraging the domain-specific information contained in the training signals of related tasks”.</p><p><strong>Inductive Bias</strong><br>A model prefer some hypotheses over others. For instance, a common form of inductive bias is l1 regularization, which leads to a preference for sparse solutions.</p><p>In the case of MTL, the inductive bias is introduced by other auxiliary tasks, which leads the model to prefer hypotheses that explain more than one task. This in general leads to better generalization ability.</p><h2 id="Hard-parameter-sharing-Multi-output"><a href="#Hard-parameter-sharing-Multi-output" class="headerlink" title="Hard parameter sharing(Multi-output)"></a>Hard parameter sharing(Multi-output)</h2><p>Multiple tasks share the same hidden layers. Each task has its own output. The risk of overfitting the shared parameters is an order N – where N is the number of tasks – smaller than overfitting the task-specific parameters.</p><h2 id="Soft-parameter-sharing"><a href="#Soft-parameter-sharing" class="headerlink" title="Soft parameter sharing"></a>Soft parameter sharing</h2><p>Each task has its own model, parameters and output. There are constraints between parameters such that the parameters are similar. A sample constraint is L2 distance between parameters.</p><h3 id="Advantages-of-MTL"><a href="#Advantages-of-MTL" class="headerlink" title="Advantages of MTL"></a>Advantages of MTL</h3><ol><li>Data Augmentation. Training multiple tasks together enables the model to employ more data in training.</li><li>Data are noisy. MTL is able to regularize the model to learn efficient and effective representations that are desirable for multiple tasks.</li><li>Eavesdropping. The model might be easier to learn some specific features from some specific dataset. MTL is able to help the model to learn easier from different tasks or dataset.</li><li>Representation bias. MTL biases the model to prefer representations that other tasks also prefer. This will also help the model to generalize to new tasks as a hypothesis space that performs well for many tasks will also perform well for learning novel tasks as long as they are from the same environment</li><li>Regularization. MTL acts as a regularizer by introducing an inductive bias. As such, it reduces the risk of overfitting as well as the Rademacher complexity of the model</li></ol><h3 id="Technique-to-do-MTL"><a href="#Technique-to-do-MTL" class="headerlink" title="Technique to do MTL"></a>Technique to do MTL</h3><ol><li>Block-sparse regularization. For related tasks, use regularization like L1 or other modified regularization to enforce the model learn sparse features which would be utilised to do inference for multiple tasks.</li><li>Learn the relationships between tasks: clustering, KNN, Bayesian methods.</li></ol><p>In MTL for computer vision, approaches often share the convolutional layers, while learning task- specific fully-connected layers. Deep Relationship Networks add matrix priors on the fully connected layers.</p><h3 id="Auxiliary-tasks"><a href="#Auxiliary-tasks" class="headerlink" title="Auxiliary tasks"></a>Auxiliary tasks</h3><p>Use Auxiliary tasks so that to achieve better result on the main task.</p><ol><li>Related task</li><li>Adversarial task. Maximize the training error using a gradient reversal layer</li><li>Hints. Predicting features as an Hints as an auxiliary task. MTL could be used to learn features that are not easy to learn. </li><li>Predicting inputs. In some cases, some inputs might not be useful for the task but they might be able to guide the learning. Use them as output might help the task.</li><li>Representation learning. employing a task that is known to enable a model to learn transferable representations(language modeling)</li></ol><p>There are many definitions about related tasks.</p><ol><li>use the same features to make a decision</li><li>related tasks share a common optimal hypothesis class</li></ol><h1 id="Core-of-MTL-what-to-share-All-parameters"><a href="#Core-of-MTL-what-to-share-All-parameters" class="headerlink" title="Core of MTL: what to share? All parameters?"></a>Core of MTL: what to share? All parameters?</h1><p>In conclusion, hard parameters sharing is still pervasive for neural-network based MTL. Recent advances on learning what to share, however, are promising. At the same time, our understanding of tasks – their similarity, relationship, hierarchy, and benefit for MTL – is still limited</p>]]></content>
      
      
        <tags>
            
            <tag> DL </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>git</title>
      <link href="/2018/11/23/git/"/>
      <url>/2018/11/23/git/</url>
      <content type="html"><![CDATA[<p>git checkout <branch>swtich to a branch.</branch></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git add .</span><br></pre></td></tr></table></figure><p>add all to buffer</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git commit -m “comment”</span><br></pre></td></tr></table></figure><p> commit the change and add comment</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git push origin &lt;local_branch&gt;:&lt;remote_branch&gt;</span><br></pre></td></tr></table></figure><p> push local branch to remote branch.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git pull</span><br></pre></td></tr></table></figure><p>update files from remote</p>]]></content>
      
      
    </entry>
    
    <entry>
      <title>seq2seq_tensorflow</title>
      <link href="/2018/11/23/seq2seq_tensorflow/"/>
      <url>/2018/11/23/seq2seq_tensorflow/</url>
      <content type="html"><![CDATA[<p>attention machanism is just an attention wrapper to wrap the RNN.</p><p>Dropout is also a wrapper to wrap RNN. During training, keep_prob = p. During testing and predict, keep_prob = 1, No dropout.</p><p>The output of RNN has to be fed to a fully-connected neural network to convert the final hidden states to scores of the vocabulary. After that, employ a softmax function to squeeze all scores in a probability distribution.</p><p>Process of constructing seq2seq model in tensorflow:</p><ol><li>define hyperparameters. Settings of hyperparameters could be loaded from config file or parsed from command line. Both parser and tf.app.flags could be used to parse.</li><li>preprocessing data. Like batching, padding and so on.</li><li>construct model. build encoder, decoder and combine them together.</li><li>write a train wrapper funtion to wrap the training process.</li><li>feed data to model and perform training</li><li>perform validation and testing</li></ol><p>Loss of seq2seq: at each step, there is only one correct token given a sentence. At each time step, use softmax to calculate the loss and optimize the sum of total loss at all time steps.</p><p>Given a sentence, each time step t, there is a loss \(l_t\). The total loss \(L=\sum_0^T l_i\) where T is the number of tokens in the sentence. The optimizer is actually optimize this loss.</p><p>The seq2seq could be regarded as a latent structure like auto-encoder because all information of the whole sentence is encoded in the final hidden state.</p><p>Latent variable: 隐藏变量</p><p>To do:</p><ol><li>write an iterator</li><li></li></ol><p>For regression(time series data prediction) problem, just add a scaling factor with a fully-connected layer.</p><p>The decoder could use the last encoder hidden state or zero or encoder input[:-1] as initial state. </p><p>The RNN decoder outputs tensor with same shape as the input. </p><p>The input is batched tensor, and RNN encoder takes sequence as input. Sequence is a list of tensor with shape [batch_size, dim]. The length of the sequence is the time step.</p><p>When you use Dataset to train the model, during inference, there are several ways to feed the data:</p><ol><li>use dataset and feed label with idiot values</li><li>create two meta graph with different input, and inference graph load parameters from the other.</li><li>extract the input feature and feed with inference input.</li></ol>]]></content>
      
      
    </entry>
    
    <entry>
      <title>tensorflow_1</title>
      <link href="/2018/11/16/tensorflow-1/"/>
      <url>/2018/11/16/tensorflow-1/</url>
      <content type="html"><![CDATA[<p> tf.feature_column.bucketized_column divides coutinuous values into several ranges such that they are able to be represented as categorical features.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.feature_column.categorical_column_with_vocabulary_file(    key,    vocabulary_file,    vocabulary_size=None,    num_oov_buckets=0,    default_value=None,    dtype=tf.string)</span><br></pre></td></tr></table></figure><p>maps each word in the vocabulary to an one-hot vector.</p><p>tf.feature_column.categorical_column_with_hash_bucket maps features to specified number of features using hash(for example, mapping 1000 words to 100 embeddings means some words would share the same embedding.). In machine learning, this kind of hash often works well in practice. That’s because hash categories provide the model with some separation. The model can use additional features to further separate kitchenware from sports.</p><p>tf.feature_column.crossed_column is able to combine features together. Somewhat counterintuitively, when creating feature crosses, you typically still should include the original (uncrossed) features in your model (as in the preceding code snippet). The independent latitude and longitude features help the model distinguish between examples where a hash collision has occurred in the crossed feature.</p><p>As a rule of thumb,<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">embedding_dimensions =  number_of_categories**0.25</span><br></pre></td></tr></table></figure></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">categorical_column = ... <span class="comment"># Create any categorical column</span></span><br><span class="line"><span class="comment"># Represent the categorical column as an embedding column.</span></span><br><span class="line"><span class="comment"># This means creating an embedding vector lookup table with one element for each category.</span></span><br><span class="line">embedding_column = tf.feature_column.embedding_column(    categorical_column=categorical_column,    dimension=embedding_dimensions)</span><br></pre></td></tr></table></figure><p>tf.train.Features is used to wrap features of input.</p><p><strong>tf.train.Example(features=features)</strong> is used to wrap examples.</p><p>using TFRecord is more efficient. A parse function is used to parse a single example.</p><h3 id="RNN"><a href="#RNN" class="headerlink" title="RNN"></a>RNN</h3><p>Most software could only process up to 120 tokens. Longer sequences are supposed to be truncated.</p><p><strong>The padded labels change the total loss, which affects the gradients</strong>.<br>Two methods to alleviate this problem:</p><ol><li>Maintain a mask</li></ol><ul><li><p>Maintain a mask (True for real, False for padded tokens)</p></li><li><p>Run your model on both the real/padded tokens (model will predict labels for the padded tokens as well)</p></li><li><p>Only take into account the loss caused by the real elements</p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">full_loss = tf.nn.softmax_cross_entropy_with_logits(preds, labels)</span><br><span class="line">loss = tf.reduce_mean(tf.boolean_mask(full_loss, mask))</span><br></pre></td></tr></table></figure><ol start="2"><li>Let your model know the real sequence length so it only predict the labels for the real tokens.<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">cell = tf.nn.rnn_cell.GRUCell(hidden_size)</span><br><span class="line"></span><br><span class="line">rnn_cells = tf.nn.rnn_cell.MultiRNNCell([cell] * num_layers)</span><br><span class="line"></span><br><span class="line">tf.reduce_sum(tf.reduce_max(tf.sign(seq), <span class="number">2</span>), <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">output, out_state = tf.nn.dynamic_rnn(cell, seq, length, initial_state)</span><br></pre></td></tr></table></figure></li></ol><p>tensorflow seq2seq resembles caffe that use a file or string to define model parameters and perform training/inference.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.contrib.rnn.MultiRNNCell(    [lstm_cell() for _ in range(number_of_layers)])</span><br></pre></td></tr></table></figure><p>is a RNN cell with a number of layers. In pytorch, you only need to input the number of layers.</p><p>Sample code using tf.name_scope and tf.variable_scope.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">"Train"</span>):</span><br><span class="line">      train_input = PTBInput(config=config, data=train_data, name=<span class="string">"TrainInput"</span>)</span><br><span class="line">      <span class="keyword">with</span> tf.variable_scope(<span class="string">"Model"</span>, reuse=<span class="keyword">None</span>, initializer=initializer):</span><br><span class="line">        m = PTBModel(is_training=<span class="keyword">True</span>, config=config, input_=train_input)</span><br><span class="line">      tf.summary.scalar(<span class="string">"Training Loss"</span>, m.cost)</span><br><span class="line">      tf.summary.scalar(<span class="string">"Learning Rate"</span>, m.lr)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> tf.name_scope(<span class="string">"Valid"</span>):</span><br><span class="line">      valid_input = PTBInput(config=config, data=valid_data, name=<span class="string">"ValidInput"</span>)</span><br><span class="line">      <span class="keyword">with</span> tf.variable_scope(<span class="string">"Model"</span>, reuse=<span class="keyword">True</span>, initializer=initializer):</span><br><span class="line">        mvalid = PTBModel(is_training=<span class="keyword">False</span>, config=config, input_=valid_input)</span><br><span class="line">      tf.summary.scalar(<span class="string">"Validation Loss"</span>, mvalid.cost)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> tf.name_scope(<span class="string">"Test"</span>):</span><br><span class="line">      test_input = PTBInput(</span><br><span class="line">          config=eval_config, data=test_data, name=<span class="string">"TestInput"</span>)</span><br><span class="line">      <span class="keyword">with</span> tf.variable_scope(<span class="string">"Model"</span>, reuse=<span class="keyword">True</span>, initializer=initializer):</span><br><span class="line">        mtest = PTBModel(is_training=<span class="keyword">False</span>, config=eval_config,</span><br><span class="line">                         input_=test_input)</span><br></pre></td></tr></table></figure></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.variable_scope(name, reuse=<span class="keyword">None</span>, initializer=initializer, reuse=tf.AUTO_REUSE):</span><br><span class="line">  <span class="keyword">pass</span></span><br></pre></td></tr></table></figure><p>The above code enable reusing of variables such that subgraphs would not be constructed.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.identity(    input,    name=None)</span><br></pre></td></tr></table></figure><p>return a tensor that is identical with input tensor.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.placeholder_with_default(    input,    shape,    name=None)</span><br></pre></td></tr></table></figure><p>If there is no value fed to placeholder, the placeholder would take input value as input. The input is actually a default value.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.math.sign(    x,    name=None)</span><br></pre></td></tr></table></figure><p>return a tensor to indicate whether x is greater than 0 or not.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.math.reduce_max(    input_tensor,    axis=None,    keepdims=None,    name=None,    reduction_indices=None,    keep_dims=None)</span><br></pre></td></tr></table></figure><p>Computes the maximum of elements across dimensions of a tensor. </p><p>Attention mechanism in tensorflow is to use an attention_wrapper to wrap the RNNcell.</p><p>tf.layers.dense() apply a fully connected layer to given inputs and return result.<br>tf.layers.Dense() return an abstract layer.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.tile(    input,    multiples,    name=None)</span><br></pre></td></tr></table></figure><p>create a tensor that repeats input multiples times. The multiples argument has to specify how many times you want to repeat for each dimension.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.concat()</span><br></pre></td></tr></table></figure><p>shape 0 of tensors must be equal.</p><p>[<code>tf.nn.dynamic_rnn</code>] is used for sequence with unknown length.</p>]]></content>
      
      
    </entry>
    
    <entry>
      <title>Recommendation_System</title>
      <link href="/2018/11/16/Recommendation-System-1/"/>
      <url>/2018/11/16/Recommendation-System-1/</url>
      <content type="html"><![CDATA[<p><strong>CTR</strong>(<strong>Click-Through-Rate</strong>).</p><p>Recommendation system could be regarded as a search-ranking problem. First the system retrives a list of candidate items according to the a query. Second the system ranks the candidate items and return some items with high scores.</p><p><strong>Memorization</strong> is loosely defined as recommeding according to co-occurence of items or features. It could recommend items directly(some one buy a medical app after a sport app, then recommend a medical app if someone buy a sport app) or with data mining of those co-occurence(some one with features \(x_m\)buy a medical app after a sport app, then only recommend a medical app to an user who bought a sport app if his/her user profile matches \(x_m\)).</p><p><strong>Generalization</strong> is loosely defined as discovering of underlying features from existing co-occurence so that new feature combinations could be inferred from existing co-occurence.</p><p>data for Web-scale recommender systems is mostly <strong>discrete and categorical</strong>, leading to a large and sparse feature space that is challenging for feature exploration. For continuous data, a common method is to divide the continuous range into several continuous range such that one-hot vector could be employed to represent a range.</p><h4 id="AUC"><a href="#AUC" class="headerlink" title="AUC"></a>AUC</h4><p>AUC - ROC curve is a performance measurement for classification problem at various thresholds settings. ROC is a probability curve and AUC represents degree or measure of separability. It tells how much model is capable of distinguishing between classes. Higher the AUC, better the model is at predicting 0s as 0s and 1s as 1s. By analogy, Higher the AUC, better the model is at distinguishing between patients with disease and no disease.</p><h2 id="Wide-amp-Deep"><a href="#Wide-amp-Deep" class="headerlink" title="Wide&amp;Deep"></a>Wide&amp;Deep</h2><p>Factorization machine and DNN requires no or less fiture engineering because it is able to learn dense and low-dimension embedding. But it would over-generate so that recommendation would be unrelevent. Wide refers to logistic regression. It is able to simply remember some rules. Wide&amp;Deep combines them together. </p><p>For wide part, features are transformed to one-hot sparse feature and fed to a linear transformation. </p><p>Feature transformation:<br>$$<br>\varnothing_k(x)=\prod^d_{i=1}x_i^{c_{ki}}<br>$$</p><p>Linear transformation:<br>$$<br>\mathbf{w}_{wide}^T[ \mathbf{x},\phi  ( \mathbf{x}  )]<br>$$<br>where \([ \mathbf{x},\phi  ( \mathbf{x}  )]\) is concatenation of original features and transformmed features.</p><p>At last, values of wide part and deep part are added together and fed to a sigmoid function to do binary classification. The result is in [0,1] which is the probability that the user would click the recommended item.<br>$$<br>P\left ( Y=1\mid \mathbf{x} \right )=\sigma \left ( \mathbf{w}<em>{wide}^T\left [ \mathbf{x},\phi \left ( \mathbf{x} \right ) \right ] + \mathbf{w}</em>{deep}^Ta^{\left ( l_f \right )}+b \right )<br>$$</p><h2 id="DeepFM"><a href="#DeepFM" class="headerlink" title="DeepFM"></a>DeepFM</h2><p>DeepFM substitutes the wide part in wide&amp;deep with <strong>Factorization Machines(FM)</strong>. It is able to model high-level feature combination by transforming the sparse feature to dense and low-dimension features. It models feature interaction as inner product of embeddings.</p><p>A feature \(x_i\) is associated with a weight vector(embedding) \(v_i\) and feature interaction or feature combination is computed as \(&lt;v_i,v_j&gt;\). Intuitively, in stead of computing feature combination directly, it insert an embedding layer to the network so as to convert features to embeddings. Compuing the dot product of embedding to model feature combination.</p><h2 id="DCN-Deep-Cross-Network"><a href="#DCN-Deep-Cross-Network" class="headerlink" title="DCN(Deep Cross Network)"></a>DCN(Deep Cross Network)</h2><p>The features are usually sparse, it is unable to represent those sparse features with one-hot vector if the size of vocabulary is huge. Therefore embedding layer is employed to convert sparse features to dense features which are real-value vectors like Natural Language Processing. After that, those vectors are stacked or concatenated with other dense features.</p><p>It also utilises matrix multiplication to implement feature combination.<br>$$<br>x_{l+1} = x_0 x_l^T w_l + b_l + x_l = f(x_l, w_l, b_l) + x_l<br>$$</p><p>where \(x_0\) is the concatenation of embedding features and dense features. \(f(x_l, w_l, b_l)\) is the feature cross between feature \(x_l\) and the original feature \(x_0\). After feature cross, the layer feature \(x_l\) is added to the next layer feature so that the feature cross \(f(x_l, w_l, b_l)\) is a kind of residual connection.</p><p>The degress of cross features is growing with the number of layers.</p><p>At last, outputs of the deep network and the cross network are also concatenated together and fed to the logistic regression.</p>]]></content>
      
      
    </entry>
    
    <entry>
      <title>SVM_2</title>
      <link href="/2018/10/09/SVM-2/"/>
      <url>/2018/10/09/SVM-2/</url>
      <content type="html"><![CDATA[<p>$$margin={1\over \left|{\boldsymbol {w}}\right|} = \sqrt{w_1^2+w_2^2+…+w_n^2}=\left|{\boldsymbol {w}}\right|_{2}$$</p><p>optimal hyperplane:</p><p>$$sign(w_1x_1+w_2x_2+…+w_nx_n+b)=sign(\boldsymbol {w}^Tx)$$</p><h2 id="Quadratic-Programming"><a href="#Quadratic-Programming" class="headerlink" title="Quadratic Programming"></a>Quadratic Programming</h2><p>minimize a (convex) quadratic function, subject to linear inequality constraints.</p>]]></content>
      
      
    </entry>
    
    <entry>
      <title>Hyper_Para_Search</title>
      <link href="/2018/10/05/Hyper-Para-Search/"/>
      <url>/2018/10/05/Hyper-Para-Search/</url>
      <content type="html"><![CDATA[<h1 id="Hyper-parameters-Searching"><a href="#Hyper-parameters-Searching" class="headerlink" title="Hyper-parameters Searching"></a>Hyper-parameters Searching</h1><h2 id="Random-Search"><a href="#Random-Search" class="headerlink" title="Random Search"></a>Random Search</h2><p>It is heavily used in deep learning. There are tons of parameters in deep learning. Grid search is computation-intensive because it tunes parameters one by one which change only a parameter and keep the others unchanged. Each time for each parameter, random search samples a value from normal distribution. It is always the case that some parameters like leanring rate are more important than other parameters. Random search could discover a pretty good setting of hyperparameters.</p><p>For example, let’s assume there are only 3 parameters. The algorithm has been run for 9 times both random search and grid search. For random search, each parameter has been tested for 9 times. For grid search, each parameter has been tested for only 3 times because it keep the other two parameters unchanged when tuning a parameter.</p><p>Advantages:<br>efficient</p><h2 id="Grid-Search"><a href="#Grid-Search" class="headerlink" title="Grid Search"></a>Grid Search</h2><p>Grid search is to generate a list of candidate parameters for each parameter. Each time only changes a parameter and keep other parameters invariant. It is systematic but it is only appropriate for low dimension. When the dimension increase, the computation would also increase dramatically. It would waste computation resource because each time only a parameter is changed.</p><p>Advantages:<br>Systematic.<br>Precise.</p><h2 id="Bayes-Optimization"><a href="#Bayes-Optimization" class="headerlink" title="Bayes Optimization"></a>Bayes Optimization</h2><p>The third one is Bayes Optimization. Bayes optimization is powerful but it is not widely employed because it is application-specific. There is not a good software to facilitate the coding process until now. Its general idea is to do some experiments on a few settings of parameters. After that choose the setting that has high variance to evaluate so as to achieve better performance. High variance means that the parameters has the potential to be better or worse. If the performance is degraded, it doesn’t matter. It resemble the greedy algorithm to some extend. </p><p>This method assumes that the similar inputs gives similar outputs. It’s a kind of weak prior. Its intuition is that to evaluate those unknown but possibly better combinations of parameters rather than try all of them.</p><h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p><a href="https://mp.weixin.qq.com/s/l6uzHwGSTY5xRSkPD_B2rw" target="_blank" rel="noopener">深度学习模型超参数搜索实用指南</a></p>]]></content>
      
      
        <tags>
            
            <tag> DL </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Technical_Analysis</title>
      <link href="/2018/10/05/Technical-Analysis/"/>
      <url>/2018/10/05/Technical-Analysis/</url>
      <content type="html"><![CDATA[<p>Price-based:</p><p>Moving average lines are heavily used to smooth the short-term fluctuations in the price charts. It is regarded as a support line where the price would not go lower than it in an uptrend. Points where the longer-term moving average crosses below the short-term moving average reveals an emerging uptrend.</p><p>Bollinger bands are constructed from n standard deviation of closing prices. The high and low bands are the prices that moving average plus or minus n standard deviation. The prices in the area between the high and low bands are considered as resonable fluctuation of prices. If the price go beyond the area, it reveals overbought or oversold which means that the price is likely to decrease and increase respectively in the near future. It is the time where contrarian strategy comes into play. It is basically a strategy to buy or sell when most investors sell or buy.</p><p>Oscillators:</p><p>Oscillators are a set of indicators that oscillate around a specific value or in a range. Oscillator charts could be employed to detect convergence or divergence between oscillator and market prices. Convergence reveals that the current trend would continue and divergence suggests the change of the current trend.</p><p>Sample indicators:</p><p>Relative Strength Index(RSI): the rations of increase in price to decrease in price in a period of time. High values indicates overbought and low values suggest oversold.</p><p>Moving Average Convergence Divergence(MACD): It is constructed from two lines. The MACD line is the difference between two expoentially moving average lines while the signal line is the expoentially moving average of the MACD line. The MACD could be employed to show both convergence or divergence and overbought or oversold. A buy signal is gerated when the MACD line cross above the signal line.</p><p>Williams %R:<br>It indicates the relation between the closing price and the highest and lowest price in the previous days. It also reveals overbought or oversold.</p><p>Accumulation/Distribution Line(AD):<br>Calculated from Money Flow Multiplier and Money Flow Volume. It takes volume into consideration. Volume is a significant indicator in technical analysis. It basically measure the money flow of the underlying asset. A pending revesal trend is indicated when divergence occurs between price and AD. Bullish Crosses occur when AD crosses above zero.</p><p>Non-Price-Based Indicators<br>Put/call ratio</p><p>Volatility Index</p>]]></content>
      
      
    </entry>
    
    <entry>
      <title>BLEU</title>
      <link href="/2018/10/04/BLEU/"/>
      <url>/2018/10/04/BLEU/</url>
      <content type="html"><![CDATA[<h3 id="Bilingual-Evaluation-Understudy-BLEU"><a href="#Bilingual-Evaluation-Understudy-BLEU" class="headerlink" title="Bilingual Evaluation Understudy(BLEU)"></a>Bilingual Evaluation Understudy(BLEU)</h3><p>$$p_{n}=\frac{\sum_{c_{\in candidates}}\sum_{n-gram_{\in c}}Count_{clip}(n-gram)}{\sum_{c^{‘}<em>{\in candidates}}\sum</em>{n-gram^{‘}_{\in c^{‘}}}Count(n-gram^{‘})}$$</p><p>First count the n-gram match sentence by sentence. After that truncate the count which is to clip the count by maximum reference count. Finally add all the n-gram for all sentences together and divided by  all the n-gram for all reference sentences.</p><p>$$Count_{clip}=min(Count,Max_Ref_Count)$$</p><p>Max_Ref_Count is the largest count of a word in a single reference sentence.</p><p>The machine could cheat by output short sentences. So penalty has to be added for short sentence.</p><p>$$BP= \begin{cases}<br>1 &amp; \text{if c&gt;r}\<br>e^{1-r/c} &amp; {if}\  c \le r<br>\end{cases}$$</p><p>If the length of the output sentence c is greater than the length of the reference, no penalty.</p><p>The final version of BLEU:</p><p>$$BLEU=BP\cdot exp(\sum_{n=1}^N w_n logP_n)$$</p><p>BLEU computes the geometric average of the modified n-gram precisions and penalized short sentences. Usually N = 4 and the weight \(w_n=\frac{1}{N}\)</p>]]></content>
      
      
    </entry>
    
    <entry>
      <title>Evaluation_NLP</title>
      <link href="/2018/10/04/Evaluation-NLP/"/>
      <url>/2018/10/04/Evaluation-NLP/</url>
      <content type="html"><![CDATA[<h2 id="Automatic-Evaluation"><a href="#Automatic-Evaluation" class="headerlink" title="Automatic Evaluation:"></a>Automatic Evaluation:</h2><h3 id="Word-Error-Rate-WER"><a href="#Word-Error-Rate-WER" class="headerlink" title="Word Error Rate(WER)"></a>Word Error Rate(WER)</h3><p>It is the Levenshtein distance between output and reference divided by the length of the reference. Dynamic programming is employed to compute the Levenshtein distance so as to determine the best alignment between the output and the reference. </p><p>Deletion is a reference word aligned to nothing and insertion is a output word align to nothing. Substitution is word that dose not match the reference word.</p><p>WER is actually edit distance normalized by length.</p><p>$${\displaystyle {\mathit {WER}}={\frac {S+D+I}{N}}={\frac {S+D+I}{S+D+C}}}$$</p><h3 id="Position-independent-Error-Rate-PER"><a href="#Position-independent-Error-Rate-PER" class="headerlink" title="Position-independent Error Rate(PER)"></a>Position-independent Error Rate(PER)</h3><p>It treats the reference and the output as bag of words so that words could be alighed directly without alighment of two sentences. It is definitely smaller than or equal to WER.</p>]]></content>
      
      
        <tags>
            
            <tag> NLP </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>CNN_NLP</title>
      <link href="/2018/10/03/CNN-NLP/"/>
      <url>/2018/10/03/CNN-NLP/</url>
      <content type="html"><![CDATA[<p>CNN is good at capture semantic information in a contextual window due to local connectivity. It requires lots of data to train because it includes many parameters. Inability to model long-distance contextual information.</p>]]></content>
      
      
    </entry>
    
    <entry>
      <title>Math</title>
      <link href="/2018/10/01/Math/"/>
      <url>/2018/10/01/Math/</url>
      <content type="html"><![CDATA[<h2 id="Gamma-Function"><a href="#Gamma-Function" class="headerlink" title="Gamma Function"></a>Gamma Function</h2><p>the gamma function is an extension of the factorial function to real and complex numbers. </p><p>If n is a positive integer</p><p>$$\Gamma(n)=(n-1)!$$</p><p>For complex number z whose real part is greater than 0, the below integral, which is known as the Euler integral of the second kind, converges bsolutely. The gamma function is defined as:</p><p>$${\displaystyle \Gamma (z)=\int _{0}^{\infty }{\frac {t^{z-1}}{\mathrm {e} ^{t}}}\,{\rm {d}}t}$$</p><p>This integral function is extended by analytic continuation to all complex numbers except the non-positive integers (where the function has simple poles), yielding the meromorphic function we call the gamma function.</p><h4 id="Properties"><a href="#Properties" class="headerlink" title="Properties"></a>Properties</h4><p>$${\displaystyle \Gamma (x+1)=x\Gamma (x)}$$</p><p>Read part of complex number:<br>\({\displaystyle \Re (z)}\)</p><p>Imaginary part of complex number:<br>\({\displaystyle \Im (z)}\)</p><h2 id="Beta-Function"><a href="#Beta-Function" class="headerlink" title="Beta Function"></a>Beta Function</h2><p>Defined by the Euler integral of the first kind.</p><p>$${\displaystyle \mathrm {\mathrm {B} } (x,y)=\int _{0}^{1}t^{x-1}(1-t)^{y-1}\,dt!}$$</p><p>where \({\displaystyle {\textrm {Re}}(x),{\textrm {Re}}(y)&gt;0\,}\).</p><p>$${\displaystyle \mathrm {B} (x,y)={\dfrac {\Gamma (x)\,\Gamma (y)}{\Gamma (x+y)}}!}$$</p><p>when x,y are integers.</p><p>the beta distribution is a family of continuous probability distributions defined on the interval [0, 1] parametrized by two positive shape parameters, denoted by \(\alpha\) and \(\beta\), that appear as exponents of the random variable and control the shape of the distribution.</p><p>The beta distribution has been applied to model the behavior of random variables limited to intervals of finite length in a wide variety of disciplines.</p><p>In Bayesian inference, the beta distribution is the conjugate prior probability distribution for the Bernoulli, binomial, negative binomial and geometric distributions. For example, the beta distribution can be used in Bayesian analysis to describe initial knowledge concerning probability of success such as the probability that a space vehicle will successfully complete a specified mission. The beta distribution is a suitable model for the random behavior of percentages and proportions.</p><h2 id="Conjugate-prior-distribution"><a href="#Conjugate-prior-distribution" class="headerlink" title="Conjugate prior distribution"></a>Conjugate prior distribution</h2><p>If the posterior distributions \(p(\theta | x)\) are in the same probability distribution family as the prior probability distribution \(p(\theta)\), the prior and posterior are then called conjugate distributions, and the prior is called a conjugate prior for the likelihood function.</p><p>For example, the Gaussian family is conjugate to itself (or self-conjugate) with respect to a Gaussian likelihood function: if the likelihood function is Gaussian, choosing a Gaussian prior over the mean will ensure that the posterior distribution is also Gaussian. This means that the Gaussian distribution is a conjugate prior for the likelihood that is also Gaussian. </p><p>Advantage of Conjugate prior distribution:<br>A conjugate prior is an algebraic convenience, giving a closed-form expression for the posterior; otherwise numerical integration may be necessary. Further, conjugate priors may give intuition, by more transparently showing how a likelihood function updates a prior distribution.</p><p>The Dirichlet distribution of order k ≥ 2 with parameters \(\alpha_1, …, \alpha_K &gt; 0\) has a probability density function with respect to Lebesgue measure on the Euclidean space \(\mathbb {R}^{K−1}\) given by</p><p>$${\displaystyle f(x_{1},\dots ,x_{K};\alpha _{1},\dots ,\alpha _{K})={\frac {1}{\mathrm {B} (\alpha )}}\prod <em>{i=1}^{K}x</em>{i}^{\alpha _{i}-1}}$$</p><p>where \(\sum_k\theta_k=1 \) and \(\theta_k&gt;0\) or in other words, \({x_k}_{k=1}^{k=K}\) belong to the standard K-1 simplex.</p><h2 id="Euclidean-space"><a href="#Euclidean-space" class="headerlink" title="Euclidean space"></a>Euclidean space</h2><p>Euclidean space’s points are vectors of real numbers.</p><p>A Euclidean space is a real vector space on which is defined a fixed<br>symmetric bilinear form whose associated quadratic form is positive definite.</p><p>The vector space itself will be denoted as a rule by L, and the fixed symmetric<br>bilinear form will be denoted by (x, y). Such an expression is also called the inner<br>product of the vectors x and y. </p><p>A Euclidean space is a real vector space L in which to every pair of vectors x<br>and y there corresponds a real number (x, y) such that the following conditions are<br>satisfied:</p><p>\(\forall x1, x2, y ∈ L\)</p><p>(1) \((x_1 + x_2, y) = (x_1, y) + (x_2, y) \  .\)</p><p>(2) \((\alpha x, y) = \alpha(x, y) α\in \mathbb {R}.\)</p><p>(3) \((x, y) = (y, x)\)</p><p>(4) \((x, x) &gt; 0 \ \ \forall x = 0.\)</p><p>Properties (1)–(3) show that the function (x, y) is a symmetric bilinear form on<br>L, and in particular, that (0, y) = 0 for every vector \(y \in L\). It is only property (4) that expresses the specific character of a Euclidean space.</p><p>The expression (x, x) is frequently denoted by \((x^2)\); it is called the scalar square<br>of the vector x. Thus property (4) implies that the quadratic form corresponding to<br>the bilinear form (x, y) is positive definite.</p><h2 id="Simplex"><a href="#Simplex" class="headerlink" title="Simplex"></a>Simplex</h2><p>In geometry, a simplex is a generalization of the notion of a triangle or tetrahedron to arbitrary dimensions. Specifically, a k-simplex is a k-dimensional polytope which is the convex hull of its k + 1 vertices. More formally, suppose the k + 1 points \({\displaystyle u_{0},\dots ,u_{k}\in \mathbb {R} ^{k}}\)are affinely independent, which means \({\displaystyle u_{1}-u_{0},\dots ,u_{k}-u_{0}}\) u1−u0,…,uk−u0 are linearly independent. Then, the simplex determined by them is the set of points</p><p>$${\displaystyle C=\left{\theta <em>{0}u</em>{0}+\dots +\theta <em>{k}u</em>{k}~{\bigg |}~\sum _{i=0}^{k}\theta _{i}=1{\mbox{ and }}\theta _{i}\geq 0{\mbox{ for all }}i\right}.}$$</p><h2 id="Hilbert-space"><a href="#Hilbert-space" class="headerlink" title="Hilbert space"></a>Hilbert space</h2><p>A Hilbert space H is a real or complex inner product space that is also a complete metric space with respect to the distance function induced by the inner product.</p><p>To say that H is a complex inner product space means that H is a complex vector space on which there is an inner product ⟨x,y⟩ associating a complex number to each pair of elements x, y of H that satisfies the following properties:</p><p>The inner product of a pair of elements is equal to the complex conjugate of the inner product of the swapped elements:</p><p>$${\displaystyle \langle y,x\rangle ={\overline {\langle x,y\rangle }}\,.}$$</p><p>The inner product is linear in its first argument. For all complex numbers a and b,</p><p>$${\displaystyle \langle ax_{1}+bx_{2},y\rangle =a\langle x_{1},y\rangle +b\langle x_{2},y\rangle \,.}$$</p><p>The inner product of an element with itself is positive definite:</p><p>$${\displaystyle \langle x,x\rangle \geq 0}$$</p><p>where the case of equality holds precisely when x = 0.</p><p>The Completeness of H is expressed using a form of the Cauchy criterion for sequences in H: a pre-Hilbert space H is complete if every Cauchy sequence converges with respect to this norm to an element in the space. Completeness can be characterized by the following equivalent condition: if a series of vectors</p><p>$${\displaystyle \sum <em>{k=0}^{\infty }u</em>{k}}$$</p><p>converges absolutely in the sense that</p><p>$${\displaystyle \sum <em>{k=0}^{\infty }|u</em>{k}|&lt;\infty \,,}$$</p><p>then the series converges in H, in the sense that the partial sums converge to an element of H.</p>]]></content>
      
      
        <tags>
            
            <tag> Math </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Probability</title>
      <link href="/2018/09/30/Probability/"/>
      <url>/2018/09/30/Probability/</url>
      <content type="html"><![CDATA[<h2 id="The-Binomial-Distribution"><a href="#The-Binomial-Distribution" class="headerlink" title="The Binomial Distribution"></a>The Binomial Distribution</h2><p>$${\displaystyle f(k;n,p)=\Pr(X=k)={n \choose k}p^{k}(1-p)^{n-k}}$$</p><p>n trails, each trail produce one result, the result is that whether a certain event E happen or not. The event happens with probability p. The Binomial Distribution is denoted as Bin(n,p)</p><h2 id="The-Multinomial-Distribution"><a href="#The-Multinomial-Distribution" class="headerlink" title="The Multinomial Distribution"></a>The Multinomial Distribution</h2><p>$$P(x_1,…,x_k|n,p_1,..p_k) = Multi(x_1,…,x_k|n,p_1,..p_k) \<br>= \dfrac{N!}{x_1!\cdots x_k!}p_i^{x_i}\<br>=\dfrac{N!}{\prod_{i=1}^kx_i!}p_i^{x_i},\<br>where\ \sum_i x_i=N,x_i&gt;0 \prod_{i=1}^d \mu_i^{m_i}$$</p><p>n trails, each trail also produce one result, the result is that one of K events \(E_j\) happen. Each event happen with probability \(\pi_j\), j=1,2,….k where \(\pi_1 + \pi_2 +…..+\pi_k=1\). \(X_k\) is number of trials in which \(E_k\) occurs. \(X_1+X_2+….+X_k=n\).</p><p>Multinomial models the distribution of the histogram vector which indicates how many time each outcome was observed over N trials of experiments.</p><p>The individual components of a multinomial random vector are binomial and have a binomial distribution, \(X_1\sim Bin(n,\pi_1)\).</p><p>The notation is \(X\sim Mult(n,\pi)\).</p><h2 id="Poisson-Distribution"><a href="#Poisson-Distribution" class="headerlink" title="Poisson Distribution"></a>Poisson Distribution</h2><p>$${\displaystyle P(X=k)={\frac {e^{-\lambda }\lambda ^{k}}{k!}}}$$</p><p>Poisson distribution is the limit of binomial distribution where \(\lambda =np\).  \(Bin(n,p) \sim possion(\lambda)\) when n is large and p is small. </p><p>Poisson distribution is to model in a fixed time period or a fixed space, counts or events that occur randomly such as number of people buy something, number of goals in a round of match.</p><p>\(\lambda \) is the parameter describing the rate, that is the mean of the distribution. In poission distribution, \(E(X) = Var(X) = \lambda\). Usually the variance is larger than \(\lambda\) because of overdispersion.</p><p>Estimation of \(\lambda\): point estimation or interal estimation.</p><h2 id="Gaussian-process"><a href="#Gaussian-process" class="headerlink" title="Gaussian process"></a>Gaussian process</h2><p>A Gaussian process is a stochastic process such that each combination of random variables has a multivariate normal distribution.</p>]]></content>
      
      
    </entry>
    
    <entry>
      <title>Topic_Model</title>
      <link href="/2018/09/30/Topic-Model/"/>
      <url>/2018/09/30/Topic-Model/</url>
      <content type="html"><![CDATA[<h2 id="LDA"><a href="#LDA" class="headerlink" title="LDA"></a>LDA</h2><p>$$p(\theta,z,w|\alpha,\beta)=p(\theta|\alpha) \prod_{n=1}^N p(z_n|\theta)p(w_n|z_n,\beta)$$</p><p>where \(p(\theta|\alpha)\) is the estimation of parameters \(\theta\), \(p(z_n|\theta)\) is probability distribution of topics \(z_n\) given parameters \(\theta\), \(p(w_n|z_n,\beta)\) is probability distribution of words \(w_n\) over topics z.</p><p>It is actually a bayes network, compute the probability distribution of topics first, and given the topics distribution, each word would belongs to one or more topics. Compute the probability distribution over words given topics distribution.</p>]]></content>
      
      
    </entry>
    
    <entry>
      <title>Clustering</title>
      <link href="/2018/09/30/Clustering/"/>
      <url>/2018/09/30/Clustering/</url>
      <content type="html"><![CDATA[<p>Two kinds of clustering:</p><ol><li>parametric: K-means</li><li>non-parametric: Dense-based</li></ol><p>hree types of clustering:</p><ul><li>Hard Clustering. Each instance belongs to only one cluster</li><li>Hierachical clustering. Nested clusters.</li><li>Soft/Fuzzy Clustering</li></ul><h2 id="DBSCAN"><a href="#DBSCAN" class="headerlink" title="DBSCAN"></a>DBSCAN</h2><p>In center-based approach, density is defined as: given a radius and a central point, the number of points in the circle including the central points.</p><p>core points: Within an area that contains multiple points. The area has to satisfy some requirement with user specified parameters. For example, with radius(Eps) 5, if the number of points in the area exceeds like 7, then the core point is defined as a core point.</p><p>border points: falls within the neighborhood of a core point. Border points could not be core points.</p><p>noise points: not core points nor border points.</p><p>Algorithm:</p><ol><li>label all points as core, border, or noise points.</li><li>Eliminate noise points.</li><li>Put an edge between all core points that are within Eps of each other.</li><li>Merge each group of connected core points into a separate cluster.</li><li>Assign each border point to one of the clusters of its associatedcore points.</li></ol><p>Selection of DBSCAN Parameters<br>k-dist: the distance between the core point and the kth nearest point. plot the the k-dist graph and select the k as MinPts(min points in a cluster) and the dramatically change point as distance.</p><p>Strength: </p><ol><li>resistant to noise and can handle clusters of arbitrary shapesand size</li></ol><p>Weakness:</p><ol><li>has trouble when the clusters have widely varying densities. </li><li>has trouble with high-dimensional data because density is more difficult to definefor such data. </li><li>DBSCAN can be expensive when the computation of nearest neighbors requires computing all pairwise proximities, as is usually the case for high-dimensional data.</li></ol><h2 id="HDBSCAN"><a href="#HDBSCAN" class="headerlink" title="HDBSCAN"></a>HDBSCAN</h2><ol><li>Transform the space. Increase the distance between noise points and core points by <strong>mutual reachability distance</strong>.</li><li>Build the minimum spanning tree. The points could be viewed as a graph. The points are vertices and weighted edges are mutual reachability distance. The longer the distance, the higher the weight.</li><li>Build the cluster hierarchy. At beginning, each point is in the same cluster. After that, remove edges one by one according to the weights of edges in decreasing order.(remove long distence edge first) If there are ties, remove them all together.</li><li>After removal, assign a new cluster label to a component if it still has at least one edge, else assign it a null label (“noise”).</li><li>Extract the clusters</li></ol><h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p>Introduction to Data Mining</p><p><a href="http://producao.usp.br/bitstream/handle/BDPI/51005/2709770.pdf?sequence=1" target="_blank" rel="noopener">Hierarchical density estimates for data clustering, visualization, and outlier detection</a></p>]]></content>
      
      
    </entry>
    
    <entry>
      <title>TextRank</title>
      <link href="/2018/09/29/TextRank/"/>
      <url>/2018/09/29/TextRank/</url>
      <content type="html"><![CDATA[<p>TextRank is actuaaly the same as PageRank. The only difference is that the unit in the PageRank is a webpage while the unit in the TextRank is word or sentence.</p><h2 id="Keyword-Extraction"><a href="#Keyword-Extraction" class="headerlink" title="Keyword Extraction"></a>Keyword Extraction</h2><p>Each word is a vertex in the graph. Set up a context window. If two words co-occur in a context window, there is a link between those two words. The rest is the same as PageRank.</p><h2 id="Sentence-Extraction"><a href="#Sentence-Extraction" class="headerlink" title="Sentence Extraction"></a>Sentence Extraction</h2><p>Each sentence is a vertex in the graph. The difference with keyword extraction is that now all sentences are considered connected with a weight. The weight is sentence similarity. The graph becomes a weighted graph which means there is a weight associated with each edge. </p>]]></content>
      
      
        <tags>
            
            <tag> NLP </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Interview</title>
      <link href="/2018/09/20/Interview/"/>
      <url>/2018/09/20/Interview/</url>
      <content type="html"><![CDATA[<p>Find the max n number:<br>Like quick sort, find a random number. Divide the original array into two parts, one is less than the random number, the other is greater than the random number. Pick another random number in the greater part, iterate aforementioned steps until there are n numbers in the greater array.</p>]]></content>
      
      
    </entry>
    
    <entry>
      <title>Paper_review</title>
      <link href="/2018/09/18/Paper-review/"/>
      <url>/2018/09/18/Paper-review/</url>
      <content type="html"><![CDATA[<p>Bidirectional LSTM-CRF for sequence tagging: CRF utilize sentence-level information. In CRF input and output are connected directly. Bidirectional LSTM-CRF connect all output together with a transition matrix from one state to another state.</p><p>A Deep reinforced model for abstractive summarization: Use reinforcement leanring to derive a policy. Some critirion such as BLEU could not back-propagate directly. Employing reinforcement leanring could alleviate this problem.</p>]]></content>
      
      
    </entry>
    
    <entry>
      <title>Writing</title>
      <link href="/2018/09/18/Writing/"/>
      <url>/2018/09/18/Writing/</url>
      <content type="html"><![CDATA[<p>Writting is to explain an idea clearly and convince others. Presentation basically is trying to tell a story.</p><p>Is the sentence easy to understand?<br>Is the sentence enjoyable and interesting to read?  </p><p>Principles of writing:</p><ul><li>Cut unnecessary words and phrases; learn to part with your words!</li><li>Use the active voice (subject + verb + object)</li><li>Write with verbs: use strong verbs, avoid turning verbs into nouns, and don’t bury the main verb!</li></ul><h4 id="Cut-unnecessary-words"><a href="#Cut-unnecessary-words" class="headerlink" title="Cut unnecessary words"></a>Cut unnecessary words</h4><ul><li>Dead weight words and phrases</li><li>Empty words and phrases</li><li>Long words or phrases that could be short</li><li>Unnecessary jargon and acronyms</li><li>Repetitive words or phrases</li><li>Adverbs</li></ul><ol><li>Eliminate negatives</li><li>Eliminate superfluous uses of “there<br>are/there is”</li><li>Omit needless prepositions</li></ol><h4 id="Use-active-voice"><a href="#Use-active-voice" class="headerlink" title="Use active voice"></a>Use active voice</h4><p>More clearly.<br>In method section, it’s fine to use passive voice.</p>]]></content>
      
      
    </entry>
    
    <entry>
      <title>scrapy</title>
      <link href="/2018/09/12/scrapy/"/>
      <url>/2018/09/12/scrapy/</url>
      <content type="html"><![CDATA[<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">StatSpider</span><span class="params">(scrapy.Spider)</span>:</span></span><br><span class="line">    name = <span class="string">"stat_chart"</span></span><br></pre></td></tr></table></figure><p>name is used to identify the spider name.</p>]]></content>
      
      
        <tags>
            
            <tag> Scrapy </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Linux_Management</title>
      <link href="/2018/09/06/Linux-Management/"/>
      <url>/2018/09/06/Linux-Management/</url>
      <content type="html"><![CDATA[<p>remotely run sth after disconnection</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nohup command ......</span><br></pre></td></tr></table></figure><p>check runing process</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ps -ef</span><br></pre></td></tr></table></figure><p>check runing process and find a specific process</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ps -ef | grep python</span><br></pre></td></tr></table></figure><p>kill a process</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kill pid</span><br></pre></td></tr></table></figure><p>count number of files</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">find . -type f | wc -l</span><br></pre></td></tr></table></figure>]]></content>
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>QA</title>
      <link href="/2018/09/05/QA/"/>
      <url>/2018/09/05/QA/</url>
      <content type="html"><![CDATA[<p>Two kinds of QA:</p><ul><li>IR-based question answering </li><li>knowledge-based question answering</li></ul><p>Factoid questions: questions that can be answered with simple facts expressed in short text answers.</p><h3 id="IR-based-question-answering"><a href="#IR-based-question-answering" class="headerlink" title="IR-based question answering:"></a>IR-based question answering:</h3><ul><li>Question Processing: extract focus, classify the question type</li><li>Answer Type Detection(Question Classification)</li><li>Query Formulation: form a query from keywords and send to an information retrieval system.</li><li>Passage Retrieval: retrive documents and rank them according to features such as relevance, number of keywords and so on.</li><li>Answer Processing <ol><li>pattern-extraction: use pattern to extract the answer from retrived document</li><li>N-gram tiling</li></ol></li></ul>]]></content>
      
      
        <tags>
            
            <tag> NLP </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>LSTM</title>
      <link href="/2018/08/30/LSTM/"/>
      <url>/2018/08/30/LSTM/</url>
      <content type="html"><![CDATA[<h2 id="LSTM"><a href="#LSTM" class="headerlink" title="LSTM"></a>LSTM</h2><p>Forget gate, input gate and output gate controls the last hidden state, current input, and current output respectively.</p><p>The cell state propagates the information through the network. It runs straight down the entire chain, with only some minor linear interactions. It’s very easy for information to just flow along it unchanged.</p><p>Forget gate controls how much the network forgets about the previous cell state. The output of forget gate do element-wise multiplication with the last cell state.</p><p>$$f_t=\sigma(W_f\cdot [h_{t-1},x_t]+b_f)$$</p><p>The input gate controls how much the network utilize the current cell state to update the last cell state. The current cell state is also compute by the last hidden state and current input with just the different weight and bias matrix.</p><p>$$i_t=\sigma(W_i\cdot [h_{t-1},x_t]+b_i)$$</p><p>$$\tilde{C_t}=tanh(W_C\cdot [h_{t-1},x_t]+b_C)$$</p><p>Update of the cell state:</p><p>$$C_t=f_t<em>C_{t-1}+i_t</em>\tilde$$</p><p>The final output gate controls hou much the network outputs the current cell state after novation. The network puts the cell state through tanh (to push the values to be between −1 and 1) and multiply it by the output of the sigmoid gate, so that it only outputs the parts we decided to.</p><p>$$o_t=\sigma(W_o\cdot [h_{t-1},x_t]+b_o)\ h_t = o_t*tanh(C_t)$$</p><h2 id="Variant-of-LSTM"><a href="#Variant-of-LSTM" class="headerlink" title="Variant of LSTM"></a>Variant of LSTM</h2><p>$$C_t=f_t<em>C_{t-1}+(1-f_t)</em>\tilde$$</p><p>Utilize \(1-f_t\) to substitutes the input gate.</p><h3 id="GRU"><a href="#GRU" class="headerlink" title="GRU"></a>GRU</h3><p>With a single update gate to control whether the last hidden state or the current state is the output. A reset gate is used to control how much the past hidden units affect the current output.</p><p>$$z_t=\sigma(W_z\cdot [h_{t-1},x_t]+b_z)\ r_t=\sigma(W_r\cdot [h_{t-1},x_r]+b_i)\ \tilde{h_t}=tanh(W\cdot [r_t<em>h_{t-1},x_t]) \ h_t = (1-z_t)</em>h_{t-1}+z_t*\tilde{h_t}<br>$$</p><p>Here reset gate resembles the forget gate in LSTM. It decides how much the last hidden state contributes to the current hidden state. And the final output hidden state is controlled by the update gate which resembles the ouput gate in LSTM. Simpler than LSTM.</p><h3 id="Peephole-connection"><a href="#Peephole-connection" class="headerlink" title="Peephole connection"></a>Peephole connection</h3><p>The value of gate is now controled by cell state, hidden state and current input. </p><p>$$o_t=\sigma(W_o\cdot [C_t,h_{t-1},x_t]+b_o)\ i_t=\sigma(W_i\cdot [C_{t-1},h_{t-1},x_t]+b_i)\ _t=\sigma(W_f\cdot [C_{t-1},h_{t-1},x_t]+b_f)<br>$$</p>]]></content>
      
      
        <tags>
            
            <tag> DL </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Attention</title>
      <link href="/2018/08/27/Attention/"/>
      <url>/2018/08/27/Attention/</url>
      <content type="html"><![CDATA[<p>Attention is a distribution which describe how much the network should focus on each unit.</p><h3 id="content-based"><a href="#content-based" class="headerlink" title="content-based"></a>content-based</h3><p>The attending RNN generates a query describing what it wants to focus on. Each item is dot-producted with the query to produce a score, describing how well it matches the query. The scores are fed into a softmax to create the attention distribution.</p><h3 id="location-based"><a href="#location-based" class="headerlink" title="location-based"></a>location-based</h3><h3 id="Neural-Turing-Machines"><a href="#Neural-Turing-Machines" class="headerlink" title="Neural Turing Machines"></a>Neural Turing Machines</h3><p>Neural Turing Machines combine a RNN with an external memory bank. Since vectors are the natural language of neural networks, the memory is an array of vectors. Every step, NTMs read and write everywhere, just to different extents.</p><p>Read operation is a weighted sum of the distribution.</p><p>Similarly, NTMs write everywhere at once to different extents. Again, an attention distribution describes how much NTMs write at every location. The new value of a position in memory is a convex combination of the old memory content and the new write value.</p><h4 id="Attention-Mechanism"><a href="#Attention-Mechanism" class="headerlink" title="Attention Mechanism"></a>Attention Mechanism</h4><ul><li>The RNN controller gives a query vector.</li><li>Each memory entry is scored for similarity with the query(dot product).</li><li>The scores are then converted into a distribution using softmax.</li><li>Interpolate the attention from the previous time step with the current distribution controlled by intepolation amount.</li><li>Convolve the attention with a shift filter which allows the controller to move its focus.</li><li>Sharpen the attention distribution. This final attention distribution is fed to the read or write operation.</li></ul><h3 id="Attentional-Interfaces"><a href="#Attentional-Interfaces" class="headerlink" title="Attentional Interfaces"></a>Attentional Interfaces</h3><p>Between connection of RNN or (RNN,CNN), there would be attentional interfaces which decides which units in the previous layer should pay attention to.</p><h2 id="Attention-is-all-you-need"><a href="#Attention-is-all-you-need" class="headerlink" title="Attention is all you need"></a>Attention is all you need</h2><p>The encoder is composed of N=6 identical layers. Each layer has two sub-layers</p><h4 id="Attention"><a href="#Attention" class="headerlink" title="Attention"></a>Attention</h4><p>Attention function could be described as a function to map query, key and values to a weighted sum. Attention is actually a query. The output is a weighted sum of values and each weight is the dot product of the query and the key.</p><h4 id="Scaled-Dot-Product-Attention"><a href="#Scaled-Dot-Product-Attention" class="headerlink" title="Scaled Dot-Product Attention"></a>Scaled Dot-Product Attention</h4><p>In the paper, scaled dot-product attention is actually the attention function scaled by \(\frac{1}{\sqrt d_k}\)</p><h4 id="Multi-Head-Attention"><a href="#Multi-Head-Attention" class="headerlink" title="Multi-Head Attention"></a>Multi-Head Attention</h4><p>Linearly project query, key, value with learnable weights. After that apply attention function to projected query, key, value. This is one head. MultiHead is concatenation of MultiHead and apply a linear transformation to the concatenation.</p><p><strong>Multi-Head Attention allows the model to jointly attend to information from different representation subspaces at different positions.</strong></p><p>Multi-head attention simulates convolutional neural network. Each head employs different weights such that different heads learn different relationship. In terms of convolution, different positions learn different features.</p><h4 id="Position-wise-Feed-Forward-Networks"><a href="#Position-wise-Feed-Forward-Networks" class="headerlink" title="Position-wise Feed-Forward Networks"></a>Position-wise Feed-Forward Networks</h4><p>Increase or decrease the dimention of representation.</p><h4 id="Positional-Embedding"><a href="#Positional-Embedding" class="headerlink" title="Positional Embedding"></a>Positional Embedding</h4><p>The paper propose to use positional embedding to encode position information.</p>]]></content>
      
      
        <tags>
            
            <tag> DL </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>NN_Architecture</title>
      <link href="/2018/08/25/NN-Architecture/"/>
      <url>/2018/08/25/NN-Architecture/</url>
      <content type="html"><![CDATA[<h3 id="GoogleNet"><a href="#GoogleNet" class="headerlink" title="GoogleNet"></a>GoogleNet</h3><ul><li>Auxiliary classifier layer is to solve the gradient vanishing problem</li><li>In the higher part of neural network, the filter would concentrate on detail or high-level feature of the images. As a result, the local region should large which is why the numbers of 3 <em> 3 and 5 </em> 5 filters have to be increased.</li><li>1 * 1 convolution: dimensionality reduction. If not, there would be many parameters.</li><li>3 <em> 3 and 5 </em> 5 is employed because with different stride and padding, their output dimension would be the same. </li><li>Different convonlution kernel means different receptive field, fileter concatenation is concatenation of features.</li></ul><h3 id="Residual-Network"><a href="#Residual-Network" class="headerlink" title="Residual Network"></a>Residual Network</h3><p>Learn the mapping(original function) directly would be hard, denoted by degration of accuracy if layers are simply added. Learn the residual function would nbe much easier. If the mapping is worse, the network would learn to discard the learnt mapping and simply use the skip connection. The performance would be at least as good as the shallow network.</p><h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p><a href="https://arxiv.org/abs/1512.03385" target="_blank" rel="noopener"><br>Deep Residual Learning for Image Recognition</a></p><p><a href="https://blog.csdn.net/shuzfan/article/details/50738394" target="_blank" rel="noopener"><br>GoogLeNet系列解读</a></p>]]></content>
      
      
        <tags>
            
            <tag> DL </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>training_problem</title>
      <link href="/2018/08/25/training-problem/"/>
      <url>/2018/08/25/training-problem/</url>
      <content type="html"><![CDATA[<h4 id="Cuda-Out-of-Memory"><a href="#Cuda-Out-of-Memory" class="headerlink" title="Cuda Out of Memory"></a>Cuda Out of Memory</h4><p>Solution: </p><ul><li>reduce batch size</li><li>reduce model size(reduce number of activation, increase filter size, decrease filter number)</li><li>For RNN, reduce the length</li></ul><h3 id="Validation-accuracy-aigzagging"><a href="#Validation-accuracy-aigzagging" class="headerlink" title="Validation accuracy aigzagging"></a>Validation accuracy aigzagging</h3><ul><li>Data is not normalized, taking some steps would deviate from the local minimum</li><li>training step size is too large.</li></ul><h2 id="NLP"><a href="#NLP" class="headerlink" title="NLP"></a>NLP</h2><p>Assign high probability to <s> and <e>.</e></s></p><p>ber: </p>]]></content>
      
      
        <tags>
            
            <tag> DL </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>gradient_descent</title>
      <link href="/2018/08/22/gradient-descent/"/>
      <url>/2018/08/22/gradient-descent/</url>
      <content type="html"><![CDATA[<h2 id="Vanilla-gradient-descent"><a href="#Vanilla-gradient-descent" class="headerlink" title="Vanilla gradient descent"></a>Vanilla gradient descent</h2><p>Calculate the gradient of the whole dataset and average the gradient by the size of the dataset. </p><p>Drawback: Time-consuming, compute gradients redundantly.</p><h2 id="Mini-batch-gradient-descent"><a href="#Mini-batch-gradient-descent" class="headerlink" title="Mini-batch gradient descent"></a>Mini-batch gradient descent</h2><p>Take a batch of examples and calculate the gradient. After that, average the gradient by the batch size.</p><h2 id="Stochastic-gradient-descent"><a href="#Stochastic-gradient-descent" class="headerlink" title="Stochastic gradient descent"></a>Stochastic gradient descent</h2><p>Take a single example and calculate the gradient. </p><p>Drawback: High variance, fluctuate a lot.<br>In high dimension, some directions would have larger gradients and zigzag a lot. The direction of gradient would deviate from the best direction.</p><h3 id="Momentum"><a href="#Momentum" class="headerlink" title="Momentum"></a>Momentum</h3><p>Momentum would accumulate gradient if the direction is the same and reduce the gradient if the direction zigzag a lot such that the overall direction would point to the local/global minimum with less zigzagging.</p><p>$$v_t = \gamma v_{t-1} - \eta \nabla_\theta J( \theta)$$</p><p>$$\theta = \theta + v_t$$</p><p>\(\theta\) is the gradient and \(\gamma\) is the momentum which is usually 0.9. \(\eta\) is the learning rate.</p><h3 id="Nesterov-accelerated-gradient"><a href="#Nesterov-accelerated-gradient" class="headerlink" title="Nesterov accelerated gradient"></a>Nesterov accelerated gradient</h3><p>It is a lookahead version of momentum. The gradient would be updated using momentum, and a estimate of the future gradient after normal momentum update\(\nabla_\theta J( \theta - \gamma v_{t-1} )\) would be added to the current update of gradient so as to accelerate convergence. <strong>It significantly increased the performance of RNNs.</strong></p><p>$$<br>v_t = \gamma v_{t-1} - \eta \nabla_\theta J( \theta + \gamma v_{t-1} ) \<br>\theta = \theta + v_t$$</p><h3 id="Adagrad"><a href="#Adagrad" class="headerlink" title="Adagrad"></a>Adagrad</h3><p>It adapts the learning rate to the parameters, performing larger updates for infrequent and smaller updates for frequent<br>parameters.</p><p>$$\theta_{t+1, i} = \theta_{t, i} - \dfrac{\eta}{\sqrt{G_{t, ii} + \epsilon}} \cdot g_{t, i}$$</p><p>\(G_{t} \in \mathbb{R}^{d \times d}\) is a diagonal matrix where each diagonal element i,i is the sum of the squares of the gradients w.r.t. \(\theta_i\) up to time step t, while \(\epsilon\) is a smoothing term that avoids division by zero (usually on the order of 1e−8). Interestingly, without the square root operation, the algorithm performs much worse.</p><p>Drawback: The accumulated sum keeps growing during training and causes the learning rate to shrink and eventually become infinitesimally small, at which point the algorithm is no longer able to acquire additional knowledge.</p><h3 id="Adadelta"><a href="#Adadelta" class="headerlink" title="Adadelta"></a>Adadelta</h3><p>$$\Delta \theta_t = - \dfrac{RMS[\Delta \theta]<em>{t-1}}{RMS[g]</em>{t}} g_{t} \<br>\theta_{t+1} = \theta_t + \Delta \theta_t<br>$$</p><h3 id="RMSprop"><a href="#RMSprop" class="headerlink" title="RMSprop"></a>RMSprop</h3><p>Approximate the learning rate with the RMS of parameter updates until the previous time step. </p><p>$$E[g^2]<em>t = 0.9 E[g^2]</em>{t-1} + 0.1 g^2_t \<br>\theta_{t+1} = \theta_{t} - \dfrac{\eta}{\sqrt{E[g^2]<em>t + \epsilon}} g</em>{t}<br>$$</p><p>It still accumulates the gradient while it also depends on the current gradient and the updates do not get monotonically smaller.<br>RMSProp still modulates the learning rate of each weight based on the magnitudes of its gradients, which has a beneficial equalizing effect.</p><h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p><a href="https://arxiv.org/pdf/1609.04747.pdf" target="_blank" rel="noopener">An overview of gradient descent optimization<br>algorithms</a></p>]]></content>
      
      
        <tags>
            
            <tag> DL </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Network_in_Network</title>
      <link href="/2018/08/18/Network-in-Network/"/>
      <url>/2018/08/18/Network-in-Network/</url>
      <content type="html"><![CDATA[]]></content>
      
      
        <tags>
            
            <tag> DL </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>seq2seq</title>
      <link href="/2018/08/11/seq2seq/"/>
      <url>/2018/08/11/seq2seq/</url>
      <content type="html"><![CDATA[<p>The input is a sequence and the output is also a sequence. Normal RNN take sequence or vector as input and output</p><ul><li>Fixed-length vector</li><li>Sequence with the same length as the input sequence.</li></ul><p>seq2seq could output a sequence of variable length. It simply utilize an encoder to encode the information given an input, which output a representation C that is a semantic summary of the input(usually fixed-length). After that, the decoder take the representation as input and output a sequence.</p><p>The decoder is a RNN language model that is conditioned on the input which is the current the previous input word and the hidden state.</p><h3 id="Reverse-the-input-sequence"><a href="#Reverse-the-input-sequence" class="headerlink" title="Reverse the input sequence"></a>Reverse the input sequence</h3><p>Doing so would make the optimization much easier because it introduces short term dependencies.</p><p>i.e.: a,b,c maps to d,e,f. With reversed input sequence, c,b,a maps to d,e,f. At present, a is much closer than d which is the correct mapping. Since the long dependency c to f may be learnt from previous mapping, longer dependency for it may not be a problem.</p><h3 id="Encoding-Context-C"><a href="#Encoding-Context-C" class="headerlink" title="Encoding Context C"></a>Encoding Context C</h3><p>The context C that is used to encode the input sequence do capture the meaning of the sequence.</p><h3 id="Lmitatoin"><a href="#Lmitatoin" class="headerlink" title="Lmitatoin"></a>Lmitatoin</h3><p>The context C might be to small to encode the semantic information of a long sentence.</p><h3 id="Decoding"><a href="#Decoding" class="headerlink" title="Decoding"></a>Decoding</h3><p>The decoding could employ beam search. The procedure is actually to maximize the log probability of target sentence given the input sentence.</p>]]></content>
      
      
        <tags>
            
            <tag> DL </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>CNN</title>
      <link href="/2018/08/10/CNN/"/>
      <url>/2018/08/10/CNN/</url>
      <content type="html"><![CDATA[<h3 id="Prior-parameter-distribution"><a href="#Prior-parameter-distribution" class="headerlink" title="Prior parameter distribution"></a>Prior parameter distribution</h3><p>A prior probability distribution over the<br>parameters of a model is to encode our belief about what models are resonable before seeing the data.</p><ul><li>a week prior: distribution with high entropy like Gaussian with high variance. It allows the data to move parameters of model freely.</li><li>a strong prior: distribution with low entropy like Gaussian with low variance. Such a prior plays a more active role in determining where the parameters end up.</li></ul><h4 id="Infinitely-Strong-Prior"><a href="#Infinitely-Strong-Prior" class="headerlink" title="Infinitely Strong Prior"></a>Infinitely Strong Prior</h4><ul><li>An infinitely strong prior places zero probability on some parameters</li><li>It says that some parameter values are forbidden regardless of support from data.</li></ul><h3 id="Convolution-as-infinitely-strong-prior"><a href="#Convolution-as-infinitely-strong-prior" class="headerlink" title="Convolution as infinitely strong prior"></a>Convolution as infinitely strong prior</h3><p>Convolution introduces an infinitely strong prior probability distribution over the parameters of a layer which says that the function the layer should learn contains only local interactions and is equivariant to translation.</p><h3 id="Pooling-as-an-Infinitely-strong-prior"><a href="#Pooling-as-an-Infinitely-strong-prior" class="headerlink" title="Pooling as an Infinitely strong prior"></a>Pooling as an Infinitely strong prior</h3><p>The use of pooling is an infinitely strong prior that each unit should be invariant to small translations.</p><p>High Bias/Underfit can be countered by:</p><ol><li>Add hidden layers</li><li>Increase hidden units/layer</li><li>Decrease regularize parameter.</li><li>Add features </li></ol><h5 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h5><p><a href="https://cedar.buffalo.edu/~srihari/CSE676/9.4%20ConvPoolAsPrior.pdf" target="_blank" rel="noopener">Deep Learning Slides</a></p><h3 id="Convolution"><a href="#Convolution" class="headerlink" title="Convolution"></a>Convolution</h3><p>Each convolution is acutually a filter doing element-wise multiplication with a local region on all channels of the input. After that sum them up and add the bias. One filter one bias.</p><h3 id="Parameters-Sharing"><a href="#Parameters-Sharing" class="headerlink" title="Parameters Sharing"></a>Parameters Sharing</h3><p>Parameters in a kernel are used to do convolution in the whole image. In terms of fully connect, for each pixel, there would be a different parameters.</p><h3 id="Local-Connectivity"><a href="#Local-Connectivity" class="headerlink" title="Local Connectivity"></a>Local Connectivity</h3><p>The neural network only contains regional connection which means the neurons in the next layer focus on part of neurons in the last layer.</p><h3 id="Pooling-Layer"><a href="#Pooling-Layer" class="headerlink" title="Pooling Layer"></a>Pooling Layer</h3><p>The employment of pooling layer is significant. It reduce the size of representation so as to reduce the computation and control overfitting. Max pooling could be regarded as extraction of the most useful characteristic. Pooling could be performed on spatial regions, or over the multi-layer outputs. For example, max pooling is performed on feature maps which is a spatial region while 1*1 convolution is performed on the multi-channel feature maps which is usually used to reduce dimension and compress information. When performed on spatial regions, it yields the same output dimension with smaller filter size. This would enable the neural network to be invariant to local small translations of the input, which is useful in case of whether a feature is present is more important than where the feature is. When performed on the multi-layer outputs, it yields the same filter size with fewer dimensionality. This would enable the neural network to be invariant to transformation such as rotation of images. In a nutshell, pooling summarises the response of activation over a region. It improves the computational and statistical efficiency. It is also used in hadling inputs of varying size.</p><h4 id="Memory-Consumption-Calculation"><a href="#Memory-Consumption-Calculation" class="headerlink" title="Memory Consumption Calculation"></a>Memory Consumption Calculation</h4><p>Activation needs to be stored for back-propagation. So it would be the major memory consumption.</p><p>i.e.: an image of 224 <em>224</em>3. The activation would be 224<em> 224</em>3=150000 floating numbers. Each floating number would use 4 bytes to store, so its size is actually 600000 bytes which is 600KB for only the first layer in the network.</p><p>Convolution is a function derived from two given functions by integration that expresses how the shape of one is modified by the other. It is how an input is transformed by a kernel.</p><p>Feature visualization have shown that:</p><ul><li><p>lower layers extract features related to content</p></li><li><p>higher layers extract features related to style**</p></li></ul>]]></content>
      
      
    </entry>
    
    <entry>
      <title>RNN</title>
      <link href="/2018/08/10/RNN/"/>
      <url>/2018/08/10/RNN/</url>
      <content type="html"><![CDATA[<p>RNN allows information flow.</p><h3 id="Parameters-Sharing"><a href="#Parameters-Sharing" class="headerlink" title="Parameters Sharing"></a>Parameters Sharing</h3><p>The same set of parameters are used to compute the hidden states at the current time step given input and the hidden state of last time step.</p><p>A output layer may be added to each time step to extract information and make predictions.</p><h3 id="Back-propagation"><a href="#Back-propagation" class="headerlink" title="Back-propagation"></a>Back-propagation</h3><p>Cannot be parallelized because gradient has to computed one by one in terms of time steps.</p><h4 id="Recurrent-Connectiong-from-output-to-hidden"><a href="#Recurrent-Connectiong-from-output-to-hidden" class="headerlink" title="Recurrent Connectiong from output to hidden"></a>Recurrent Connectiong from output to hidden</h4><p>Training can be parallelized because the label is known and could be fed to hidden states directly. Trained with <strong>Teacher Forcing</strong> which is that given the input sequence and ground truth label in the last time step, produce the output in the current time step.</p><p>Drawback: require the output to capture the past information, which is difficult because the output dosen’t contains those information.</p><h2 id="RNN-as-graphical-model"><a href="#RNN-as-graphical-model" class="headerlink" title="RNN as graphical model"></a>RNN as graphical model</h2><p>RNN could be viewed as a graphical model. Compared to the graphical model, the number of parameters is far less than that of the graphical model due to parameter sharing.</p><p>Basic assumption of RNN is that the sequence is stationary.</p><p><strong>stationary</strong> The relationship between the previous time step and the current time step is not dependent on t.</p><p>RNN could model long dependency while normal graphical model would make <strong>Markov assumption</strong> to simplify the parameters which makes them less powerful in terms of long dependency. Long dependency makes RNN hard to optimize.</p><p>RNN introduce hidden states h s.t. the dependency structure is simpler than the normal graphical model because hidden state encodes information including dependency which graphical model utilizes edges to represent dependency directly(too many parameters to optimize).</p><h3 id="Clip-Gradient-Solution-to-gardient-explosion"><a href="#Clip-Gradient-Solution-to-gardient-explosion" class="headerlink" title="Clip Gradient(Solution to gardient explosion)"></a>Clip Gradient(Solution to gardient explosion)</h3><p>There are some cliffs which is with large gradient inside a place where surroundings are with small gradient. Due to the leanring rate is adapted, at that time, the learning rate may be large to accelerate learning s.t. at the cliffs the gradient would overshoot. Clip the gradient means if the norm of gradient is larger than a threshold, normalize the gradient. This would make the gradient a biased estimation of the gradient of the mini-batch. Larger gradient would contribute more the overall gradient. But the clipped gradient could solve the problem.</p><h2 id="Output"><a href="#Output" class="headerlink" title="Output"></a>Output</h2><p>The output of character level or word level RNN is the probability distribution of the next character or word given previous sequences of character or word. We sample from this distribution, and feed it right back in to get the next letter. Repeat this process and you’re sampling text!</p><h4 id="vector-to-sequence-RNN"><a href="#vector-to-sequence-RNN" class="headerlink" title="vector-to-sequence RNN"></a>vector-to-sequence RNN</h4><p>The vector could be fed into the RNN at the beginning or fed into each hidden state at each time step.</p><h3 id="Recursive-Neural-Network"><a href="#Recursive-Neural-Network" class="headerlink" title="Recursive Neural Network"></a>Recursive Neural Network</h3><p>Tree structure neural network. Its advantage is that its depth is far shallow than normal neural network with the same length of input.</p><h3 id="Challenge-of-Long-Term-Dependencies"><a href="#Challenge-of-Long-Term-Dependencies" class="headerlink" title="Challenge of Long-Term Dependencies"></a>Challenge of Long-Term Dependencies</h3><p>With long-term dependency, due to parameter sharing, the weight matrix W would be multiplied for several time which make the gradient exponentially larger or samller. Even the problem of vanishing gradient is solved, due to exponentially samller of gradient, it is very hard to train the network.</p><h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p><a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/" target="_blank" rel="noopener"><br>The Unreasonable Effectiveness of Recurrent Neural Networks</a></p>]]></content>
      
      
        <tags>
            
            <tag> DL </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>activation_function</title>
      <link href="/2018/08/09/activation-function/"/>
      <url>/2018/08/09/activation-function/</url>
      <content type="html"><![CDATA[<h2 id="Rectified-Linear-Units"><a href="#Rectified-Linear-Units" class="headerlink" title="Rectified Linear Units"></a>Rectified Linear Units</h2><p>Easy to optimize, and train. It is a good practice to initialize the bias b to be small positive values s.t. most units are active at the beginning.</p><p>Drawback: not able to learn examples that activation is zero. A large gradient could update the unit s.t. it would never be active again if the learning rate is large.</p><h3 id="Leaky-ReLU"><a href="#Leaky-ReLU" class="headerlink" title="Leaky ReLU"></a>Leaky ReLU</h3><p>Make some modifications s.t. the negative part could also be learnt.</p><h3 id="Maxout-units"><a href="#Maxout-units" class="headerlink" title="Maxout units"></a>Maxout units</h3><p>Generalization of ReLU and Leaky Relu. The activation function is now \(\max(w_1^T\cdot x, w_2^T\cdot x)\) where \(w_1^T\cdot x\) is Relu (when w1 are all zeros, it is Relu)and \(w_2^T\cdot x\) is Leaky Relu.</p><h2 id="Sigmoid"><a href="#Sigmoid" class="headerlink" title="Sigmoid"></a>Sigmoid</h2><p>Could be used as output units for 0-1 classfication because the cost is optimized to be small to avoid saturation.</p><p>Drawback: hard to train due to saturation. Not zero-centered.</p><h2 id="Tanh"><a href="#Tanh" class="headerlink" title="Tanh"></a>Tanh</h2><p>A scaled sigmoid, zero-centered. Resemble the identity function</p>]]></content>
      
      
        <tags>
            
            <tag> DL </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>SVM</title>
      <link href="/2018/08/05/SVM/"/>
      <url>/2018/08/05/SVM/</url>
      <content type="html"><![CDATA[<p>Derivation of SVM:</p><ul><li>write down the equation. $$\max \limits_{w,b} {1\over ||w||}$$ such that $$ {(w^Tx_i+b)*y_i}\ge1$$</li><li>Lagrange multipliers to solve the dual problem and get the answer of the primal problem if the problem satisfy KKT condition.</li><li>$$\begin{cases}<br>{\partial L \over \partial w}=0 &amp; \<br>{\partial L \over \partial b}=0 &amp;<br>\end{cases} \Longrightarrow<br>\begin{cases}<br>w=\sum \limits_{i=1}^m\alpha_ix_iy_i &amp; \<br>0=\sum \limits_{i=1}^m\alpha_iy_i &amp;<br>\end{cases}$$<br>$$\begin{cases}<br>w^<em>=\sum \limits_{i=1}^m\alpha_i^</em>x_iy_i &amp; \<br>b^<em>=y_j-\sum \limits_{i=1}^m\alpha_i^</em>y_i(x_i\cdot x_j) &amp;<br>\end{cases}$$</li></ul><p>$$y_j(w^<em>\cdot x_j+b^</em>)-1=0$$ substitute the w with aforementioned equation and multiply \(y_j\) simultaneously.\(y_j^2=1\)</p><ul><li>Most \(\alpha_i\)=0, for those \(\alpha_j \neq 0 \), their training samples \(x_i\) are so called support vector.</li><li>Slove the problem</li></ul><p>For problems that are not linearly separatable, add a slack variable.</p><p>Above is so called linear SVM.</p><h2 id="Non-Linear-SVM"><a href="#Non-Linear-SVM" class="headerlink" title="Non-Linear SVM"></a>Non-Linear SVM</h2><p>Apply a kernel function K(x,z) to substitute the original inner product \(x_i\cdot x_j\). Affine the original variables in Euclidean space to another feature space to transfer the problem from non-linear to linear.</p><h2 id="Hinge-Loss"><a href="#Hinge-Loss" class="headerlink" title="Hinge Loss"></a>Hinge Loss</h2><p>Anything falls between the margin would contribute to the loss. Those classified wrong would contribute more than classfied correct but with low confidence level. It is the upper bound of 0-1 loss.</p><h2 id="Perceptron-Loss"><a href="#Perceptron-Loss" class="headerlink" title="Perceptron Loss"></a>Perceptron Loss</h2><p>Between 0-1 loss and hinge loss. The loss would be zero if classification is right. If the classification is wrong within the margin, the loss between 0 and 1. If the classification is wrong and outside the margin, the loss greater than 1.</p><h2 id="0-1-Loss"><a href="#0-1-Loss" class="headerlink" title="0-1 Loss"></a>0-1 Loss</h2><p>The loss is only 0 or 1 corresponds to wrong or correct classification. Not continuously differentiable.</p><h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p><a href="http://net.pku.edu.cn/~course/cs410/2015/resource/book/2012-book-StatisticalLearning-LH.pdf" target="_blank" rel="noopener">统计学习方法</a></p>]]></content>
      
      
        <tags>
            
            <tag> ML </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>CRF</title>
      <link href="/2018/08/02/CRF/"/>
      <url>/2018/08/02/CRF/</url>
      <content type="html"><![CDATA[<h2 id="Conditional-Random-Field-CRF"><a href="#Conditional-Random-Field-CRF" class="headerlink" title="Conditional Random Field(CRF)"></a>Conditional Random Field(CRF)</h2><p>It is a kind of generalized logistic regression model.</p><p>HMMs have difficulty modeling overlapping, non-independent features because the assuption is indepence. In NLP, words are correlated and connection between them contains information. Here is where CRF comes into play.</p><p>Linear chain CRF, can be thought of as the undirected graphical model version of HMM. It is as efficient as HMMs, where the sum-product algorithm and max-product algorithm still apply. Linear chain CRF is a special case of CRF, where each clique is the nearby two nodes. In terms of graph, the structure would be much more different.</p><p>Overlapping features are in fact boost up the belief of the result, which should not be eliminated simply.</p><p>CRF is conditional probability distribution while HMM is joint probability distribution.</p><h3 id="Formal-Definition-of-CRF"><a href="#Formal-Definition-of-CRF" class="headerlink" title="Formal Definition of CRF"></a>Formal Definition of CRF</h3><p>$$P(y\mid x) = \frac{1}{Z(x)} \prod_{c \in C} \phi_c(x_c,y_c)$$</p><p>where C denotes the set of cliques (i.e. fully connected subgraphs), \(\phi_c(x_c,y_c)\) is a factor. </p><p>$$Z(x) = \sum_{y \in \mathcal{Y}} \prod_{c \in C} \phi_c(x_c,y_c)$$</p><h4 id="Parameterized-Form-of-CRF"><a href="#Parameterized-Form-of-CRF" class="headerlink" title="Parameterized Form of CRF:"></a>Parameterized Form of CRF:</h4><p>$$P(y|x)=\frac{1}{Z(x)}\exp (\sum_{i,k}\lambda_kt_k(y_{i-1},y_i,x,i)+\sum_{i,l}\mu_ls_l(y_i,x,i))$$</p><p>$$Z(x)=\sum_y \exp (\sum_{i,k}\lambda_kt_k(y_{i-1},y_i,x,i)+\sum_{i,l}\mu_ls_l(y_i,x,i))$$</p><p>where \(\lambda_k, \mu_l\) are weights and \(t_k(y_{i-1},y_i,x,i)\) is the transition probability that given \(y_{i-1}\), the next label is \(y_{i}\) given input x at position i. \(\mu_ls_l(y_i,x,i)\) is the probability that at position i, given x, the output is \(y_{i}\).</p><h4 id="Inference-of-label-y"><a href="#Inference-of-label-y" class="headerlink" title="Inference of label y"></a>Inference of label y</h4><p>$$\arg \max_y \phi_1(y_1, x_1) \prod_{i=2}^n \phi(y_{i-1}, y_i) \phi(y_i, x_i)$$</p><p>In practice, \(\phi_c(x_c,y_c) = \exp(w_c^T f_c(x_c, y_c)).\) And \(f_c(x_c, y_c) = \lambda_kt_k(y_{i-1},y_i,x,i)+\mu_ls_l(y_i,x,i)\). This could also be written in vector form.</p><p>The most important realization that need to be made about CRF features is that they can be arbitrarily complex. In fact, we may define CRF that depend on the entire input x. This will not affect computational performance at all, because at inference time, the x will be always observed.</p><h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p><a href="http://net.pku.edu.cn/~course/cs410/2015/resource/book/2012-book-StatisticalLearning-LH.pdf" target="_blank" rel="noopener">统计学习方法</a></p><p><a href="https://github.com/Zhenye-Na/cs446/blob/master/docs/Probabilistic%20Graphical%20Models%20-%20Principles%20and%20Techniques.pdf" target="_blank" rel="noopener">Probabilistic Graphical Models - Principles and Techniques</a></p><p><a href="https://ermongroup.github.io/cs228-notes/representation/undirected/" target="_blank" rel="noopener">cs228 notes </a></p>]]></content>
      
      
        <tags>
            
            <tag> ML </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Word_Representation</title>
      <link href="/2018/08/01/Word-Representation/"/>
      <url>/2018/08/01/Word-Representation/</url>
      <content type="html"><![CDATA[<p>The gradient of the whole word matrix(context matrix) should be outer product rather than normal inner product because their dimensions are not matched.</p><h3 id="Feedforward-Neural-Net-Language-Model-NNLM"><a href="#Feedforward-Neural-Net-Language-Model-NNLM" class="headerlink" title="Feedforward Neural Net Language Model (NNLM)"></a>Feedforward Neural Net Language Model (NNLM)</h3><p>Time complexity:<br>Q = N × D + N × D × H + H × V, where the dominating term is H × V.</p><p>N are the N input examples, D is the dimensionality of the word vectors, H is the hidden layer size, V is the vocab size.</p><p>With binary tree representations of the vocabulary, the number of output units that need to be evaluated can go down to around log2(V). Thus, most of the complexity is caused by the term N × D × H.</p><p>Huffman trees assign short binary codes to frequent words, and this further reduces the number of output units that need to be evaluated: while balanced binary tree would require log2(V) outputs to be evaluated, the Huffman tree based hierarchical softmax requires only about log2(Unigram perplexity(V)).</p><h3 id="Continuous-Bag-of-Words-Model-CBOW"><a href="#Continuous-Bag-of-Words-Model-CBOW" class="headerlink" title="Continuous Bag-of-Words Model(CBOW)"></a>Continuous Bag-of-Words Model(CBOW)</h3><p>Given context words, predict the central words. Average the input word vectors, which ignore the order of words, and then predict the output word.</p><p>The training complexity of this architecture is proportional to</p><p>Q = N × D + D × log2(V ).</p><p>C is the context size.</p><p>The order of words in the history and future does not influence the projection, like bag-of-words model.</p><p>Note that the weight matrix between the input and the projection layer is shared for all word positions in the same way as in the NNLM. Here the weight matrix are the word vectors.</p><h3 id="Continuous-Skip-gram-Model"><a href="#Continuous-Skip-gram-Model" class="headerlink" title="Continuous Skip-gram Model"></a>Continuous Skip-gram Model</h3><p>Similar to CBOW, in this model, input the central word and predict the context words, others are the same. This is a </p><p>The training complexity of this architecture is proportional to</p><p>Q = C × (D + D × log2(V ))</p><p>where C is the maximum distance of the words. For each training word we will select randomly a number R in range &lt; 1; C &gt;, and then use R words from history and R words from the future of the context as correct labels. This will require us to do R × 2 word classifications, with the current word as input, and each of the R + R words as output. </p><p>increasing the context size C improves quality of the resulting word vectors, but it also increases the computational complexity. </p><p>Since the more distant words are usually less related to the current word than those close to it, we give less weight to the distant words by sampling less from those words in our training examples. 2<em>R words which is less than C are used as correct label. this step contains sampling 2</em>R words from C word. </p><h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p><a href="https://web.stanford.edu/~jurafsky/slp3/" target="_blank" rel="noopener">Speech and Language Processing</a></p>]]></content>
      
      
        <tags>
            
            <tag> NLP </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Pytorch</title>
      <link href="/2018/07/31/Pytorch/"/>
      <url>/2018/07/31/Pytorch/</url>
      <content type="html"><![CDATA[<p>reshape in pytorch: torch.view</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">x = torch.randn(<span class="number">4</span>, <span class="number">4</span>)</span><br><span class="line">z = x.view(<span class="number">-1</span>, <span class="number">8</span>)  <span class="comment"># the size -1 is inferred from other dimensions</span></span><br><span class="line">z.size()</span><br><span class="line"><span class="comment">### torch.Size([2, 8])</span></span><br></pre></td></tr></table></figure><p>torch.view() doesn’t change the data. torch.resize() may change the data.</p><p>torch.unsqueeze(input, dim, out=None) insert a dimension at specified dimension. Negative dimension means the dimension is counted backward.</p><p>Converting a Torch Tensor to a NumPy Array</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">b = a.numpy()</span><br></pre></td></tr></table></figure><p>Converting NumPy Array to Torch Tensor</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">b = torch.from_numpy(a)</span><br></pre></td></tr></table></figure><p>Tensors can be moved onto any device using the .to method.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x = x.to(device)</span><br></pre></td></tr></table></figure><p>torch.Tensor is the central class of the package. If you set its attribute .requires_grad as True, it starts to track all operations on it. When you finish your computation you can call .backward() and have all the gradients computed automatically. The gradient for this tensor will be accumulated into .grad attribute.</p><p>To stop a tensor from tracking history, you can call .detach() to detach it from the computation history, and to prevent future computation from being tracked.</p><p>To prevent tracking history (and using memory), you can also wrap the code block in with torch.no_grad():. This can be particularly helpful when evaluating a model because the model may have trainable parameters with requires_grad=True, but for which we don’t need the gradients.</p><p>Each tensor has a .grad_fn attribute that references a Function that has created the Tensor</p><p>Gradient in Pytorch is accumulated. use .zero_grad() to clear gradient.</p><p>dtype=torch.long is for integers.</p><p>Input to Pytorch must in batch. X with shape (N-sample,……)</p><p>torch.nn only supports mini-batches. The entire torch.nn package only supports inputs that are a mini-batch of samples, and not a single sample.</p><p>For example, nn.Conv2d will take in a 4D Tensor of n Samples x n Channels x Height x Width.</p><p>If you have a single sample, just use input.unsqueeze(0) to add a fake batch dimension.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torchvision.datasets.ImageFolder(root=data_path,transform=torchvision.transforms.ToTensor())</span><br></pre></td></tr></table></figure><p>Transform image dataset to tensors. Foldeds’ names are classes.</p><p>Display an image in pytorch: </p><ul><li>transform the array</li><li>transform to numpy array</li><li>display</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> im <span class="keyword">in</span> images:</span><br><span class="line">    new = transforms.ToPILImage()</span><br><span class="line">    pilima = new(im)</span><br><span class="line">    plt.imshow(np.array(pilima))</span><br></pre></td></tr></table></figure><p>Images in pytorch are arranged as (N,C,H,W).<br>Normal Images are (W,H,C).</p><p>nn.Sequential is a wrapper for constructing neural network conviniently.</p><p>Dimension specified as 0 but tensor has no dimensions. For CrossEntropyLoss, the target has to be one dimension tensor rather than just a value.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.utils.rnn.pack_padded_sequence()</span><br></pre></td></tr></table></figure><p>Pack the padded sequence. When calculating loss, we don’t want to calculate loss of token like <pad>. Pack the padded sequence would eliminate these tokens and calculate the loss.</pad></p><p>Example:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> torch.nn.utils.rnn <span class="keyword">import</span> pack_sequence</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a = torch.tensor([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b = torch.tensor([<span class="number">4</span>,<span class="number">5</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>c = torch.tensor([<span class="number">6</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>pack_sequence([a, b, c])</span><br><span class="line">PackedSequence(data=tensor([ <span class="number">1</span>,  <span class="number">4</span>,  <span class="number">6</span>,  <span class="number">2</span>,  <span class="number">5</span>,  <span class="number">3</span>]), batch_sizes=tensor([ <span class="number">3</span>,  <span class="number">2</span>,  <span class="number">1</span>]))</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.numel(input)</span><br></pre></td></tr></table></figure><p>return the total number of elements in the input tensor.</p>]]></content>
      
      
        <tags>
            
            <tag> DL </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Deep_Learning</title>
      <link href="/2018/07/31/Deep-Learning/"/>
      <url>/2018/07/31/Deep-Learning/</url>
      <content type="html"><![CDATA[<h2 id="multi-class-classification-problem"><a href="#multi-class-classification-problem" class="headerlink" title="multi-class classification problem"></a>multi-class classification problem</h2><p>Solutions:</p><ul><li>Train multiple classifiers and predict the label one by ont</li><li>Learn the representation and compare. (clustering, or simply compare distance)</li></ul><p>Training step is actually a mini-batch. An epoch is the entire training set.</p><h2 id="Notes"><a href="#Notes" class="headerlink" title="Notes"></a>Notes</h2><p>Before training, calculate the memory consumption of the neural network and make sure the GPU has enough memory.</p>]]></content>
      
      
        <tags>
            
            <tag> DL </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>feature_selection</title>
      <link href="/2018/07/30/feature-selection/"/>
      <url>/2018/07/30/feature-selection/</url>
      <content type="html"><![CDATA[<h2 id="Mutual-Information"><a href="#Mutual-Information" class="headerlink" title="Mutual Information"></a>Mutual Information</h2><p>$$I(x,y)=\sum_{x\in {0,1}} \sum_{y\in {0,1}} p(x,y)\log_2\frac{P(x, y)}{p(x)p(y)}$$</p><p>This could be used as the heuristic of feature selection. Higher mutual information means the feature do relates to the class, which is helpful in classfication.</p><h2 id="chi-squared-test"><a href="#chi-squared-test" class="headerlink" title="chi-squared test"></a>chi-squared test</h2><p>$$X^2(D,t,c)=\sum_{e_t\in {0,1}} \sum_{e_c\in {0,1}} \frac{(N_{e_te_c}-E_{e_te_c})^2}{E_{e_te_c}}$$</p><p>N is the observed frequency in D and E the expected frequency. </p><p>chi-squared test is a measure of how much expected counts E and observed counts N deviate from each other. A high value indicates that the hypothesis of independence is incorrect.</p><h4 id="Problems"><a href="#Problems" class="headerlink" title="Problems"></a>Problems</h4><p>For a test with one degree of freedom, the so-called Yates correction should be used, which makes it harder to reach statistical significance. <strong>degree of freedom</strong> = (num of columns -1) * (num of rows -1)</p><p>Also, whenever a statistical test is used multiple times, then the probability of getting at least one error increases. If 1,000 hypotheses are rejected, each with 0.05 error probability, then 0.05 × 1000 = 50 calls of the test will be wrong on average. </p><h2 id="Frequency-based-feature-selection"><a href="#Frequency-based-feature-selection" class="headerlink" title="Frequency-based feature selection"></a>Frequency-based feature selection</h2><p>select the feature that occurs usually. When many thousands of features are selected, then frequency-based feature selection often does well.</p><h2 id="Feature-selection-for-multiple-classifiers"><a href="#Feature-selection-for-multiple-classifiers" class="headerlink" title="Feature selection for multiple classifiers"></a>Feature selection for multiple classifiers</h2><p>Commonly, feature selection statistics are first computed separately for each class on the two-class classification task c versus not c and then combined. </p><p>One combination method computes a single figure of merit for each feature, for example, by averaging the values A(t, c) for feature t, and then selects the k features with highest figures of merit.</p><p>Another frequently used combination method selects the top k/n features for each of n classifiers and then combines these n sets into one global feature set.</p><h2 id="Comparison-of-feature-selection-methods"><a href="#Comparison-of-feature-selection-methods" class="headerlink" title="Comparison of feature selection methods"></a>Comparison of feature selection methods</h2><p>Mutual information prefer common terms while chi-squared test prefer rare terms. Because A single occurrence is not very informative according to the information-theoretic definition of information.</p><p>All three methods are greedy methods.</p>]]></content>
      
      
        <tags>
            
            <tag> NLP </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Boosting</title>
      <link href="/2018/07/28/Boosting/"/>
      <url>/2018/07/28/Boosting/</url>
      <content type="html"><![CDATA[<h2 id="Bagging"><a href="#Bagging" class="headerlink" title="Bagging"></a>Bagging</h2><p>For each trial 1,2…T, a training set of size N(identical to the size of the original training set) is sampled(with replacement) from the original training set.</p><p>Each trial a classifier \(C^t\) is trained. The final classifier \(C^*\) aggregate those T classfiers together.</p><p>To classify an instance x, a vote for class k is recorded by every classier for which \(C^t(x)=k\) and \(C^*(x)\) is then the class with the most votes. (Ties being resolve arbitrarily)</p><p>An <strong>order􏲵-correct</strong> classifier-learning system is one that􏲬 over many training sets􏲬 tends to predict the correct class of a test instance more frequently than any other class􏲮.</p><p>Aggre􏲵gating classifiers produced by an order-correct learner results in an optimal classi􏲻er</p><p><strong>Requirement of bagging</strong>:each single classifier is unstable – that is, it has high variance, small change to the training set leads to different classifiers.</p><h2 id="Boosting"><a href="#Boosting" class="headerlink" title="Boosting"></a>Boosting</h2><p>Intuition of Boosting: Train several weak classifier and combine together to get a strong classifier.</p><h3 id="AdaBoost"><a href="#AdaBoost" class="headerlink" title="AdaBoost"></a>AdaBoost</h3><p>Usually employed in classification problem</p><p>Step:</p><ul><li>Initially, each training sample is assigned an equal weight. </li><li>Train a classifier on the training set</li><li>Compute the error rate</li><li>Compute the coefficient of the classifier</li><li>Change the weight of the training samples. Increase the weights of the samples that are classified wrong, pay more attention to them. Decrease the weights of the samples that are classified correct. Here the calculation of the new weight is actually a softmax to make the weight a probability distribution.</li><li>Train another classifier on the training set with new weight and repeat the above several steps.</li><li>Finally, combine the classifiers.</li></ul><p>The output of the final classifiers(absolute value) is the confidence level of the classfication result. More iterations, higher confidence level.</p><p>AdaBoost could be viewed as forward stagewise algorithm which optimize the set os parameters step by step.</p><h4 id="Toy-Model"><a href="#Toy-Model" class="headerlink" title="Toy Model"></a>Toy Model</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">smaller_than</span><span class="params">(x,y)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> y-x &gt; <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">classifier</span><span class="params">(x, v, flag=<span class="number">1</span>)</span>:</span>   <span class="comment">#threshold v</span></span><br><span class="line">    <span class="string">'''flag = 1: x&lt;v are classified as 1, x&gt;v are classified as -1</span></span><br><span class="line"><span class="string">       flag = 0: x&lt;v are classified as -1, x&gt;v are classified as 1'''</span></span><br><span class="line">    threshold = int(np.floor(v)+<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">if</span> flag == <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">if</span> threshold &lt;= <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span> -np.ones(x.shape)</span><br><span class="line">        <span class="keyword">elif</span> threshold &gt; <span class="number">9</span>:</span><br><span class="line">            <span class="keyword">return</span> np.ones(x.shape)</span><br><span class="line">        x[:threshold] = <span class="number">1</span></span><br><span class="line">        x[threshold:] = <span class="number">-1</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">if</span> threshold &lt;= <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span> np.ones(x.shape)</span><br><span class="line">        <span class="keyword">elif</span> threshold &gt; <span class="number">9</span>:</span><br><span class="line">            <span class="keyword">return</span> -np.ones(x.shape)</span><br><span class="line">        x[:threshold] = <span class="number">-1</span></span><br><span class="line">        x[threshold:] = <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">find_best_split</span><span class="params">(x,y,weight)</span>:</span></span><br><span class="line">    error = <span class="number">1</span></span><br><span class="line">    best_result = <span class="keyword">None</span></span><br><span class="line">    best_classifier = <span class="keyword">None</span></span><br><span class="line">    <span class="keyword">for</span> f <span class="keyword">in</span> range(<span class="number">2</span>):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(x.shape[<span class="number">0</span>]+<span class="number">1</span>):</span><br><span class="line">            r = classifier(np.array(x,copy=<span class="keyword">True</span>),j<span class="number">-0.5</span>,f)</span><br><span class="line">            <span class="comment"># print("j", j)</span></span><br><span class="line">            <span class="comment"># print("classify_result", r)</span></span><br><span class="line">            p_error = np.sum((r!=y)*weight)<span class="comment"># /float(len(x))</span></span><br><span class="line">            <span class="comment"># print("p_error", p_error)</span></span><br><span class="line">            <span class="comment"># if p_error &lt; error:</span></span><br><span class="line">            <span class="comment"># if np.log(p_error)-np.log(error) &lt; 0:</span></span><br><span class="line">            <span class="keyword">if</span> smaller_than(p_error,error):     <span class="comment">#for the sake of numerical stability</span></span><br><span class="line">                error = p_error</span><br><span class="line">                best_result = np.array(r, copy=<span class="keyword">True</span>)</span><br><span class="line">                best_classifier = (j<span class="number">-0.5</span>, f)</span><br><span class="line">            <span class="comment"># print("best_result_123", best_result)</span></span><br><span class="line">            <span class="comment"># print("error_123", error)</span></span><br><span class="line">    <span class="comment"># print("best_result_123", best_result)</span></span><br><span class="line">    <span class="comment"># print("error_123", error)</span></span><br><span class="line">    <span class="keyword">return</span> best_result, error, best_classifier</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line"></span><br><span class="line">    x = np.arange(<span class="number">10</span>)</span><br><span class="line">    y = np.array([<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">-1</span>,<span class="number">-1</span>,<span class="number">-1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">-1</span>])</span><br><span class="line">    iterations = <span class="number">10</span></span><br><span class="line">    weight = np.ones((x.shape)) / float(len(x))</span><br><span class="line">    coefficient_l = []</span><br><span class="line">    c_l = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(iterations):</span><br><span class="line">        best_result, error, best_classifier = find_best_split(np.array(x,copy=<span class="keyword">True</span>),y,weight)</span><br><span class="line">        c_l.append(best_classifier)</span><br><span class="line">        <span class="comment"># print("best_result", best_result)</span></span><br><span class="line">        <span class="comment"># print("error", error)</span></span><br><span class="line">        alpha = <span class="number">1</span>/<span class="number">2.0</span> * np.log((<span class="number">1</span>-error)/error)</span><br><span class="line">        coefficient_l.append(alpha)</span><br><span class="line">        numerator = np.exp(-alpha*y*best_result)</span><br><span class="line">        denominator_weight = np.sum(weight * numerator)</span><br><span class="line">        <span class="comment"># print("weight ", weight)</span></span><br><span class="line">        weight = weight * numerator/ denominator_weight</span><br><span class="line">        <span class="comment"># print("weight_updated ", weight)</span></span><br><span class="line">    <span class="comment"># print(coefficient_l)</span></span><br><span class="line"></span><br><span class="line">    <span class="string">'''Final classifier'''</span></span><br><span class="line">    final_error = <span class="keyword">None</span></span><br><span class="line">    final_result = np.zeros(x.shape)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(c_l)):</span><br><span class="line">        final_result += coefficient_l[i]*classifier(np.array(x,copy=<span class="keyword">True</span>),</span><br><span class="line">                                                    v=c_l[i][<span class="number">0</span>],flag=c_l[i][<span class="number">1</span>])</span><br><span class="line">    print(final_result)</span><br><span class="line">    final_result[final_result&gt;<span class="number">0</span>]=<span class="number">1</span></span><br><span class="line">    final_result[final_result&lt;<span class="number">0</span>] = <span class="number">-1</span></span><br><span class="line">    final_error = np.sum(final_result!=y)/float(len(x))</span><br><span class="line">    print(final_error)</span><br></pre></td></tr></table></figure><h3 id="Boosting-Tree"><a href="#Boosting-Tree" class="headerlink" title="Boosting Tree"></a>Boosting Tree</h3><p>When ths base classifier is the base function, boosting is named boosting tree.</p><h3 id="Gradient-Boosting"><a href="#Gradient-Boosting" class="headerlink" title="Gradient Boosting"></a>Gradient Boosting</h3><p>It is not easy to optimize normal loss function for boosting tree. Gradient boosting is employed to solve this problem.<br>For regression problem, utilize the the negative gradient of the loss function to approximate the residual error so as to approximate a boosting tree.</p><h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p><a href="https://pdfs.semanticscholar.org/79ea/6a5a68e05065f82acd11a478aa7eac5f6c06.pdf" target="_blank" rel="noopener">Bagging􏰀 Boosting􏰀 and C4.5􏰁􏰂􏰃</a></p><p><a href="http://net.pku.edu.cn/~course/cs410/2015/resource/book/2012-book-StatisticalLearning-LH.pdf" target="_blank" rel="noopener">统计学习方法</a></p>]]></content>
      
      
        <tags>
            
            <tag> ML </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Word_Vectors</title>
      <link href="/2018/07/28/WordVectors/"/>
      <url>/2018/07/28/WordVectors/</url>
      <content type="html"><![CDATA[<p>The gradient of the whole word matrix(context matrix) should be outer product rather than normal inner product because their dimensions are not matched.</p><h1 id="Two-types-of-word-vectors"><a href="#Two-types-of-word-vectors" class="headerlink" title="Two types of word vectors"></a>Two types of word vectors</h1><ul><li>count-based: LSA, LDA, Glove</li><li>window-based: word2vec</li></ul><p>Drawback of count-based method:</p><ul><li>unstable, may change if there is a new word.</li><li>high dimension \(V \times V\) although dimension could be decreased by SVD.</li></ul><p>Word vectors are application-specific.</p><h2 id="Word2vec"><a href="#Word2vec" class="headerlink" title="Word2vec"></a>Word2vec</h2><p>Input vectors are also named context vectors.<br>Output vectors are also named word vectors.</p><h3 id="Feedforward-Neural-Net-Language-Model-NNLM"><a href="#Feedforward-Neural-Net-Language-Model-NNLM" class="headerlink" title="Feedforward Neural Net Language Model (NNLM)"></a>Feedforward Neural Net Language Model (NNLM)</h3><p>Time complexity:<br>Q = N × D + N × D × H + H × V, where the dominating term is H × V.</p><p>N are the N input examples, D is the dimensionality of the word vectors, H is the hidden layer size, V is the vocab size.</p><p>With binary tree representations of the vocabulary, the number of output units that need to be evaluated can go down to around log2(V). Thus, most of the complexity is caused by the term N × D × H.</p><p>Huffman trees assign short binary codes to frequent words, and this further reduces the number of output units that need to be evaluated: while balanced binary tree would require log2(V) outputs to be evaluated, the Huffman tree based hierarchical softmax requires only about log2(Unigram perplexity(V)).</p><h3 id="Continuous-Bag-of-Words-Model-CBOW"><a href="#Continuous-Bag-of-Words-Model-CBOW" class="headerlink" title="Continuous Bag-of-Words Model(CBOW)"></a>Continuous Bag-of-Words Model(CBOW)</h3><p>Given context words, predict the central words. Average the input word vectors, which ignore the order of words, and then predict the output word.</p><p>The training complexity of this architecture is proportional to</p><p>Q = N × D + D × log2(V ).</p><p>C is the context size.</p><p>The order of words in the history and future does not influence the projection, like bag-of-words model.</p><p>Note that the weight matrix between the input and the projection layer is shared for all word positions in the same way as in the NNLM. Here the weight matrix are the word vectors.</p><h3 id="Continuous-Skip-gram-Model"><a href="#Continuous-Skip-gram-Model" class="headerlink" title="Continuous Skip-gram Model"></a>Continuous Skip-gram Model</h3><p>Similar to CBOW, in this model, input the central word and predict the context words, others are the same. This is a </p><p>The training complexity of this architecture is proportional to</p><p>Q = C × (D + D × log2(V ))</p><p>where C is the maximum distance of the words. For each training word we will select randomly a number R in range &lt; 1; C &gt;, and then use R words from history and R words from the future of the context as correct labels. This will require us to do R × 2 word classifications, with the current word as input, and each of the R + R words as output. </p><p>increasing the context size C improves quality of the resulting word vectors, but it also increases the computational complexity. </p><p>Since the more distant words are usually less related to the current word than those close to it, we give less weight to the distant words by sampling less from those words in our training examples. 2 <em> R words which is less than C are used as correct label. this step contains sampling 2 </em> R words from C word. </p><p>There are two kinds of vectors for each word. They are context vectors and word vectors respectively. Normally the final word vectors could be the sum of two vectors or simply the word vector.</p><h3 id="Modification"><a href="#Modification" class="headerlink" title="Modification"></a>Modification</h3><p>In skip-gram and CBOW, softmax is extremely expensive.</p><p>Take skip-gram as an example. The objective is to maximize the following ojective function:</p><p>$$\frac{1}{T}\sum_{t=1}^{T}\sum_{-c\leq{j}\leq{c},j\neq0}\log p(w_{t+j}|w_t)$$</p><p>where c is the size of the training context.</p><p>The p is defined as :</p><p>$$p(o|c)=\frac{exp(<br>{u_o}^Tv_{c})}{\sum_{w=1}^{W}exp({u_{w}}^T*v_{c})}$$</p><p>which is an expensive softmax function to squeeze all the values into a probability distribution.</p><h4 id="2-choices-to-improve-softmax"><a href="#2-choices-to-improve-softmax" class="headerlink" title="2 choices to improve softmax"></a>2 choices to improve softmax</h4><h5 id="Hierarchical-Softmax"><a href="#Hierarchical-Softmax" class="headerlink" title="Hierarchical Softmax"></a>Hierarchical Softmax</h5><p>Turn all words into a tree so that the height of tree is log2(V).</p><h5 id="Negative-Sampling"><a href="#Negative-Sampling" class="headerlink" title="Negative Sampling"></a>Negative Sampling</h5><p>Noise Contrastive Estimation (NCE) states that a good model is able to differentiate data from noise by means of logistic regression.</p><p>The skip-gram model only focus on leanring good word vectors.</p><p>Here the noise is words that are outside of the context.</p><p>Simplified version of NCE:</p><p>$$\log\sigma{({u_o}^Tv_{c})}+\sum_{i=1}^k E_{j\sim P_n(w)}\log\sigma{(-{u_j}^Tv_{c})}$$</p><p>$$P_n(w_i) = \frac{  {f(w_i)}^{3/4}  }{\sum_{j=0}^{n}  {f(w_j)}^{3/4}}$$</p><p>where n is total number of words in the corpus.</p><h4 id="Subsampling-of-Frequent-Words"><a href="#Subsampling-of-Frequent-Words" class="headerlink" title="Subsampling of Frequent Words"></a>Subsampling of Frequent Words</h4><p>The frequent words may contain less information. During training, it would discard words in the context by chance using the below formula</p><p>$$P(w_i)=1-\sqrt{\frac{t}{f(w_i)}} $$</p><p>In the implementation code, the formula is</p><p>$$P(w_i) = (\sqrt{\frac{z(w_i)}{0.001}} + 1) \cdot \frac{0.001}{z(w_i)}$$</p><h2 id="Glove"><a href="#Glove" class="headerlink" title="Glove"></a>Glove</h2><p>Utilize statistical information in co-occurrence matrix.</p><p>Utilize a third word to determine whether two words are related or not. If two words are not correlated,</p><p>$$\frac{P_{ik}}{P_{jk}} \approx 1$$</p><p>where \(P_{ik}\) is conditional probability \(P(k|i)\).</p><p>The objective is to find a function to represent the relationship between word vectors and conditional probability.</p><p>$$F(w_i,w_j,\tilde{w}<em>k)=\frac{P</em>{ik}}{P_{jk}}$$</p><p>The function F has to satisfy certain requirements:</p><ol><li>preserve linear structure</li><li>exchangeable</li></ol><p>Finally, weight counts because rare co- occurrences may carry less information.</p><p>$$J(\theta)=\frac{1}{2}\sum_{i,j=1}^{W}f(P_{ij})(u_i^Tv_j-log P_{ij})^2$$</p><h2 id="FastText"><a href="#FastText" class="headerlink" title="FastText"></a>FastText</h2><p>It is a model derived from word2vec. In order to better represent morphological words, each word is now represent by a set of n-gram characters. Each word is added two symbols ‘&lt;’ and ‘&gt;’ respectively to indicate start and end of the word.</p><p>For example, word ‘FastText’ becomes word ‘<fasttext>‘. 3-gram set is (&lt;Fa,Fas,ast,stT,tTe,Tex,ext,xt&gt;).</fasttext></p><p>Negetive sampling of word2vec:</p><p>$$\log\sigma{({u_o}^Tv_{c})}+\sum_{i=1}^k E_{j\sim P_n(w)}\log\sigma{(-{u_j}^Tv_{c})}$$</p><p>In word2vec, each word is an unique unit. Each word has the unique word vectors representation which lose the morphological information. In FastText, subword model is employed, in which each word is now represent by a set of n-gram characters to utilize morphological information.</p><p>The objective function is:</p><p>$$\log\sigma{(\sum_{g\in G_{o}}{z_g}^Tv_{c})}+\sum_{i=1}^k E_{j\sim P_n(w)}\log\sigma{(-\sum_{g\in G_{j}}{z_{gj}}^Tv_{c})}$$</p><p>where \(G_{o}\) is the set of n-grams character of word \(w_o\), \(z_{g}\) is the vector representation of the specific n-gram characters. </p><p>$$u_o = \sum_{g\in G_{o}}{z_g}$$</p><p>The word vector for each word is then the sum of its all n-gram vector representation.</p><h2 id="WordRank"><a href="#WordRank" class="headerlink" title="WordRank"></a>WordRank</h2><p>Turn the problem into a ranking problem.</p><h2 id="Character-level-embedding"><a href="#Character-level-embedding" class="headerlink" title="Character-level embedding"></a>Character-level embedding</h2><p>Advantages:</p><ul><li>better in terms of morphological languages</li><li>In some languages such as Chinese, each sentence is composed of characters directly. Character-level embedding is also better in this case.</li><li>OOV(out of vocabulary words). Able to handle OOV.</li></ul><h4 id="OOV-Handling"><a href="#OOV-Handling" class="headerlink" title="OOV Handling"></a>OOV Handling</h4><ul><li>Character-level embedding</li><li>Initialize the unknown word as the sum of all context vectors and refine it with a high learning rate</li></ul>]]></content>
      
      
        <tags>
            
            <tag> NLP </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>python</title>
      <link href="/2018/07/26/python/"/>
      <url>/2018/07/26/python/</url>
      <content type="html"><![CDATA[<h3 id="Dictionary"><a href="#Dictionary" class="headerlink" title="Dictionary"></a>Dictionary</h3><p>Find the key that has the largest value in a dictionary.</p><p>Assume stats is the dictionary.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">max(stats, key=stats.get)</span><br><span class="line"></span><br><span class="line">max_key = max(stats, key=lambda k: stats[k])</span><br></pre></td></tr></table></figure><p>map dictionary:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">my_dictionary = dict(map(lambda kv: (kv[0], f(kv[1])), my_dictionary.items()))</span><br></pre></td></tr></table></figure></p><p>build a dictionary with the same key from the other dictionary.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">d = dic.fromkeys(dic.keys(), 0)</span><br></pre></td></tr></table></figure><p>Since in python every thing is reference, for variable instances like list array, normal assign symbol ‘=’ would add a new reference to the instance. If the value of the instance is changed, it would affect other usage.</p><p>For example:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">l1 = [1,2,3]</span><br><span class="line">l2 = l1</span><br><span class="line">l2[2] = 100</span><br></pre></td></tr></table></figure></p><p>Now l1[2] is also 100.</p><p>solution:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">l1 = [1,2,3]</span><br><span class="line">l2 = copy.deepcopy(l1)</span><br><span class="line">l2[2] = 100</span><br></pre></td></tr></table></figure></p><p>Now l1[2] is still 3.</p><p>or<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">l2 = list(l1)</span><br></pre></td></tr></table></figure></p><p>A shallow copy constructs a new compound object and inserts references into it to the objects found in the original.<br>A deep copy constructs a new compound object and then, recursively, inserts copies into it of the objects found in the original.</p><p>from pip import main<br>ImportError: cannot import name main</p><p>solution: Roll back</p><p>python3 -m pip install –user –upgrade pip==9.0.3</p><p>assert condition is True, or else print the string.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">assert</span> condition, <span class="string">'.....'</span></span><br></pre></td></tr></table></figure><p>Decimal, Octal, Hexadecimal, Binary</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">oct()</span><br><span class="line">hex()</span><br><span class="line">bin()</span><br></pre></td></tr></table></figure><p>convert jupyter notebook to python file:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jupyter nbconvert --to script [YOUR_NOTEBOOK].ipynb</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">getattr(x,foo)</span><br></pre></td></tr></table></figure><p>is the same as x.foo. get the attribute named foo of x.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">__file__</span><br></pre></td></tr></table></figure><p>is only available in running in command line mode. Not available in interactive mode like Jupyter.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">os.path.expanduser(path)</span><br></pre></td></tr></table></figure><p>turn “~” into home directory</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">zip(*iterables)</span><br></pre></td></tr></table></figure><p>Make an iterator that aggregates elements from each of the iterables.</p><p><code>*l</code> idiom is to <strong>unpack argument lists</strong> when calling a function 解包列表中的变量传递给函数</p>]]></content>
      
      
        <tags>
            
            <tag> Programming </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Linear_Algebra</title>
      <link href="/2018/07/26/Linear-Algebra/"/>
      <url>/2018/07/26/Linear-Algebra/</url>
      <content type="html"><![CDATA[<p>By default, vectors are column vectors.</p><h4 id="Outer-Product"><a href="#Outer-Product" class="headerlink" title="Outer Product"></a>Outer Product</h4><p>\(<br>\left(\begin{array}{cc}<br>{1} \\ {2}<br>\end{array}\right) \) \(\otimes\) \(<br>\left(\begin{array}{cc}<br>10 &amp; 20<br>\end{array}\right)<br>\) = \(  \left(\begin{array}{cc}<br>{1 \times 10} &amp; {1 \times 20} \\ {2 \times 10} &amp; {2 \times 20}<br>\end{array}\right)  \)</p><p>Outer product increase the dimension of the matrix. Outer product of a (a1∗a2) matrix and  a (b1∗b2) matrix is a (a1∗a2)∗(b1∗b2) matrix.</p><p>$$\begin{array} \<br>x \otimes y<br>&amp; = \begin{bmatrix}<br>x_1 &amp; \cdots &amp; x_{1n} \\<br>x_2 &amp; \cdots &amp; x_{2n} \\<br>\cdots &amp; \cdots &amp; \cdots \\<br>x_m &amp; \cdots &amp; x_{mn}<br>\end{bmatrix}<br>\begin{bmatrix}<br>y_1 &amp; \cdots &amp; y_{1q} \\<br>y_2 &amp; \cdots &amp; y_{2q} \\<br>\cdots &amp; \cdots &amp; \cdots \\<br>y_p &amp; \cdots &amp; x_{pq}<br>\end{bmatrix} \<br>&amp; =<br>\begin{bmatrix}<br>x_1y_1 &amp; \cdots &amp; x_1y_{1q} &amp; x_1y_{2} &amp; \cdots &amp; x_1y_{pq} \\<br>\cdots &amp; \cdots &amp; \cdots &amp; \cdots &amp; \cdots &amp; \cdots \\<br>x_{1n}y_1 &amp; \cdots &amp; x_{1n}y_{1q} &amp; x_{1n}y_{2} &amp; \cdots &amp; x_{1n}y_{pq} \\<br>x_2y_1 &amp; \cdots &amp; x_2y_{1q} &amp; x_2y_{2} &amp; \cdots &amp; x_2y_{pq} \\<br>\cdots &amp; \cdots &amp; \cdots &amp; \cdots &amp; \cdots &amp; \cdots \\<br>x_{mn}y_1 &amp; \cdots &amp; x_{mn}y_{1q} &amp; x_{mn}y_{2} &amp; \cdots &amp; x_{mn}y_{pq}<br>\end{bmatrix}<br>\end{array}$$</p><h4 id="Element-wise-Product-Hadamard-product"><a href="#Element-wise-Product-Hadamard-product" class="headerlink" title="Element-wise Product  (Hadamard product)"></a>Element-wise Product  (Hadamard product)</h4><p>$$\begin{array} \<br>x \otimes y<br>&amp; = \begin{bmatrix}<br>x_1 &amp; \cdots &amp; x_{1n} \\<br>x_2 &amp; \cdots &amp; x_{2n} \\<br>\cdots &amp; \cdots &amp; \cdots \\<br>x_m &amp; \cdots &amp; x_{mn}<br>\end{bmatrix}<br>\begin{bmatrix}<br>y_1 &amp; \cdots &amp; y_{1n} \\<br>y_2 &amp; \cdots &amp; y_{2n} \\<br>\cdots &amp; \cdots &amp; \cdots \\<br>y_m &amp; \cdots &amp; x_{mn}<br>\end{bmatrix} \<br>&amp; =<br>\begin{bmatrix}<br>x_1y_1 &amp; \cdots &amp; x_{1i}y_{1i} &amp; x_{1j}y_{1j} &amp; \cdots &amp; x_{1n}y_{1n} \\<br>\cdots &amp; \cdots &amp; \cdots &amp; \cdots &amp; \cdots &amp; \cdots \\<br>x_{m1}y_{m1} &amp; \cdots &amp; x_{mi}y_{mi} &amp; x_{mj}y_{mj} &amp; \cdots &amp; x_{mn}y_{mn}<br>\end{bmatrix}<br>\end{array}$$</p><p><strong>Example</strong><br>\(<br>\left(\begin{array}{cc}<br>1 &amp; 2 \\ 3 &amp; 4<br>\end{array}\right) \) \(\odot\) \(<br>\left(\begin{array}{cc}<br>10 &amp; 20 \\ 30 &amp; 40<br>\end{array}\right) \) = \(<br>\left(\begin{array}{cc}<br>{1 \times 10} &amp; {2 \times 20} \\ {3 \times 30} &amp; {4 \times 40}<br>\end{array}\right) \)</p><h4 id="Vector-Norm"><a href="#Vector-Norm" class="headerlink" title="Vector Norm"></a>Vector Norm</h4><p>L1 Norm: The sum of absolute values in the matrix. </p><p>$$\lVert w \rVert_1 = \textstyle \sum_{i=1}^n |w_i|$$</p><p>L2 Norm: The sqrt of the sum of squared values in the matrix. </p><p>$$\lVert w \rVert_2 = \sqrt {\textstyle \sum_{i=1}^n w_i^2}$$</p><h4 id="Matrix-Norm"><a href="#Matrix-Norm" class="headerlink" title="Matrix Norm"></a>Matrix Norm</h4><p>The spectral norm of a matrix A is the largest singular value of A.For example, the square root of the largest eigenvalue of the positive-semidefinite matrix \({\displaystyle A^{*}A}\).</p><h4 id="Identity-Matrix"><a href="#Identity-Matrix" class="headerlink" title="Identity Matrix"></a>Identity Matrix</h4><p>An identity matrix of size n is the n × n square matrix with ones on the main diagonal and zeros elsewhere.</p><p>$${ I_{n}={\begin{bmatrix}\ 1&amp;0&amp;0&amp;\cdots &amp;0\\ 0&amp;1&amp;0&amp;\cdots &amp;0\\ 0&amp;0&amp;1&amp;\cdots &amp;0\\ \vdots &amp;\vdots &amp;\vdots &amp;\ddots &amp;\vdots \\ 0&amp;0&amp;0&amp;\cdots &amp;1\end{bmatrix}}}$$</p><h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p><a href="https://www.cnblogs.com/steven-yang/p/6348112.html#%E7%9F%A9%E9%98%B5%E7%9A%84%E5%90%84%E7%A7%8D%E4%B9%98%E7%A7%AF" target="_blank" rel="noopener">机器学习中的基本数学知识</a></p><p><a href="https://en.wikipedia.org/wiki/Identity_matrix" target="_blank" rel="noopener">Identity matrix</a></p>]]></content>
      
      
    </entry>
    
    <entry>
      <title>Numpy</title>
      <link href="/2018/07/26/Numpy/"/>
      <url>/2018/07/26/Numpy/</url>
      <content type="html"><![CDATA[<p>numpy.ufunc.at. apply function at given index.</p><p>np.add.at(a, [0, 1, 2, 2], 1): add 1 to array a at index [0, 1, 2, 2]</p><p>numpy.random.permutation(x):Randomly permute a sequence, or return a permuted range. 即把一序列打成乱序输出</p><p>numpy.outer(a, b, out=None);Compute the outer product of two vectors.    </p><p>operator *: element-wise multuply</p><p>Axis = 0 is column. Axis = 1 is row</p><p>a[:6:2] means the first element of every two elements from 0 to 5</p><p>array dimension: count the bracket</p><p>flat attribute which is an iterator over all the elements of the array:</p><p>np.nditer(a, flags=[‘f_index’]) is used to iterate elements</p><p>access multiple columns elements: a[b,c] while b is from 0 to n, c shows in each line which element you want to access.</p><p><a href="https://docs.scipy.org/doc/numpy-dev/user/quickstart.html#indexing-slicing-and-iterating" target="_blank" rel="noopener">https://docs.scipy.org/doc/numpy-dev/user/quickstart.html#indexing-slicing-and-iterating</a></p><p>access nth column: a[:,n]</p><p>transpose an one-dimension array: a.reshape(n,len(a))</p><p>multi-dimensional array, count the dimension from low to high</p><p>np.argsort()Returns the indices that would sort an array.<br>numpy.bincount<br>Count number of occurrences of each value in array of non-negative ints.</p><p>Np.argmax()  Returns the indices of the maximum values along an axis.<br>Np.nonzero() return tuple that consists of arrays. The first array indicates dimension, the second one indicates location(index)</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a = np.array(x,copy=True)</span><br></pre></td></tr></table></figure><p>copy an array to a new variable. </p>]]></content>
      
      
    </entry>
    
    <entry>
      <title>Recurrent_Neural_Network</title>
      <link href="/2018/07/25/Recurrent-Neural-Network/"/>
      <url>/2018/07/25/Recurrent-Neural-Network/</url>
      <content type="html"><![CDATA[<p>Gradient vanishing or exploding:<br>Since the time step 1 would have effect on time step n, when doing back propagation, according to the chain rule, the same weight matrix W would be multiplied by n times which is W to the power of n. So the norm of W is greater than 1, there is gradient exploding. And vice versa, gradient vanishing if the norm of W is smaller than 1.</p><p>Solution to gradient vanishing:<br>Initialize weight matrix to identity matrix  rather than a matrix of random values. And use Relu as activation function. The intuition of this is to take average of input and hidden state. Then start to optimize the weight matrix.</p><h3 id="Attention-Model"><a href="#Attention-Model" class="headerlink" title="Attention Model"></a>Attention Model</h3><p>The input includes all or some of the hidden states in the encoder. Utilize a score function to weight importance of those hidden states and feed into the decoder with the input word.</p>]]></content>
      
      
        <tags>
            
            <tag> DL </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Tensorflow</title>
      <link href="/2018/07/23/Tensorflow/"/>
      <url>/2018/07/23/Tensorflow/</url>
      <content type="html"><![CDATA[<p>Characteristic: Lazy evaluation like scala</p><p>Two steps to build and run a model:</p><ul><li>assemble a graph</li><li>use a session to execute operations in the graph</li></ul><p>Placeholder: a node to store variable which would not be modified during backpropagation</p><p>Variable: a node that would be modified during backpropagation</p><p>Constant: values that cannot be changed</p><p>Running parts need to be encapsulated into session.run(). session.run() is evaluation of the graph.</p><p>Variables could have name and scope.</p><p>Use TF DType to accelerate the computation or tensorflow has to infer the type.</p><p>create variables with tf.get_variable</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">m = tf.get_variable(&quot;matrix&quot;, initializer=tf.constant([[0, 1], [2, 3]]))</span><br></pre></td></tr></table></figure><p>rather than </p><figure class="highlight m"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">Before running, variables need to be initialized.</span><br></pre></td></tr></table></figure><p>initializer = tf.global_variables_initializer()<br>with tf.Session() as sess:<br>    sess.run(initializer)<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">Initialize only a subset of variables:</span><br></pre></td></tr></table></figure></p><p>with tf.Session() as sess:<br>    sess.run([a,b])<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">Initialize only a single variable:</span><br></pre></td></tr></table></figure></p><p>m=tf.get_variable(“matrix”,initializer=tf.constant([[0, 1], [2, 3]]))<br>with tf.Session() as sess:<br>    sess.run(m.initializer)<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">W.assign(100) creates an assign operation that assign 100 to variable W. The operation needs to be executed in a session to take effect.</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">tensorflow separates definitions of computation and execution. It first assembles a graph. Second use a session to execute.</span><br><span class="line"></span><br><span class="line">Nodes are operators, variables, and constants</span><br><span class="line"></span><br><span class="line">Edges are tensors.</span><br><span class="line"></span><br><span class="line">A Session object encapsulates the environment in which Operation objects are executed, and Tensor objects are evaluated.  Session will also allocate memory to store the current values of variables.</span><br></pre></td></tr></table></figure></p><p>tf.Session.run(fetches,    feed_dict=None,    options=None,    run_metadata=None)<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">fetches is a list of tensors whose values you want. tensorflow would return the values you want and skip computing unnecessary values.</span><br><span class="line"></span><br><span class="line">Multiple graphs require multiple sessions, each will try to use all available resources by default</span><br><span class="line"></span><br><span class="line">why graphs:</span><br><span class="line">1. break computation to facilitate auto-differentiation.</span><br><span class="line">2. save computation. only compute necessary values</span><br><span class="line">3. easier to distribute</span><br><span class="line">4. ML models visulised as graphs</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Can&apos;t pass data between them without passing them through python/numpy, which doesn&apos;t work in distributed</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Create the summary writer after graph definition and before running your session.</span><br><span class="line"></span><br><span class="line">```python</span><br><span class="line"># The default path for saving event files is the same folder of this python file.</span><br><span class="line">tf.app.flags.DEFINE_string(</span><br><span class="line">&apos;log_dir&apos;, os.path.dirname(os.path.abspath(__file__)) + &apos;/logs&apos;,</span><br><span class="line">&apos;Directory where event logs are written to.&apos;)</span><br><span class="line"></span><br><span class="line"># Store all elements in FLAG structure!</span><br><span class="line">FLAGS = tf.app.flags.FLAGS</span><br><span class="line"></span><br><span class="line">with tf.Session() as sess:</span><br><span class="line">    sess.run(tf.global_variables_initializer())</span><br><span class="line">    writer = tf.summary.FileWriter(os.path.expanduser(FLAGS.log_dir), sess.graph)</span><br><span class="line">    .....</span><br><span class="line"># Closing the writer.</span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure></p><p>These codes are used to specify the path of logs directory and store all elements in FLAG structure.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># clean flag name</span></span><br><span class="line"><span class="keyword">from</span> absl <span class="keyword">import</span> flags</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> name <span class="keyword">in</span> list(flags.FLAGS):</span><br><span class="line">  delattr(flags.FLAGS, name)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">UnrecognizedFlagError: Unknown command line flag <span class="string">'f'</span></span><br></pre></td></tr></table></figure><p>To solve this problem, just add a flag. In coommand line, there is not such a problem.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.app.flags.DEFINE_string(<span class="string">'f'</span>, <span class="string">''</span>, <span class="string">'kernel'</span>)</span><br></pre></td></tr></table></figure></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.app.flags.DEFINE_string(&apos;str_name&apos;, &apos;def_v_1&apos;,&quot;descrip1&quot;)</span><br></pre></td></tr></table></figure><p>tf.app.flags is used to assign a name to a variable and parse variables in command line. The first argument is the variable name. The second argument is the default value. The third argument is a description. argparse module in python could also be employed to parse arguments.</p><p>Any evaluation of variable must be run in a session.</p><p>Three ways to initialize variables:</p><ol><li>Initializing Specific Variables.</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># &quot;variable_list_custom&quot; is the list of variables that we want to initialize.</span><br><span class="line">variable_list_custom = [weights, custom_variable]</span><br><span class="line"></span><br><span class="line"># The initializer</span><br><span class="line">init_custom_op = tf.variables_initializer(var_list=all_variables_list)</span><br></pre></td></tr></table></figure><p>This enable us to initialize specific variables. We are supposed to initialize all variables after specific initialization.</p><ol start="2"><li>Global variable initialization. This operation has to be done after the construction of a model.</li><li>Initialization of a variables using other existing variables. New variables can be initialized using other existing variables’ initial values by taking the values using initialized_value().<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create another variable with the same value as 'weights'.</span></span><br><span class="line">WeightsNew = tf.Variable(weights.initialized_value(), name=<span class="string">"WeightsNew"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Now, the variable must be initialized.</span></span><br><span class="line">init_WeightsNew_op = tf.variables_initializer(var_list=[WeightsNew])</span><br></pre></td></tr></table></figure></li></ol><p>tf.one_hot() The axis argument determines which axis is the one-hot vector. </p><p>Name scope is for grouping nodes together to facilitate visulisation in Tensorboard. Name scope is for reusing of operations while variable scope is for reusing of variables. </p><p>Name scope is able to assign names to a set of variables. It is equivalent to add “name_scope/” to the variable name as prefix.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">with tf.name_scope(&quot;outer&quot;):  c_2 = tf.constant(2, name=&quot;c&quot;)  # =&gt; operation named &quot;outer/c&quot;</span><br></pre></td></tr></table></figure><p>An <code>Operation</code> is a node in a TensorFlow <code>Graph</code> that takes zero or more <code>Tensor</code> objects as input, and produces zero or more <code>Tensor</code> objects as output. Objects of type <code>Operation</code> are created by calling a Python op constructor (such as [<code>tf.matmul</code>] or [<code>tf.Graph.create_op</code>].</p><p>A <code>Tensor</code> is a symbolic handle to one of the outputs of an <code>Operation</code>. It does not hold the values of that operation’s output, but instead provides a means of computing those values in a TensorFlow [<code>tf.Session</code>].</p><p>Note that [<code>tf.Tensor</code>] objects are implicitly named after the [<code>tf.Operation</code>]that produces the tensor as output. A tensor name has the form <code>&quot;&lt;OP_NAME&gt;:&lt;i&gt;&quot;</code>.</p><p>tf.get_variable would search the variable with the given name. If there is not such a variable, it would create a new variable.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.reduce_mean()</span><br></pre></td></tr></table></figure><p>Sum over a vector in a particular dimension and compute the mean. The axis argument is used to specify the particular dimension.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.nn.softmax_cross_entropy_with_logits_v2()</span><br></pre></td></tr></table></figure><p>Take unscaled log probabilities as input and perform softmax. After that, compute cross entropy loss. This functino allows gradient to backpropagated to labels.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.cast()</span><br></pre></td></tr></table></figure><p>Casts a tensor to a new type.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x = tf.constant([1.8, 2.2], dtype=tf.float32)tf.cast(x, tf.int32)  # [1, 2], dtype=tf.int32</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tf.Graph().as_default():</span><br><span class="line">  ...</span><br></pre></td></tr></table></figure><p>There is a default graph in tensorflow. All operations and variables are added to the graph if not specified. This line of code use another graph and add variables to that graph. Outside the code block, variables would be added to the default graph.</p><p> TensorFlow will create a new [<code>tf.Tensor</code>]each time you use the same tensor-like object. If the tensor-like object is large (e.g. a <code>numpy.ndarray</code> containing a set of training examples) and you use it multiple times, you may run out of memory.</p><p>By default, tf.Session is bounded to the default graph. If there is multiple graphs, specify graph parameter in tf.Session().</p><p>The allow_soft_placement flag allows the switching back-and-forth between different devices. In tensorflow, not all operations are supported in GPU. The log_device_placement flag is to present which operations are set on what devices.</p><p>The <strong>max_to_keep</strong> flags determine the maximum number of the saved models that the TensorFlow keeps and its default is set to ‘5’ by TensorFlow.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.zeros_like(input_tensor, dtype=None, name=None, optimize=True)</span><br></pre></td></tr></table></figure><p>create a tensor filled with zero with the same shape as input_tensor</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.fill(dims, value, name=None)</span><br></pre></td></tr></table></figure><p>create a tensor filled with a scalar value</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tf.lin_space(start, stop, num, name=None)</span><br><span class="line"></span><br><span class="line">tf.range(start, limit=None, delta=1, dtype=None, name=&apos;range&apos;)</span><br></pre></td></tr></table></figure><p>create a tensor with a sequence of values</p><p>scalars are treated like tensors with zero dimension</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a = sess.run(a)    #use a_out = sess.run(a) instead for the sake of memory</span><br></pre></td></tr></table></figure><p>Use TF DType whenever possible for computation convenience.</p><p> Each session maintains its own copy of variables</p><p>tf.constant is an op. tf.Variable is a class with many ops.</p><p>Only use tf.constant for primitive type. Otherwise the loading of graphs would be expensive.</p><p>Constant values are stored in the graph definition.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">s = tf.get_variable(&quot;scalar&quot;, initializer=tf.constant(2))  #is preferred</span><br><span class="line"></span><br><span class="line">s = tf.Variable(2)</span><br></pre></td></tr></table></figure><p>Initializer is an op. You need to execute it within the context of a session.</p><p>Each variable has its own initializer.</p><p>Sessions allocate memory to store variable values.</p><p>Eval() a variable is equivalent to sess.run(a variable)</p><p>tf.Variable.assign() is an op.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.placeholder(dtype, shape=None, name=None)</span><br></pre></td></tr></table></figure><p>shape=None is easy to construct graphs but it is difficult for debugging.</p><p>tensors could be fed with some dummy values for testing purpose.</p><p>Lazy loading would make the graph bloated and hard to load. <strong>Remeber to seperate definition of a graph from computing/running ops</strong>.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># feed 1.0 to x</span><br><span class="line">x = tf.placeholder(tf.float32, shape=None, name=&apos;x&apos;)</span><br></pre></td></tr></table></figure><p>InvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor ‘x’ with dtype float.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># feed 1.0 to x</span><br><span class="line">x = tf.placeholder(tf.float32, name=&apos;x&apos;)</span><br></pre></td></tr></table></figure><p>works…….</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.cond( pred, true_fn=None, false_fn=None,    strict=False, name=None)</span><br></pre></td></tr></table></figure><p>tf.cond: pred is an expression. true_fn and flase_fn are callable function. If the expression is true, return the result of true_fn and vise versa.</p><p>tf.placeholder is pythonic, but it is also easy to become bottleneck if running in single thread.</p><p>tf.data is preferred. For prototyping, feed dict can be faster and easier to write (pythonic). But tf.data is tricky to use when you have complicated preprocessing or multiple data sources.</p><p>Session looks at all trainable variables that optimizer depends on and update them.</p><p>NCE guarantees approximation to softmax but Negative Sampling doesn’t.</p><p>tf.train.Saver saves graph’s variables in binary files. It saves session rather than graph. When re-using parameters, it is necessart to construct the graph first and then restore the parameters.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">with tf.name_scope(&quot;summaries&quot;): </span><br><span class="line">  tf.summary.scalar(&quot;loss&quot;, self.loss)</span><br><span class="line">  tf.summary.scalar(&quot;accuracy&quot;, self.accuracy)</span><br><span class="line">  tf.summary.histogram(&quot;histogram loss&quot;, self.loss)</span><br><span class="line">  summary_op = tf.summary.merge_all()</span><br></pre></td></tr></table></figure><p>merge them all into one summary op to make managing them easier.</p><p>Like everything else in TF, summaries are ops. For the summaries to be built, you have to run it in a session</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">loss_batch, _, summary = sess.run([loss, optimizer, summary_op])</span><br><span class="line"></span><br><span class="line">writer.add_summary(summary, global_step=step)</span><br></pre></td></tr></table></figure><p>Randomization:</p><ol><li>operation level. my_var = tf.Variable(tf.truncated_normal((-1.0,1.0), stddev=0.1, seed=0))</li><li>graph level. tf.set_random_seed(2)</li></ol><p>tf dataset:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.data.Dataset.from_tensor_slices()</span><br></pre></td></tr></table></figure><p>constructs a dataset from one or more <code>tf.Tensor</code> objects. It slices the first dimension of the tensor.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.data.Dataset.batch()</span><br></pre></td></tr></table></figure><p>or<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.data.Dataset.map()</span><br></pre></td></tr></table></figure></p><p>apply a transformation to a dataset and create another dataset.</p><p>A [<code>tf.data.Dataset</code>] represents a sequence of elements, in which each element contains one or more <code>Tensor</code>objects. For example, an element could be an image corresponds to a label or a sequence of tokens correspond to another sequence of tokens or only a simple label.</p><p>A <a href="https://www.tensorflow.org/api_docs/python/tf/data/Iterator" target="_blank" rel="noopener"><code>tf.data.Iterator</code></a> provides the main way to extract elements from a dataset. The operation returned by <code>Iterator.get_next()</code> yields the next element of a <code>Dataset</code> when executed, and typically acts as the interface between input pipeline code and your model. For more sophisticated uses, the <code>Iterator.initializer</code>operation enables you to reinitialize and parameterize an iterator with different datasets, so that you can, for example, iterate over training and validation data multiple times in the same program.</p><p> <a href="https://www.tensorflow.org/api_docs/python/tf/data/TFRecordDataset" target="_blank" rel="noopener"><code>tf.data.TFRecordDataset</code></a> constructs dataset from files if the files are on disk in the recommended TFRecord format.</p><p>If the iterator reaches the end of the dataset, executing the <code>Iterator.get_next()</code> operation will raise a <a href="https://www.tensorflow.org/api_docs/python/tf/errors/OutOfRangeError" target="_blank" rel="noopener"><code>tf.errors.OutOfRangeError</code></a>. After this point the iterator will be in an unusable state, and you must initialize it again if you want to use it further.</p><p>A common pattern is to wrap the “training loop” in a <code>try</code>-<code>except</code> block:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sess.run(iterator.initializer)<span class="keyword">while</span> <span class="keyword">True</span>:  <span class="keyword">try</span>:    sess.run(result)  <span class="keyword">except</span> tf.errors.OutOfRangeError:    <span class="keyword">break</span></span><br></pre></td></tr></table></figure><p>A <strong>reinitializable</strong> iterator can be initialized from multiple different <code>Dataset</code> objects. For example, you might have a training input pipeline that uses random perturbations to the input images to improve generalization, and a validation input pipeline that evaluates predictions on unmodified data. These pipelines will typically use different <code>Dataset</code> objects that have the same structure (i.e. the same types and compatible shapes for each component).</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">iterator = tf.data.Iterator.from_structure(training_dataset.output_types,                                           training_dataset.output_shapes)</span><br><span class="line">next_element = iterator.get_next()</span><br></pre></td></tr></table></figure><p>A <strong>one-shot</strong> iterator is the simplest form of iterator, which only supports iterating once through a dataset, with no need for explicit initialization. One-shot iterators handle almost all of the cases that the existing queue-based input pipelines support, but they do not support parameterization. </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">dataset = tf.data.Dataset.range(<span class="number">100</span>)</span><br><span class="line">iterator = dataset.make_one_shot_iterator()</span><br><span class="line">next_element = iterator.get_next()</span><br></pre></td></tr></table></figure><p>An <strong>initializable</strong> iterator requires you to run an explicit <code>iterator.initializer</code> operation before using it. In exchange for this inconvenience, it enables you to <em>parameterize</em> the definition of the dataset, using one or more <code>tf.placeholder()</code>tensors that can be fed when you initialize the iterator.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">max_value = tf.placeholder(tf.int64, shape=[])</span><br><span class="line">dataset = tf.data.Dataset.range(max_value)</span><br><span class="line">iterator = dataset.make_initializable_iterator()</span><br><span class="line">next_element = iterator.get_next()<span class="comment"># Initialize an iterator over a dataset with 10 elements.</span></span><br><span class="line">sess.run(iterator.initializer, feed_dict=&#123;max_value: <span class="number">10</span>&#125;)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>):  </span><br><span class="line">  value = sess.run(next_element)  </span><br><span class="line">  <span class="keyword">assert</span> i == value</span><br></pre></td></tr></table></figure><p>The <code>Iterator.get_next()</code> method returns one or more <a href="https://www.tensorflow.org/api_docs/python/tf/Tensor" target="_blank" rel="noopener"><code>tf.Tensor</code></a> objects that correspond to the symbolic next element of an iterator. Each time these tensors are evaluated, they take the value of the next element in the underlying dataset. Note that the iterator does not get to the next element immediately. The returned element is suuposed to be passed to  <code>tf.Session.run()</code> to get the next elements and advance the iterator.</p><p>Applying arbitrary Python logic with <code>tf.py_func()</code></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.stack(    values,    axis=0,    name=&apos;stack&apos;)</span><br></pre></td></tr></table></figure><p>concatenate tensors along specified dimension.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tf.data.Dataset.padded_batch()</span><br></pre></td></tr></table></figure><p>padded_shapes is None, the component will be padded out to the maximum length of all elements in that dimension.</p><p>Estimators are high-level abstraction of low-level tensorflow operation. It enables easier training, testing on different kinds of devices and modes like training on a single PC or a cluster.</p><p>4 steps to use pre-made Estimators</p><ol><li>write function to import dataset</li><li>Define the feature columns.</li><li>Instantiate the relevant pre-made Estimator like specifying number of hidden layers, output features</li><li>There are training and evaluation methods for Estimators. Call a training, evaluation, or inference method.</li></ol><p>tf.feature_column could be regarded as a kind of interface between the dataset and model in Estimators. It could abstract continuous values or categorical values.</p>]]></content>
      
      
        <tags>
            
            <tag> Notes </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Dependency_Parsing</title>
      <link href="/2018/07/23/Dependency-Parsing/"/>
      <url>/2018/07/23/Dependency-Parsing/</url>
      <content type="html"><![CDATA[<h2 id="Transition-Based-Dependency-Parsing"><a href="#Transition-Based-Dependency-Parsing" class="headerlink" title="Transition-Based Dependency Parsing"></a>Transition-Based Dependency Parsing</h2><p>Linear time, greedy algorithm, no backtracking.</p><p>A configuration is a stack, a buffer of token lists and an oracle. The key is to train the oracle. </p><p>The algorithm is intuitive. If there is a match in the candidate relation set, pop the words and add the relation to the result set. Push the words in the buffer into the stack. repeat until no word left.</p><h3 id="Creating-an-Oracle"><a href="#Creating-an-Oracle" class="headerlink" title="Creating an Oracle"></a>Creating an Oracle</h3><p>Supervised learning is employed to do this.</p><h4 id="Generating-Training-Data"><a href="#Generating-Training-Data" class="headerlink" title="Generating Training Data"></a>Generating Training Data</h4><p>given a reference parse and a configuration, the training oracle proceeds as follows:</p><ul><li>Choose LEFTARC if it produces a correct head-dependent relation </li><li>Otherwise, choose RIGHTARC if (1) it produces a correct head-dependent relation<br>and (2) all of its dependents in the buffer have already been assigned.</li><li>Otherwise, choose SHIFT.</li></ul><h4 id="Features"><a href="#Features" class="headerlink" title="Features"></a>Features</h4><p>create feature sets.</p><h4 id="Learning"><a href="#Learning" class="headerlink" title="Learning"></a>Learning</h4><p>The dominant approaches to training transition-based dependency parsers have been multinomial logistic regression and support vector machines, both of which can make effective use of large numbers of sparse features.</p><p>Deep learning approaches have been applied successfully to transition-based parsing. These approaches eliminate the need for complex, hand-crafted features and have been particularly effective at overcoming the data sparsity issues normally associated training transition-based<br>parsers.</p><h3 id="Alternative-Transition-Systems"><a href="#Alternative-Transition-Systems" class="headerlink" title="Alternative Transition Systems"></a>Alternative Transition Systems</h3><p><strong>arc eager</strong> transition system is just a modified version of the oracle.</p><p>The operation of the oracle:</p><ul><li>LEFTARC: Assert a head-dependent relation between the word at the front of<br>the input buffer and the word at the top of the stack; pop the stack.</li><li>RIGHTARC: Assert a head-dependent relation between the word on the top of<br>the stack and the word at front of the input buffer; shift the word at the front<br>of the input buffer to the stack.</li><li>SHIFT: Remove the word from the front of the input buffer and push it onto<br>the stack.</li><li>REDUCE: Pop the stack.</li></ul><h3 id="Beam-Search"><a href="#Beam-Search" class="headerlink" title="Beam Search"></a>Beam Search</h3><p>BFS with a heuristic filter that prunes the search frontier to stay within a fixed-size beam width.</p><h3 id="Graph-Based"><a href="#Graph-Based" class="headerlink" title="Graph-Based"></a>Graph-Based</h3>]]></content>
      
      
        <tags>
            
            <tag> NLP </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Back_Propagation</title>
      <link href="/2018/07/21/Back-Propagation/"/>
      <url>/2018/07/21/Back-Propagation/</url>
      <content type="html"><![CDATA[<h3 id="Derivative-of-composite-function"><a href="#Derivative-of-composite-function" class="headerlink" title="Derivative of composite function"></a>Derivative of composite function</h3><p>$$\frac{d\frac{f(x)}{g(x)}}{dx} = \frac{f’(x)g(x)-f(x)g’(x)}{g^2(x)}$$</p><h3 id="Derivative-of-Cross-Entropy"><a href="#Derivative-of-Cross-Entropy" class="headerlink" title="Derivative of Cross Entropy"></a>Derivative of Cross Entropy</h3><p>$$CE(\vec{y},\vec{\hat{y}}) = -\sum_iy_i\log(\hat{y_i})$$</p><p>Here \(y_i\) is an one-hot vector denotes the correct class \(c_i\). In the actual computation, it only selects out the correct class without any extra function.</p><p>For a single example \(x_i\):</p><p>if \(\hat{y_i}=y_i\):</p><p>$$\frac{dCE(y_i,\hat{y_i})}{dx_i} = \frac{1}{\hat{y_i}}\frac{d(\hat{y_i})}{dx_i} = \frac{\sum_j^Ce^{(x_j)}}{e^{x_i}}\ \frac{e^{x_i}\sum_j^Ce^{x_j}-e^{2x_i}}{(\sum_j^Ce^{x_j})^2} = \hat{y_i}-1$$</p><p>if \(\hat{y_i}\ne y_i\):</p><p>$$\frac{dCE(y_i,\hat{y_i})}{dx_i} = \frac{1}{\hat{y_i}}\frac{d(\hat{y_i})}{dx_i} = \frac{\sum_j^Ce^{(x_j)}}{e^{x_i}}\ \frac{e^{x_i}e^{x_k}}{(\sum_j^Ce^{x_j})^2}=\hat{y_i}$$</p><p>The rest is just compute the gradient layer by layer.</p><p><strong>Note that when compute the gradient with regard to activation function, there would be outer product.</strong></p>]]></content>
      
      
        <tags>
            
            <tag> DL </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Pagerank</title>
      <link href="/2018/07/18/Pagerank/"/>
      <url>/2018/07/18/Pagerank/</url>
      <content type="html"><![CDATA[<p>A good hub page is one that points to many good authorities; a good authority page is one that is pointed to by many good hub pages.</p><h2 id="PageRank"><a href="#PageRank" class="headerlink" title="PageRank"></a>PageRank</h2><h4 id="Intuition"><a href="#Intuition" class="headerlink" title="Intuition"></a>Intuition</h4><p>Pages that are visited more are given higher weight. Employ graph to represent the internet. Higher in links means visited more.</p><p>PageRank values would converge to the final value regardless of the start state and it is in the range [0,1]. So the PageRank values could also be viewed as the probability of the surfer is in the node i at any time given the PageRank value of the node i.</p><p>PageRank could be regarded as a random walk in the internet. Start at any state, and then walk through the out links randomly. In case of circular routes and dead end, employ the scaled version of random walk. As the random walk proceeds, some nodes are visited more often than others; intuitively, these are nodes with many links coming in from other frequently visited nodes. The idea behind PageRank is that pages visited more often in this walk are more important.</p><p><strong>Teleport</strong>:if N is the total number of nodes in the web graph, the teleport operation takes the surfer to each node with probability 1/N.</p><h4 id="Random-Walk-Interpretation"><a href="#Random-Walk-Interpretation" class="headerlink" title="Random Walk Interpretation"></a>Random Walk Interpretation</h4><p>Scaled version of random walk:<br>with alpha probability take teleport operation and with 1-alpha probability take the out links of the current nodes.</p><p>Interpreted in terms of the (scaled) version of PageRank, <strong>Perron’s Theorem</strong> tells us that there is a unique vector y that remains fixed under the application of the scaled update rule, and that repeated application of the update rule from any starting point will converge to y.<br>This vector y thus corresponds to the limiting PageRank values we have been seeking.</p><h4 id="Graph-Interpretation"><a href="#Graph-Interpretation" class="headerlink" title="Graph Interpretation"></a>Graph Interpretation</h4><p>Each vertex is a node. PageRank value is 1 in total. Initially, each node has the same pagerank value 1/N. With the different in links and out links, the pagerank value would flow through those links to different notes. So the pagerank value would change accordingly.</p><p><strong>Scaled version of graph</strong>:<br>With alpha probability take teleport operation and with 1-alpha probability do the normal flow operation. In terms of graph, it discount the overall pagerank value to \(1-\alpha \) and assign the rest \(\alpha \) pagerank value to each node. So each node would get the same pagerank value \(\alpha /N\).</p><h3 id="Markov-chain"><a href="#Markov-chain" class="headerlink" title="Markov chain"></a>Markov chain</h3><p>A Markov chain is a discrete-time stochastic process: a process that occurs in a series of time-steps in each of which a random choice is made. A Markov chain consists of N states. Each web page will correspond to a state in the Markov chain.</p><p>A Markov chain is characterized by an N × N transition probability matrix P each of whose entries is in the interval [0, 1]; the entries in each row of P add up to 1.</p><p>Transition matrix P:<br>The rows represent that given a node i, the probability of the node i transits to nodes j.(distribute the pagerank score)<br>The columns represent that given a node j, the probability of nodes i transits to node j.(incoming pagerank score)</p><p><strong>ERGODIC MARKOV CHAIN</strong>:<br>Definition: A Markov chain is said to be ergodic if there exists a positive integer T0 such that for all pairs of states i, j in the Markov chain, if it is started at time 0 in state i then for all t &gt; T0, the probability of being in state j at time t is greater than 0.</p><p>For a Markov chain to be ergodic, two technical conditions are required of its states and the non-zero transition probabilities; these conditions are known as <strong>irreducibility</strong> and <strong>aperiodicity</strong>.</p><p><strong>irreducibility</strong> ensures that there is a sequence of transitions of non-zero probability from any state to any other.</p><p><strong>aperiodicity</strong> ensures that the states are not partitioned into sets such that all state transitions occur cyclically from one set to another.</p><p>Scaled version of random walk which take teleport operation with alpha probability guarantees transition probability are greater than 0 and no loop transitions.(irreducibility and aperiodicity)</p><h3 id="Compute-PageRank"><a href="#Compute-PageRank" class="headerlink" title="Compute PageRank"></a>Compute PageRank</h3><ul><li>Iteratively compute \(\vec{x}P^t\) s.t. \(\vec{x}\) becomes unchanged.</li><li>Compute the eigenvector coresponding to the largest eigenvalue 1 which is the PageRank. But compute the eigenvector could be computationally expensive.</li></ul><h4 id="Implementation"><a href="#Implementation" class="headerlink" title="Implementation"></a>Implementation</h4><h5 id="Matrix-Multiplication-version-of-PageRank"><a href="#Matrix-Multiplication-version-of-PageRank" class="headerlink" title="Matrix-Multiplication version of PageRank:"></a>Matrix-Multiplication version of PageRank:</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Pagerank</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, N=<span class="number">0</span>, alpha=<span class="number">0</span>)</span>:</span></span><br><span class="line">        self.alpha = alpha</span><br><span class="line">        self.N = N</span><br><span class="line">        self.pg_vector = <span class="keyword">None</span></span><br><span class="line"></span><br><span class="line">    <span class="string">'''derive transition matrix from adjacency matrix'''</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">derive_transition</span><span class="params">(self,adjacency_matrix,alpha=<span class="number">0</span>)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> self.alpha != <span class="number">0</span>:</span><br><span class="line">            alpha = self.alpha</span><br><span class="line"></span><br><span class="line">        N = adjacency_matrix.shape[<span class="number">0</span>]</span><br><span class="line">        transition_m = np.zeros(adjacency_matrix.shape)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(adjacency_matrix.shape[<span class="number">0</span>]):</span><br><span class="line">            <span class="keyword">if</span> np.sum(adjacency_matrix[i,:]) == <span class="number">0</span>:</span><br><span class="line">                transition_m[i,:] = np.array([<span class="number">1</span>/N]*N)   <span class="comment">#this node is a dead end, transit to one of all nodes in the graph</span></span><br><span class="line">            <span class="keyword">else</span>:           <span class="comment"># with alpha probability transit to one of all nodes, 1-alpha take normal random walk</span></span><br><span class="line">                transition_m[i, :] = alpha * np.array([<span class="number">1</span> / N] * N) + (<span class="number">1</span>-alpha) * adjacency_matrix[i,:] / np.sum(adjacency_matrix[i,:])</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> transition_m</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">propagate_transition</span><span class="params">(self, transition_m, pg_vector=None)</span>:</span>  <span class="comment">#pg_vector is column vectors</span></span><br><span class="line">        <span class="keyword">if</span> pg_vector <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">            <span class="keyword">return</span> np.dot(transition_m.T, pg_vector)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">if</span> self.pg_vector <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">                self.initialize_pg_vector()</span><br><span class="line"></span><br><span class="line">            self.pg_vector = np.dot(transition_m.T, self.pg_vector)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">return</span> self.pg_vector</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">initialize_pg_vector</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">assert</span> self.N != <span class="number">0</span>, <span class="string">"Please input number of Nodes N"</span></span><br><span class="line">        self.pg_vector = np.ones((self.N)).T</span><br><span class="line">        self.pg_vector /= self.N</span><br><span class="line">        print(self.pg_vector)</span><br></pre></td></tr></table></figure><h5 id="Graph-version-of-PageRank"><a href="#Graph-version-of-PageRank" class="headerlink" title="Graph version of PageRank:"></a>Graph version of PageRank:</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> copy</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Graph</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, d, vertex=None)</span>:</span></span><br><span class="line">        <span class="keyword">assert</span> isinstance(d,dict), <span class="string">"please input a dict"</span></span><br><span class="line">        self.edges = d</span><br><span class="line">        self.d = d</span><br><span class="line">        self.vertexes = self.get_vertexes()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_vertexes</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> list(self.d.keys())</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_edges</span><span class="params">(self)</span>:</span></span><br><span class="line">        l = []</span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> self.d.keys():</span><br><span class="line">            <span class="keyword">for</span> v <span class="keyword">in</span> self.d[k]:</span><br><span class="line">                l.append(k+<span class="string">'-'</span>+v)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> l</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__matrix_to_dict</span><span class="params">(self, matrix)</span>:</span>     <span class="comment">#convert adjacency matrix to dict</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">BFS</span><span class="params">(self)</span>:</span></span><br><span class="line">        done = []</span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> self.d.keys():</span><br><span class="line">            <span class="keyword">if</span> k <span class="keyword">not</span> <span class="keyword">in</span> done:</span><br><span class="line">                done.append(k)</span><br><span class="line">            <span class="keyword">for</span> v <span class="keyword">in</span> self.d[k]:</span><br><span class="line">                <span class="keyword">if</span> v <span class="keyword">in</span> done:</span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    done.append(v)</span><br><span class="line">        <span class="keyword">return</span> done</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">DFS</span><span class="params">(self)</span>:</span></span><br><span class="line">        done = []</span><br><span class="line">        l = list(self.d.keys())</span><br><span class="line">        <span class="keyword">while</span> len(l) != <span class="number">0</span>:</span><br><span class="line">            current = l.pop()</span><br><span class="line">            <span class="keyword">if</span> current <span class="keyword">not</span> <span class="keyword">in</span> done:</span><br><span class="line">                done.append(current)</span><br><span class="line">                l.extend(list(self.d[current]))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> done</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">DFS_recursive</span><span class="params">(self)</span>:</span></span><br><span class="line">        done = []</span><br><span class="line">        l = list(self.d.keys())</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">recursive</span><span class="params">(element)</span>:</span></span><br><span class="line">            waiting_l = self.d[element]</span><br><span class="line">            <span class="keyword">for</span> e <span class="keyword">in</span> waiting_l:</span><br><span class="line">                <span class="keyword">if</span> e <span class="keyword">not</span> <span class="keyword">in</span> done:</span><br><span class="line">                    done.append(e)</span><br><span class="line">                    recursive(e)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> len(l) != <span class="number">0</span>:</span><br><span class="line">            current = l.pop()</span><br><span class="line">            <span class="keyword">if</span> current <span class="keyword">not</span> <span class="keyword">in</span> done:</span><br><span class="line">                done.append(current)</span><br><span class="line">                recursive(current)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> done</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">PageRank</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, graph)</span>:</span></span><br><span class="line">        self.g = graph</span><br><span class="line">        self.vertexes = graph.vertexes</span><br><span class="line">        self.pr_value = &#123;&#125;</span><br><span class="line">        self.num_points = len(self.vertexes)</span><br><span class="line">        self.__pr_value_initialization__()</span><br><span class="line">        self.new_pr_value = &#123;&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__pr_value_initialization__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> ver <span class="keyword">in</span> self.vertexes:</span><br><span class="line">            self.pr_value[ver] = <span class="number">1.0</span> / self.num_points</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__new_pr_value_initialization__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> ver <span class="keyword">in</span> self.vertexes:</span><br><span class="line">            self.new_pr_value[ver] = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">update_a_round</span><span class="params">(self, alpha=<span class="number">0</span>)</span>:</span></span><br><span class="line">        self.__new_pr_value_initialization__()</span><br><span class="line">        <span class="keyword">for</span> ver <span class="keyword">in</span> self.vertexes:</span><br><span class="line">            <span class="keyword">if</span> len(self.g.edges[ver]) == <span class="number">0</span>:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">                <span class="comment"># self.new_pr_value[ver] = self.pr_value[ver]</span></span><br><span class="line">            value_flow = self.pr_value[ver] / len(self.g.edges[ver])</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> child <span class="keyword">in</span> self.g.edges[ver]:</span><br><span class="line">                self.new_pr_value[child] += value_flow</span><br><span class="line">        <span class="keyword">if</span> alpha != <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">for</span> ver <span class="keyword">in</span> self.vertexes:</span><br><span class="line">                self.new_pr_value[ver] = alpha * <span class="number">1.0</span> / self.num_points + (<span class="number">1</span>-alpha) * self.new_pr_value[ver]</span><br><span class="line"></span><br><span class="line">        self.pr_value = copy.deepcopy(self.new_pr_value)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">propagate_transition</span><span class="params">(self, alpha=<span class="number">0</span>)</span>:</span></span><br><span class="line">        last = np.zeros((self.num_points))</span><br><span class="line">        <span class="comment"># for i in range(100):</span></span><br><span class="line">        <span class="keyword">while</span> <span class="keyword">True</span>:</span><br><span class="line">            self.update_a_round(alpha)</span><br><span class="line">            current = np.array(list(self.pr_value.values()))</span><br><span class="line">            error = abs(current - last)</span><br><span class="line">            <span class="comment"># print('last', last)</span></span><br><span class="line">            <span class="comment"># print('current', current)</span></span><br><span class="line">            <span class="comment"># print('i', i)</span></span><br><span class="line">            <span class="comment"># print('error: ', error)</span></span><br><span class="line">            <span class="keyword">if</span> np.sum(error) &lt; <span class="number">1e-6</span>:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">            last = current</span><br><span class="line"></span><br><span class="line"><span class="string">'''Test'''</span></span><br><span class="line"></span><br><span class="line">d_map = &#123;&#125;</span><br><span class="line">d = &#123;<span class="string">'A'</span>:[<span class="string">'B'</span>,<span class="string">'C'</span>],<span class="string">'B'</span>:[<span class="string">'D'</span>,<span class="string">'E'</span>],<span class="string">'C'</span>:[<span class="string">'F'</span>,<span class="string">'G'</span>],<span class="string">'D'</span>:[<span class="string">'H'</span>,<span class="string">'A'</span>],<span class="string">'E'</span>:[<span class="string">'H'</span>,<span class="string">'A'</span>],<span class="string">'F'</span>:[<span class="string">'A'</span>],<span class="string">'G'</span>:[<span class="string">'A'</span>],<span class="string">'H'</span>:[<span class="string">'A'</span>],<span class="string">'P'</span>:[]&#125;</span><br><span class="line"><span class="comment"># d = &#123;'A':['B'],'B':['A','C'],'C':['B']&#125;</span></span><br><span class="line">g = Graph(d)</span><br><span class="line">pg = PageRank(g)</span><br><span class="line">pg.propagate_transition()</span><br><span class="line">print(pg.pr_value)</span><br></pre></td></tr></table></figure><h3 id="Topic-Specific-PageRank"><a href="#Topic-Specific-PageRank" class="headerlink" title="Topic Specific PageRank"></a>Topic Specific PageRank</h3><p>Start at a random page in the topic and also end at a random page in the topic. \(\vec{x}_{sports}\) is a topic specific pagerank vector where for pages belongs to sports, there is a topic specific pagerank and pagerank of other pages are 0.</p><p>Calculate the PageRank of a page with regard to topics. The only difference is that the teleportation is different. The naive teleport go to a node in the graph with probability 1/N. The teleportation of topic specific pagerank is to go to a page in a specific topic with probability alpha. Given the number of pages S in the topic T, the probability is \(\frac{1}{S}\) rather than \(\frac{1}{N}\).</p><p>i.e.:<br>Let s be [A,B,C,D]. A belongs to topic 1. B,C and D belongs to topic 2.<br>When calculating the topic specific pagerank, for topic 2, the formula is still \(\vec{x}P^t\). But here \(P\) for topic 2 is \(\alpha M + (1-\alpha)\frac{1}{S}\) rather than     \(\alpha M + (1-\alpha)\frac{1}{N}\). Actually the formula for topic 2 is \(\alpha M + (1-\alpha)[0,\frac{1}{3},\frac{1}{3},\frac{1}{3}]\) and in normal PageRank it should be \(\alpha M + (1-\alpha)[\frac{1}{4},\frac{1}{4},\frac{1}{4},\frac{1}{4}]\).</p><h3 id="Personalized-PageRank"><a href="#Personalized-PageRank" class="headerlink" title="Personalized PageRank"></a>Personalized PageRank</h3><p>Now the difference is still the teleportation. The teleportation is tailored according to the users’ interest. Let’s assume the interest of a person is sports and finance. Their weights are 0.8,0.2 specifically. The teleportation is to go to a topic with the corresponding weight and then a page in the specific topic with probability alpha. This could also be viewed as a linear combination of topic specific vectors. In this example, the formula would be \(\alpha M + (1-\alpha) [0.8\vec{x_{sports}} + 0.2\vec{x_{finance}}]\).</p><h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p><a href="http://www.cs.cornell.edu/home/kleinber/networks-book/" target="_blank" rel="noopener">Networks, Crowds, and Markets: Reasoning About a Highly Connected World</a></p><p><a href="https://nlp.stanford.edu/IR-book/" target="_blank" rel="noopener">Introduction to Information Retrieval</a></p>]]></content>
      
      
    </entry>
    
    <entry>
      <title>Parsing</title>
      <link href="/2018/07/13/Parsing/"/>
      <url>/2018/07/13/Parsing/</url>
      <content type="html"><![CDATA[<p><strong>Context-Free Grammar(CFG)</strong></p><p>The symbols that correspond to words in the language (“the”, “nightclub”) are called <strong>terminal</strong> symbols. They are left nodes in a parse tree. </p><p>The lexicon is the set of rules that introduce these terminal symbols. </p><p>The symbols that express abstractions over these terminals are called <strong>non-terminals</strong>. Ther are the non-left  </p><p>Each grammar must have one designated start symbol, which is often called S &lt;\s&gt;.</p><h2 id="Formal-Definition-of-CFG"><a href="#Formal-Definition-of-CFG" class="headerlink" title="Formal Definition of CFG"></a>Formal Definition of CFG</h2><p>G=(T,N,S,R)</p><ul><li>T is a set of terminal symbols.</li><li>N is a set of nonterminal symbols</li><li>S is the start symbol (S \(\in\) N)</li><li>R is a set of rules/productions of the form X -&gt; \(\gamma\).</li></ul><p>A grammar G generates a language L.</p><h2 id="Conversion-to-CNF"><a href="#Conversion-to-CNF" class="headerlink" title="Conversion to CNF"></a>Conversion to CNF</h2><p><strong>Chomsky Normal Form(CNF)</strong>: for each non-terminal, only two non-ternimal or single terminal could be derived from it.</p><p><strong>Unit Production</strong>: Rules with a single non-terminal on the right.</p><p>three situations needed to address in any generic grammar: </p><ul><li>rules that mix terminals with non-terminals on the right-hand side</li><li>rules that have a single non-terminal on the right-hand side</li><li>rules in which the length of the right-hand side is greater than 2</li></ul><p>rules that mix terminals and non-terminals is to introduce a new dummy non-terminal to substitute the original terminal. For example, a rule for an infinitive verb phrase such as INF-VP → to VP would be replaced by the<br>two rules INF-VP → TO VP and TO → to.</p><p>To eliminate unit production:if A<br>-&gt;&gt; B by a chain of one or more unit productions and B → \(\gamma\) is a non-unit production in our grammar, then we add A → γ for each such rule in the grammar and discard all the intervening unit productions. </p><p>Rules with right-hand sides longer than 2 are normalized through the introduction<br>of new non-terminals that substitute the longer sequences iteratively.</p><p>i.e.: A → B C D. After transformation, A → X D and X -&gt;B C</p><p>The entire conversion process can be summarized as follows:</p><ul><li>Copy all conforming rules to the new grammar unchanged.</li><li>Convert terminals within rules to dummy non-terminals.</li><li>Convert unit-productions.</li><li>Make all rules binary and add them to new grammar.</li></ul><h3 id="Learn-PCFG-Rules"><a href="#Learn-PCFG-Rules" class="headerlink" title="Learn PCFG Rules"></a>Learn PCFG Rules</h3><p><strong>Count-based</strong></p><p>For unambiguous parsing, just count each rule showed in the resulting parsing tree and get the probability like language model.</p><p>For ambiguous parsing, initialize the parsing s.t. each rule is assigned the equal probability. And then parse the sentece an calculate probability of each parsing. Update the weight. Iteratively doing this, an extension of EM algorithm.</p><h3 id="Problems-of-PCFG"><a href="#Problems-of-PCFG" class="headerlink" title="Problems of PCFG"></a>Problems of PCFG</h3><ul><li>Lack of Sensitivity to Lexical Dependencies</li><li>Independence Assumptions Miss Structural Dependencies Between Rules. For different location, each rule may be expanded differently.</li></ul><h3 id="Improving-PCFGs-by-Splitting-Non-Terminals"><a href="#Improving-PCFGs-by-Splitting-Non-Terminals" class="headerlink" title="Improving PCFGs by Splitting Non-Terminals"></a>Improving PCFGs by Splitting Non-Terminals</h3><ul><li>split the NP non-terminal into two versions: one for subjects, one for objects.</li><li>parent annotation</li></ul><p>This method also induce new problem. More rules lead to less training which may cause overfitting.</p><p>Modern models automatically search for the optimal splits. The split and merge algorithm  for example, starts with a simple X-bar grammar, alternately splits the non-terminals, and merges non-terminals, finding the set of annotated nodes that maximizes the likelihood of the training set treebank.</p>]]></content>
      
      
        <tags>
            
            <tag> NLP </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>CKY</title>
      <link href="/2018/07/13/CKY/"/>
      <url>/2018/07/13/CKY/</url>
      <content type="html"><![CDATA[<p>CKY is to initialize a matrix and fill in the upper right triangular matrix. Each word is filled into the matrix from left to right and bottom to up. </p><p>There is a probability distribution about contituent for each word. And then the matrix is filled up using viterbi algorithm. Take the max probability.</p><p>Transfer the rules to binary reduce the complexity.</p>]]></content>
      
      
        <tags>
            
            <tag> NLP </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Language_Model</title>
      <link href="/2018/07/09/Language-Model/"/>
      <url>/2018/07/09/Language-Model/</url>
      <content type="html"><![CDATA[<h2 id="Unigram"><a href="#Unigram" class="headerlink" title="Unigram"></a>Unigram</h2><p>$$p(w_i) = \frac{c(w_i)}{N}$$</p><p>\(c(w_i)\) is the count of the word. N is the total number of word.</p><h2 id="Bigram"><a href="#Bigram" class="headerlink" title="Bigram"></a>Bigram</h2><p>$$p(w_i|w_{i-1}) = \frac{c(w_iw_{i-1})}{c(w_{i-1})}$$</p><h2 id="N-Gram"><a href="#N-Gram" class="headerlink" title="N-Gram"></a>N-Gram</h2><p>Given the previous N words, estimate the probability of the current word.</p><p>$$p(w_i|w_{i-N-1}^{N-1}) = \frac{c(w_iw_{i-N-1}^{N-1})}{c(w_{i-N-1}^{N-1})}$$</p><h2 id="Deal-with-Unknown-Words"><a href="#Deal-with-Unknown-Words" class="headerlink" title="Deal with Unknown Words"></a>Deal with Unknown Words</h2><p>There are two common ways to train the probabilities of the unknown word model <unk>. </unk></p><p>The first one is to turn the problem back into a closed vocabulary one by choosing a fixed vocabulary in advance:</p><ul><li>Choose a vocabulary (word list) that is fixed in advance.</li><li>Convert in the training set any word that is not in this set to the unknown word token <unk> in a text normalization step.</unk></li><li>Estimate the probabilities for <unk> from its counts just like any other regular word in the training set.</unk></li></ul><p>The second alternative, replacing words in the training data by <unk> based on their frequency.<br>i.e.: replace all words by <unk> that occur fewer than n times in the training set or choose the top V words by frequency and replace the rest by UNK. </unk></unk></p><p>The third way:<br>$$p(w_i)=\lambda_1p_{ML}(w_i)+(1-\lambda_1)\frac{1}{N}$$</p><p>Save some probability for unknown words \((\lambda_{unk} = 1-\lambda_1)\). This is in fact another kind of smoothing. Discount the probability of known words and assign to the unknown words.<br> \(\lambda\) is a hyperparameter. It is 0.95 by default. N is the total number of words.</p><h2 id="Coverage"><a href="#Coverage" class="headerlink" title="Coverage"></a>Coverage</h2><p>The percentage of known words in the corpus. Usually omit the symbol of the end of a sentence .</p><h2 id="Entropy-of-a-sentence"><a href="#Entropy-of-a-sentence" class="headerlink" title="Entropy of a sentence"></a>Entropy of a sentence</h2><p>$$H(S)= -\frac{1}{N}\sum_{w\in S}\log_2 P(w)$$</p>]]></content>
      
      
        <tags>
            
            <tag> NLP </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Word_Senses</title>
      <link href="/2018/07/06/Word_Senses/"/>
      <url>/2018/07/06/Word_Senses/</url>
      <content type="html"><![CDATA[<h1 id="Word-sense-disambiguation-WSD"><a href="#Word-sense-disambiguation-WSD" class="headerlink" title="Word sense disambiguation(WSD)"></a>Word sense disambiguation(WSD)</h1><p>Word sense disambiguation(WSD) is significant because it is common that there are multiple senses within a word. Better word sense disambiguation would improve the performance of tasks such as question answering and machine translation.</p><p>Two kinds of WSD tasks:</p><ul><li>lexical sample</li><li>all-words</li></ul><p>Lexical sample: given a set of target words and with an inventory of senses from some lexicon. Supervised learning is employed to solve this problem at usual. Hand-label a small set of words and corresponding sense, and feed into a classifier.</p><p>All-words: given entire texts and a lexicon that contains an inventory of senses for each entry. The objective is to disambiguate every content word in the text. It is impractical to train a classifier for each term because the number of words is large.</p><h3 id="Supervised-Learning-Approach"><a href="#Supervised-Learning-Approach" class="headerlink" title="Supervised Learning Approach"></a>Supervised Learning Approach</h3><ol><li>Feature Vector Extraction. Process the sentence in a context window to extract feature vector.</li></ol><p>There are two kinds of feature vector:</p><ul><li>collocation features. Multiple words in a position-specific relationship to a target word. It is effective at encoding local lexical and grammatical information that usually isolate a given sense. High performing systems generally use POS tags and word collocations of length 1,2 and 3 from a window of words 3.</li><li>bag-of-words: neglecting the position information, just record number of context words in a context window. The context words could be pre-selected(frequent used words) given a target word.</li></ul><p><strong>Evaluation</strong>: most frequent sense as baseline. Most freauent sense usually choose the most frequently used sense given a context.</p><h3 id="Dictionary-and-Thesaurus"><a href="#Dictionary-and-Thesaurus" class="headerlink" title="Dictionary and Thesaurus"></a>Dictionary and Thesaurus</h3><h5 id="The-Lesk-Algorithm"><a href="#The-Lesk-Algorithm" class="headerlink" title="The Lesk Algorithm"></a>The Lesk Algorithm</h5><p>It is a family of dictionary-based algorithms.<br>Simplified algorithm compute the number of overlapped words between a given context and all of the word senses. Output the sense with the most overlapped words.</p><p>Original Lesk Algorithm compute the number of overlapped words between sense of each context word and the sense of the target word.<br>i.e.: Bank is a financial institute for deposit.<br>Simplified algorithm compute the number of overlapping words between each sense and the context [financial,institute, deposit] and output the sense with the most overlapped words.<br>The original algorithm compute all senses with all senses of each word in the context  [financial,institute, deposit] and output the sense with the most overlapped words.</p><p><strong>Notes</strong>:stop-words are not taken into consideration.</p><p>Problem: Entries of the dictionary for the target word are not enough which reduce the chance of overlapping.</p><p>Solution: To expand the sense, include senses of similar words which may increase the number of overlapping words.</p><p>The best solution is to utilize sense-tagged corpus, which is so called <strong><strong>Corpus Lesk Algorithm</strong></strong>. To expand the signature for a word sense, add all word senses with the same label. i.e.: add word sense of large, huge to big. Instead of employ a stop-list, the algorithm apply IDF to reduce the weight of function words like the,of. This algorithm is usually a baseline.</p><p>The bag-of-words approach could be improved by combining the Lesk algorithm. The glosses and example sentences for the target sense in WordNet would be used as words features along with <strong>sense-tagged</strong> corpus like SemCor.</p><h5 id="Graph-based-Methods"><a href="#Graph-based-Methods" class="headerlink" title="Graph-based Methods"></a>Graph-based Methods</h5><p>A graph is employed to represent words. Each sense is a node and relations between senses are edges. It is usually an undirected graph.</p><p>The correct sense is the one that is central in the graph. Use degree to decide centrality.</p><p>Another approach is to assign probability to nodes according to personalized page rank.</p><p><strong>Problem of both supervised and dictionary-based approach</strong>: need hand-built resouces</p><h3 id="Semi-Supervised-Bootstrapping"><a href="#Semi-Supervised-Bootstrapping" class="headerlink" title="Semi-Supervised: Bootstrapping"></a>Semi-Supervised: Bootstrapping</h3><ol><li>Use a small set of labeled data to train the classifier. </li><li>Do classification.</li><li>Select the result with high confidence and add to the training set.</li><li>Train the classifier and repeat step 2 and 3.</li><li>Stop until there is no untagged data left or reach a specific error rate threshold.</li></ol><p>To construct the training set, hand-label it or use heuristic to help.</p><p>Heuristic:</p><ul><li><strong>one sense per collocation</strong>: certain words or phrases strongly indicates a specific sense.</li><li><strong>one sense per discourse</strong>:a particular word appearing multiple times in a text or discourse often appeared with the same sense. This heuristic seems to hold better for coarse-grained senses and particularly for cases of homonymy rather than polysemy.</li></ul><h3 id="Unsupervised-Approach-Word-Sense-Induction-WSI"><a href="#Unsupervised-Approach-Word-Sense-Induction-WSI" class="headerlink" title="Unsupervised Approach:Word Sense Induction(WSI)"></a>Unsupervised Approach:Word Sense Induction(WSI)</h3><p>It is actually a clustering of word senses. </p><ol><li>For each token(sense) of a word in the corpus, use context word vector \(\vec{c}\) to represent it. </li><li>Do clustering s.t. there is N clusters and each token \(\vec{c}\) is assigned to a cluster. Each cluster defines a sense.</li><li>Recompute the center s.t. the center vector \(\vec{s_j}\) represent a sense.</li></ol><p>To do word sense disambiguation:</p><ol><li>compute context word vector \(\vec{c}\) to represent the sense of the word. </li><li>Do clustering and assign the context vector to a cluster.</li></ol><p>All we need is a clustering algorithm and a distance metric between vectors.</p><p>A frequently used technique in language applications is known as agglomerative<br>clustering.</p><p>Recent algorithms have also used topic modeling algorithms like Latent Dirichlet Allocation (LDA), another way to learn clusters of words based on their distributions.</p><p>It is fair to say that no evaluation metric for this task has yet become standard.</p><h1 id="Word-Similarity-Thesaurus-Methods"><a href="#Word-Similarity-Thesaurus-Methods" class="headerlink" title="Word Similarity(Thesaurus Methods)"></a>Word Similarity(Thesaurus Methods)</h1><p>Word similarity refers to meaning(synonyms).<br>Word relatedness characterizes relationships(antonyms,synonyms).</p><h5 id="Path-length-based-Approach"><a href="#Path-length-based-Approach" class="headerlink" title="Path-length based Approach"></a>Path-length based Approach</h5><p>Thesaurus could be viewed as a graph.</p><p>The simplest thesaurus-based algorithms use the edge between words to measure similarity.</p><p>pathlen(c1, c2) = 1 + edges in the shortest path between the sense nodes c1 and c2.</p><p>path-length based similarity:<br>$$sim_{path}(c_1,c_2)=\frac{1}{pathlen(c_1, c_2)}$$</p><p>Path lengths are not the same in different level of the hierarchy.<br>It is possible to refine path-based algorithms with normalizations based on depth in the hierarchy. In general an approach that independently represent the distance associated with each edge it is preferred.</p><p>For data without sense tag(words are not presented according to their senses), measure similarity according to senses of words. If there is a pair of senses is similar, then two words are similar.</p><p>$$word_{sim}(w_1,w_2)=\max_{c_1\in senses(w_1)\  c_2\in senses(w_2)} sim(c_1, c_2)$$</p><h5 id="information-content-word-similarity-algorithms"><a href="#information-content-word-similarity-algorithms" class="headerlink" title="information-content word-similarity algorithms"></a>information-content word-similarity algorithms</h5><p>still rely on the structure of the thesaurus but also add probabilistic information derived from a corpus.</p><p>The corpus is represented as a set of concepts. And it is represented as a tree  structure. The leaf nodes are basic concepts and parent nodes contain the children which is a superset of concepts. Each node is assigned a probability. So p(root) = 1.</p><p>$$P(c) = \frac{\sum_{w\in words(c)}count(w)}{N}$$</p><p>c is a specific concept. The probability of a concept is number of words in the concept divided by total number of words.</p><p><strong>information content</strong>: information content (IC) of a concept c</p><p>$$IC(c) = −\log P(c) $$</p><p>the lowest common subsumer(LCS) of two concepts:<br>LCS(c1, c2) = the lowest common subsumer,the lowest node in the hierarchy that subsumes both c1 and c2.(The lowest parent node of c1 and c2)</p><p><strong>Resnik similarity</strong>: similarity between two words is related to their common information; the more two words have in common, the more similar they are. Resnik proposes to estimate the common amount of information by the information content of the lowest common subsumer of the two nodes. </p><p>$$sim_{Resnik}(c_1,c_2)=-\log P(LCS(c_1,c_2))$$</p><p><strong>Lin similarity</strong></p><p>Similarity Theorem: The similarity between A and B is measured by the ratio<br>between the amount of information needed to state the commonality of A and<br>B and the information needed to fully describe what A and B are.<br>$$sim_{Lin}(A,B)=\frac{common(A,B)}{description(A,B)}$$</p><p>the information in common between two concepts is twice the information in the lowest common subsumer LCS(c1, c2). Adding in the above definitions of the information content of thesaurus concepts<br>$$sim_{Lin}(C_1,C_2)=\frac{2\times \log P(LCS(c_1,c_2))}{\log P(c_1)+\log P(c_2)}$$</p><p><strong>Jiang-Conrath distance</strong> express distance rather than similarity, work as well as or better than all the other thesaurus-based methods:</p><p>$$dist_{JC}(c_1, c_2) = 2\times \log P(LCS(c_1, c_2))−(\log P(c_1) +\log P(c_2)) $$</p><p>It could be transferred to similarity by take reciprocal.<br>$$sim_{JC}=\frac{1}{dist_{JC}}$$</p><p><strong>dictionary-based method</strong>: This method makes use of glosses, which are, in general, a property of dictionaries rather than thesauruses. Two concepts/senses are similar if their glosses contain overlapping words.</p><p>For each n-word phrase that occurs in both glosses, Extended Lesk adds in a<br>score of \(n^2\).(the relation is non-linear because of the Zipfian relationship between lengths of phrases and their corpus frequencies; longer overlaps are rare, so they should be weighted more heavily)</p><p>Given such an overlap function, when comparing two concepts (synsets), Extended<br>Lesk not only looks for overlap between their glosses but also between the<br>glosses of the senses that are hypernyms, hyponyms, meronyms, and other relations<br>of the two concepts. </p><p>If we just considered hyponyms and defined<br>gloss(hypo(A)) as the concatenation of all the glosses of all the hyponym senses of<br>A, the total relatedness between two concepts A and B might be</p><p>$$similarity(A,B) = overlap(gloss(A), gloss(B))+overlap(gloss(hypo(A)), gloss(hypo(B)))+overlap(gloss(A), gloss(hypo(B)))+overlap(gloss(hypo(A)),gloss(B))$$</p><p>Extended Lesk overlap measure:</p><p>$$sim_{eLESK}(c_1,c_2) =\sum_{r,q\in RELS}overlap(gloss(r(c_1)),gloss(q(c_2)))$$</p><p>RELS is the set of possible relations whose glosses we compare. Possible relations are  like hypernyms, hyponyms, meronyms, and other relations of the two concepts.</p><h2 id="Evaluating-Thesaurus-Based-Similarity"><a href="#Evaluating-Thesaurus-Based-Similarity" class="headerlink" title="Evaluating Thesaurus-Based Similarity"></a>Evaluating Thesaurus-Based Similarity</h2><p>The most common intrinsic evaluation metric computes the correlation coefficient between an algorithm’s word similarity scores and word similarity ratings assigned by humans. </p><p>Zipf’s law states that given some corpus of natural language utterances, the frequency of any word is inversely proportional to its rank in the frequency table.The most frequent word will occur approximately twice as often as the second most frequent word, three times as often as the third most frequent word.</p><h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p><a href="https://en.wikipedia.org/wiki/Zipf%27s_law" target="_blank" rel="noopener">Zipf’s law</a></p>]]></content>
      
      
        <tags>
            
            <tag> NLP </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>vector_semantics</title>
      <link href="/2018/07/05/vector-semantics/"/>
      <url>/2018/07/05/vector-semantics/</url>
      <content type="html"><![CDATA[<h2 id="Pointwise-Mutual-Information-PMI"><a href="#Pointwise-Mutual-Information-PMI" class="headerlink" title="Pointwise Mutual Information (PMI)"></a>Pointwise Mutual Information (PMI)</h2><p>Normal count-based word-context matrix would provide a lot of useless information. i.e.: the entry (apple, the) is large but provide useless information.</p><p>Instead we’d like context words that are particularly informative about the target<br>word. The best weighting or measure of association between words should tell us<br>how much more often than chance the two words co-occur.</p><p>mutual information </p><p>The pointwise mutual information is a measure of how often two events x and y occur, compared with what we would expect if they were independent:<br>$$I(x,y)=\log_2\frac{P(x, y)}{p(x)p(y)}$$</p><p>The pointwise mutual information of a word w and a cotext word c is:<br>$$PMI(w,c)=\log_2\frac{P(w, c)}{p(w)p(c)}$$</p><p>The ratio gives us an estimate of<br>how much more the target and feature co-occur actually than just by chance.</p><p><strong>Positive PMI</strong>: use 0 to substitute negetive PMI. It is used commonly because negative PMI is unreliable. Negative PMI means that the two words co-occur less than expectation which could be due to the small corpora.</p><p>A normal count-based co-occurrence matrix could be turned into PPMI matrix.</p><p><strong>Problem</strong>:biased toward infrequent words because the demoninator which is the frequency of the word is low.</p><p>To solve this problem,change the computation for P(c).</p><p>$$PPMI_\alpha(w,c)=\max(\log_2\frac{P(w, c)}{p(w)p_\alpha(c)},0)$$<br>$$p_\alpha(c) = \frac{count(c)^\alpha}{\sum_ccount(c)^\alpha}$$</p><p>Usually \(\alpha\)=0.75 drawing on a similar weighting used for skipgrams.This increases the probability assigned to rare<br>contexts and solve this problem.</p><p>Another solutio is Laplace smoothing.</p><h3 id="TF-IDF"><a href="#TF-IDF" class="headerlink" title="TF-IDF"></a>TF-IDF</h3><p>IDF is used to give a higher weight to rare words because they are likely to present more information.</p><p>$$idf_i = \log (\frac{N}{df_i})$$</p><p>Combining term frequency with IDF results in a scheme known as tf-idf weighting of the value for word i in document j,\(w_{ij}\):\</p><p>$$w_{ij}=tf_{ij}idf_i$$</p><p>The tf-idf weighting is by far the dominant way of weighting co-occurrence matrices in information retrieval, but also plays a role in many other aspects of natural language processing including summarization.</p><h3 id="t-test"><a href="#t-test" class="headerlink" title="t-test"></a>t-test</h3><h2 id="Similarity-Measure-for-vectors-binary"><a href="#Similarity-Measure-for-vectors-binary" class="headerlink" title="Similarity Measure for vectors(binary)"></a>Similarity Measure for vectors(binary)</h2><p><strong>Jaccard similarity</strong>:<br>$$sim_{Jaccard}=\frac{\sum_{i=1}^N\min(v_i,w_i)}{\sum_{i=1}^N\max(v_i,w_i)}$$</p><p>$$J(A,B)=\frac{|A\cap B|}{|A\cup B|}$$</p><p>The min of \(v_i\) and \(w_i\)means if a feature exists in one vector but not the other vector, the result would be zero. The<br>denominator can be viewed as a normalizing factor.</p><p><strong>Dice measure</strong>:<br>$$sim_{Dice}=\frac{2 \times \sum_{i=1}^N\min(v_i,w_i)}{\sum_{i=1}^N(v_i+w_i)}$$</p><p><strong>KL divergence</strong><br>if two vectors, \(\vec{v}\) and \(\vec{w}\), each express a probability<br>distribution (their values sum to one), then they are are similar to the extent that these probability distributions are similar.</p><p>Given two probability distribution or vectors P and Q:</p><p>$$D(P||Q) = \sum_xP(x)\log \frac{P(x)}<br>{Q(x)}$$</p><p>Unfortunately, the KL-divergence is undefined when Q(x) = 0 and P(x) \(\neq\) 0, which is a problem since these word-distribution vectors are generally quite sparse.</p><p>Jensen-Shannon divergence solves this problem.<br>$$JS(P||Q)=D(P|\frac{Q+P}{2})+D(Q|\frac{Q+P}{2})$$</p><h3 id="Using-syntax-to-define-a-word’s-context"><a href="#Using-syntax-to-define-a-word’s-context" class="headerlink" title="Using syntax to define a word’s context"></a>Using syntax to define a word’s context</h3><p>Instead of defining a word’s context by nearby words, we could instead define it by<br>the syntactic relations of these neighboring words. i.e.: the word duty could be represented by a bunch of combinations like additional,administrative(adj) or assert, assign(verb). </p><h3 id="Evaluating-Vector-Models"><a href="#Evaluating-Vector-Models" class="headerlink" title="Evaluating Vector Models"></a>Evaluating Vector Models</h3><p>test their performance on similarity, and in particular on computing the correlation between an algorithm’s word similarity scores and word similarity ratings<br>assigned by humans.</p>]]></content>
      
      
        <tags>
            
            <tag> NLP </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Hierarchical_Softmax</title>
      <link href="/2018/07/04/Hierarchical-Softmax/"/>
      <url>/2018/07/04/Hierarchical-Softmax/</url>
      <content type="html"><![CDATA[<h3 id="Hierarchical-softmax"><a href="#Hierarchical-softmax" class="headerlink" title="Hierarchical softmax"></a>Hierarchical softmax</h3><p>It truns the normal softmax to a tree structure to avoid computing every context word with the center word.</p><p>Normal softmax requires normalization which is extremely expensive especially in the case of Natural Language Processing that there are usually millions or billions of tokens in the corpus. Normal softmax would squeeze the values of these millions or billions of tokens into a probability distribution each time predicting the context word.</p><p>Normal softmax computes P(Y |X) directly which needs normalization, the author chooses to assign Y to different clusters such that there is a function mapping X to different clusters. Given the cluster, compute the conditional probability to avoid normalization over the entire X.<br>$$P(Y = y|X = x) =P(Y |C = c(Y ), X)P(C =c(Y )|X)$$</p><p>Prove:<br>$$P(Y |X) = \sum_i P(Y, C = i|X) = \sum_i P(Y |C =i, X)P(C = i|X) = P(Y |C = c(Y ), X)P(C =c(Y )|X)$$</p><p>C(Y) is a function to classify Y into C classes. \(P(Y |C = c(Y ), X)P(C =c(Y )|X)\) is equivalent to \(\sum_i P(Y |C =i, X)P(C = i|X)\) if every Y is classified into a class and the probablities of assign a Y to a cluster are multiplied together.</p><p>To utilize the architecture of binary trees, do hierarchical clustering such that each time two clusters are mergerd. Initially each word is a cluster. As a result, each level consists of a number of cluster. From the root to the leaf, multiply the probabilities together and we get the probability.</p><p>Each word v must be represented by a bit vector \((b_1(v), . . . b_m(v))\) (where m depends on v)</p><p>$$P(v|w_{t−1}, . . . , w_{t−n+1}) =\prod_{j=1}^mP(b_j(v)|b_1(v), . . . , b_{j−1}(v), w_{t−1}, . . . , w_{t−n+1})$$</p><p>\(b_j(v)\) is the intermediate vector in the tree. The intermediate node is in fact a cluster. Each leaf node is a word.</p><p>Each intermediate note could be viewed as a group of similar-meaning words. Each node is associated with a feature vector.</p><p>$$P(b = 1|node, w_{t−1}, . . . , w_{t−n+1}) =sigmoid(\alpha_{node} + \beta’\cdot tanh(c + Wx + UN_{node}))$$</p>]]></content>
      
      
        <tags>
            
            <tag> ML </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>sql</title>
      <link href="/2018/07/03/sql/"/>
      <url>/2018/07/03/sql/</url>
      <content type="html"><![CDATA[<p>RDBMS stands for Relational Database Management System.</p><p>Every table is broken up into smaller entities called fields which is a column in a table designed to maintain specific information about every record in the table.</p><p>A record, also called a row, is each individual entry that exists in a table. A record is a horizontal entity in a table.</p><p>A column is a vertical entity in a table that contains all information associated with a specific field in a table.</p><p>A database most often contains one or more tables. Each table is identified by a name. Tables contain records (rows) with data.</p><p>Semicolon is the standard way to separate each SQL statement in database systems that allow more than one SQL statement to be executed in the same call to the server.</p><h3 id="Keywords"><a href="#Keywords" class="headerlink" title="Keywords"></a>Keywords</h3><ul><li>COUNT SELECT COUNT(Country) FROM Customers; Return the number of country from table Customers</li><li>Distinct SELECT Country FROM Customers; Selects all values from the “Country” column in the “Customers” table.</li><li>WHERE The WHERE clause is used to extract only those records that fulfill a specified condition. SELECT * FROM Customers WHERE Country=’Mexico’; Selects all the customers from the country “Mexico”, in the “Customers” table.</li><li>AND operator displays a record if all the conditions separated by AND is TRUE.<br>The OR operator displays a record if any of the conditions separated by OR is TRUE.The NOT operator displays a record if the condition(s) is NOT TRUE.</li><li>ORDER BY</li><li>INSERT INTO</li><li>IS NULL and IS NOT NULL to test null values</li><li>SELECT TOP = Mysql SELECT column_name(s) FROM table_name WHERE condition LIMIT number;</li><li>LIKE The LIKE operator is used in a WHERE clause to search for a specified pattern in a column. </li><li>%:The percent sign represents zero, one, or multiple characters </li><li>_:The underscore represents a single character</li><li>IN: = multiple OR conditions.</li><li>BETWEEN: selects values within a given range. The values can be numbers, text, or dates.It is inclusive: begin and end values are included. </li><li>SQL aliases are used to give a table, or a column a temporary name. An alias only exists for the duration of the query.</li><li>JOIN: SELECT column_name(s) FROM table1 INNER JOIN table2 ON table1.column_name = table2.column_name;</li><li>UNION: combine the result-set of two or more SELECT statements. </li><li>GROUP BY: used with aggregate functions (COUNT, MAX, MIN, SUM, AVG) to group the result-set by one or more columns.</li><li>The HAVING clause was added to SQL because the WHERE keyword could not be used with aggregate functions.</li><li>The EXISTS operator is used to test for the existence of any record in a subquery.</li><li>The ANY operator returns true if any of the subquery values meet the condition.</li><li>The ALL operator returns true if all of the subquery values meet the condition.</li><li>The SELECT INTO statement copies data from one table into a new table.</li><li>The INSERT INTO SELECT statement copies data from one table and inserts it into another table.</li></ul><h3 id="Notes"><a href="#Notes" class="headerlink" title="Notes"></a>Notes</h3><ul><li>SQL keywords are NOT case sensitive: select is the same as SELECT</li><li>SQL requires single quotes around text values. Numeric fields should not be enclosed in quotes:</li><li>(INNER) JOIN: Returns records that have matching values in both tables</li><li>LEFT (OUTER) JOIN: Return all records from the left table, and the matched records from the right table</li><li>RIGHT (OUTER) JOIN: Return all records from the right table, and the matched records from the left table</li><li>FULL (OUTER) JOIN: Return all records when there is a match in either left or right table</li><li>Each SELECT statement within UNION must have the same number of columns.The columns must also have similar data types.The columns in each SELECT statement must also be in the same order</li></ul>]]></content>
      
      
        <tags>
            
            <tag> Database sql </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Semantics_with_Dense_Vectors</title>
      <link href="/2018/07/03/Semantics-with-Dense-Vectors/"/>
      <url>/2018/07/03/Semantics-with-Dense-Vectors/</url>
      <content type="html"><![CDATA[<h2 id="Skip-gram-Model"><a href="#Skip-gram-Model" class="headerlink" title="Skip-gram Model"></a>Skip-gram Model</h2><p>Given a center word, predict its neighbor word(context word). There are two matrices, one is context matrix and the other is word matrix.</p><p>The training objective of the Skip-gram model is to find word representations that are useful for predicting the surrounding words in a sentence or a document.<br>The objective of the Skip-gram model is to maximize the average log probability \(\frac{1}{T}\sum_{t=1}^T\sum_{−c≤j≤c,j\neq 0}\log p(w_{t+j}|w_t) \)</p><p>The basic Skip-gram formulation defines \(p(w_{t+j} |w_t)\) using the softmax function:<br>$$p(w_{O}|w_I) = \frac{exp({v’_{w_O}}^Tv_{w_I})}{\sum_{w=1}^Wexp({v’<em>w}^Tv</em>{w_I})}$$</p><h2 id="Negative-Sampling"><a href="#Negative-Sampling" class="headerlink" title="Negative Sampling"></a>Negative Sampling</h2><p>Noise Contrastive Estimation (NCE). NCE posits that a good model should be able to differentiate data from noise by means of logistic regression. </p><p>While NCE can be shown to approximately maximize the log probability of the softmax, the Skipgram model is only concerned with learning high-quality vector representations, so we are free to<br>simplify NCE.<br>Here is <strong>Negative Sampling</strong>, its <strong>objective funtion</strong>:</p><p>$$\log\sigma({v’_{w_O}}^Tv_{w_I})+\sum_{i=1}^kE_{w_i\sim P_n(w)}[\log\sigma({-v’_{w_i}}^Tv_{w_I})]$$</p><p>The above objective function is used to replace every \(\log P(w_O|w_I )\) term in the Skip-gram objective. Thus the task is to<br>distinguish the target word \(w_O\) from draws from the noise distribution \(P_n(w)\) using logistic regression, where there are k negative samples for each data sample. k in the range 5–20 are useful for small training datasets, while for large datasets the k 2–5. The main difference between the Negative sampling and NCE is that NCE needs both samples and the numerical probabilities of the noise distribution, while Negative sampling uses only samples. And NCE approximately maximizes the log probability of the softmax, this property is not important for our application.</p><p>Essentially, the probability for selecting a word as a negative sample is related to its frequency, with more frequent words being more likely to be selected as negative samples.Raise to the power of 3/4 is an emprical result.</p><p>$$P(w_i) = \frac{  {f(w_i)}^{3/4}  }{\sum_{j=0}^{n}\left(  {f(w_j)}^{3/4} \right) }$$</p><p>To counter the imbalance between the rare and frequent words, we used a simple subsampling approach: each word \(w_i\)<br>in the training set is discarded with probability computed by the formula</p><p>$$p(w_i)=1-\sqrt{\frac{t}{f(w_i)}}$$</p><p>where \(f(w_i)\) is the frequency of word \(w_i\) and t is a chosen threshold, typically around \(10^{−5}\).</p><p>Another implementation:<br>$$p(w_i)=(\sqrt{\frac{z(w_i)}{0.001}}+1)\cdot \frac{0.001}{z(w_i)}$$</p><p>0.001 is the default sample value. Smaller values of ‘sample’ mean words are less likely to be kept. \(z(w_i)\) is the frequency of the word i.</p><ul><li>P(wi)=1.0 (100% chance of being kept) when z(wi)&lt;=0.0026. This means that only words which represent more than 0.26% of the total words will be subsampled.</li><li>P(wi)=0.5 (50% chance of being kept) when z(wi)=0.00746.</li></ul><p><strong>projection layer</strong> input is one-hot vector, multiplied by embedding layer, the output is the projection layer. The units in the projection layer are word vectors.</p><h5 id="Hyperparameters"><a href="#Hyperparameters" class="headerlink" title="Hyperparameters"></a>Hyperparameters</h5><p>a context window size L</p><h2 id="CBOW"><a href="#CBOW" class="headerlink" title="CBOW"></a>CBOW</h2><p>continuous bag of words </p><p>Reversed version of skip-grams, predicting the current word \(w_j\) from the context window of 2L words around it</p><p>$$p(w_{c,j}|w_j) = \frac{exp(c_k\cdot v_j)}{\sum_{i\in|V|}exp(c_i\cdot v_j)}$$</p><p>\(c_k\)means the \(k_{th}\) context word. \(v_j\)means the word vector of given word \(w_j\). The computing of demoninator \(\sum_{i\in|V|}exp(c_i\cdot v_j)\) is extremely expensive because it requires computing for each given word \(w_j\).</p><h3 id="Relationship-between-Word-Vectors"><a href="#Relationship-between-Word-Vectors" class="headerlink" title="Relationship between Word Vectors"></a>Relationship between Word Vectors</h3><p>Word vector matrix W and context word vector matrix C multiply together would produce a |V|*|V| matrix X.<br>Skip-gram’s optimal value occurs when<br>this learned matrix X is actually a version of the PMI matrix, with the values shifted<br>by logk (where k is the number of negative samples):<br>$$WC = X^{PMI} −\log k$$</p><p>In other words, skip-gram is implicitly factorizing a (shifted version of the) PMI<br>matrix into the two embedding matrices W and C, just as SVD did, albeit with a different kind of factorization.</p><p>Once the embeddings are learned, for each word \(w_i\), there is a word vector \(v_i\) and a context word vector \(c_i\). We can choose to throw away the C matrix and just keep W, as we did with SVD.<br>Alternatively we can add the two embeddings together, using the summed embedding<br>\(v_i + c_i\) as the new d-dimensional embedding, or we can concatenate them<br>into an embedding of dimensionality 2d.</p><p>As with the simple count-based methods like PPMI, the context window size<br>L effects the performance of skip-gram embeddings, and experiments often tune<br>the parameter L on a dev set. As with PPMI, window sizing leads to qualitative<br>differences: smaller windows capture more syntactic information, larger ones more<br>semantic and relational information. One difference from the count-based methods<br>is that for skip-grams, the larger the window size the more computation the algorithm requires for training.</p><h3 id="Properties-of-embeddings"><a href="#Properties-of-embeddings" class="headerlink" title="Properties of embeddings"></a>Properties of embeddings</h3><p><strong>Offsets</strong> between vector embeddings<br>can capture some relations between words.</p><h3 id="Brown-Clustering"><a href="#Brown-Clustering" class="headerlink" title="Brown Clustering"></a>Brown Clustering</h3><p>Brown clustering is an agglomerative clustering algorithm for deriving vector representations of words by clustering words based on their associations with the preceding or following words.</p><ul><li><ol><li>Each word is initially assigned to its own cluster.</li></ol></li><li><ol start="2"><li>merge each pair of clusters. The pair whose merger results in the smallest decrease in the likelihood of the corpus (according to the class-based language model) is merged.</li></ol></li><li><ol start="3"><li>Clustering proceeds until all words are in one big cluster</li></ol></li></ul><p>Each cluster contains words that are  contextually similar(similar meaning/sense).After clustering, a word can be represented by the binary string that corresponds to its path from the root node.<br>Each prefix represents a cluster that the word belongs to.These prefixes can then be used as a vector representation for the word; the shorter the prefix, the more abstract the cluster.</p><p>(i.e.:the string 0001 represents the names of common nouns for corporate executives {chairman, president}, 1 is verbs {run, sprint, walk}, and 0 is nouns.)</p><p>The length of the vector representation can thus be adjusted to fit the needs of the particular task. a 4-6 bit prefix to capture part of speech information and a full bit string to represent words. The first 8 or<br>9-bits of a Brown clustering perform well at grammar induction. Because they are<br>based on immediately neighboring words, Brown clusters are most commonly used<br>for representing the syntactic properties of words, and hence are commonly used as<br>a feature in parsers. Nonetheless, the clusters do represent some semantic properties as well.</p><p>Note that the naive version of the Brown clustering algorithm described above is<br>extremely inefficient — \(O(n^5)\): at each of n iterations, the algorithm considers each of \(O(n^2)\) merges, and for each merge, compute the value of the clustering by summing over \(O(n^2)\)terms. because it has to consider every possible pair of merges. In practice<br>we use more efficient \(O(n^3)\) algorithms that use tables to pre-compute the values for each merge.</p><p><strong>hard clustering</strong> algorithm:each word has only one cluster</p><h4 id="class-based-language-model"><a href="#class-based-language-model" class="headerlink" title="class-based language model"></a>class-based language model</h4><p>a model in which each word \(w\in V\) belongs to a class \(c\in C\) with a probability P(w|c).<br>Class based LMs assigns a probability to a pair of words \(w_{i−1}\) and \(w_i\) by modeling the transition between classes rather than between words:<br>$$P(w_i|w_{i−1}) = P(w_i|c_i)P(c_i|c_{i−1})$$</p><p>Given the class label of word \(c_{i-1})\), compute the transition probability and then given the new transition, the probability of current word \(w_i\).</p><p>The class-based LM can be used to assign a probability to an entire corpus given<br>a particularly clustering C as follows:</p><p>$$P(corpus|C) = \prod_{i−1}^nP(c_i<br>|c_{i−1})P(w_i|c_i)$$</p><p>Class-based language models are generally not used as a language model for applications like machine translation or speech recognition because they don’t work<br>as well as standard n-grams or neural language models.</p><h2 id="LSA-latent-semantic-analysis"><a href="#LSA-latent-semantic-analysis" class="headerlink" title="LSA(latent semantic analysis)"></a>LSA(latent semantic analysis)</h2><p>:applying SVD to the term-document matrix </p><p>LSA is a particular application of SVD to a |V| × c term-document matrix X representing |V| words and their co-occurrence with c documents or contexts.<br>SVD factorizes any such rectangular |V| × c matrix X into the product of three matrices<br>W, \(\sum\), and \(C^T\). In the matrix W, each of the w rows still represents a word, but each column represents one of m dimensions in a latent space, such that the m column vectors are orthogonal to each other and the columns are ordered by the amount of variance in the original dataset. The number of such dimensions m is the rank of X (the rank of a matrix is the number<br>of linearly independent rows). \(\sum\) is a diagonal matrix, with singular values<br>along the diagonal, expressing the importance of each dimension. The matrix<br>\(C^T\) still represents documents or contexts, but each row now represents one of the new latent dimensions and the m row vectors are orthogonal to each other.<br>By using only the first k dimensions instead of all m dimensions, the product of these 3 matrices becomes a least-squares approximation to the original X. Since the first dimensions encode the most variance, one way to view the reconstruction is as modeling the most important information in the original dataset.</p><p>Using only the top k dimensions leads to a reduced |V| ×k matrix \(W_k\), with one k-dimensioned row per word. This row now acts as a dense k-dimensional vector (embedding) representing that word, substituting for the very high-dimensional rows of the original X.</p><p>LSA implementations generally use a particular weighting of each co-occurrence cell that multiplies two weights called the local and global weights for each cell (i, j)—term i in document j. The local weight of each term i is its log frequency: log f(i, j) +1. The global weight of term i is a version of its entropy: $$1+\frac{\sum_jp(i,j)\log p(i,j)}{\log D}$$<br>D is the number of documents.</p><p><strong>Advantages</strong>: Solve the problem of one word multiple senses or one sense multiple words by reduce the demensionality and extract the key information. Information extraction is to project the original co-occurence data to a new axes which could be viewed as a semantic space.</p><p><strong>Disadvantages</strong>: SVD requires lots of time to compute.</p><h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p><a href="http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf" target="_blank" rel="noopener">Distributed Representations of Words and Phrases<br>and their Compositionality</a><br><a href="http://mccormickml.com/2017/01/11/word2vec-tutorial-part-2-negative-sampling/" target="_blank" rel="noopener">Word2Vec Tutorial Part 2 - Negative Sampling</a></p>]]></content>
      
      
        <tags>
            
            <tag> NLP SVD Skip-gram CBOW Brown Clustering </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Neural_Networks_and_Neural_Language_Model</title>
      <link href="/2018/07/01/Neural-Networks-and-Neural-Language-Model/"/>
      <url>/2018/07/01/Neural-Networks-and-Neural-Language-Model/</url>
      <content type="html"><![CDATA[<p>A neural network with one hidden layer can be shown to learn any function.</p><h3 id="Stochastic-gradient-descent"><a href="#Stochastic-gradient-descent" class="headerlink" title="Stochastic gradient descent"></a>Stochastic gradient descent</h3><p><strong><strong>is to choose a training example or a batch of examples to compute the gradients rather than use the entire training set.</strong></strong></p><h3 id="XOR-Problem"><a href="#XOR-Problem" class="headerlink" title="XOR Problem"></a>XOR Problem</h3><p><strong>not linearly separable</strong><br>a hidden layer rotates the axis or converts the original data to another plane.</p><h3 id="Cross-Entropy-Loss"><a href="#Cross-Entropy-Loss" class="headerlink" title="Cross Entropy Loss"></a>Cross Entropy Loss</h3><p>$$L(\hat{y}, y) = \log p(\hat{y}_i) $$<br>If \(\hat{y}\) != y, it doesn’t contribute to the loss. Only the true class would contribute the loss. If \(p(\hat{y})\) =1, \(\log p(\hat{y}_i)=0\). If \(p(\hat{y})\) =0, \(\log p(\hat{y}_i)=\infty\).<br>\(\hat{y}\) means output of the network.</p><h3 id="Embedding-Layer"><a href="#Embedding-Layer" class="headerlink" title="Embedding Layer"></a>Embedding Layer</h3><p>Could be understood as a weight matrix. Because the one-hot vector is multiplied by the embedding layer to get the word vector, so the embedding layer is actually also a weight matrix. Via back propagation, it could also be trained simultaneously with other weights in the neural network.</p>]]></content>
      
      
    </entry>
    
    <entry>
      <title>Logistic_Regression</title>
      <link href="/2018/06/29/Logistic-Regression/"/>
      <url>/2018/06/29/Logistic-Regression/</url>
      <content type="html"><![CDATA[<h2 id="Binomial-Logistic-Regression"><a href="#Binomial-Logistic-Regression" class="headerlink" title="Binomial Logistic Regression"></a>Binomial Logistic Regression</h2><p>$$p(1|x) = \frac{\exp(\vec{w} \cdot \vec{x})}{1+\exp(\vec{w} \cdot \vec{x})}$$</p><p>$$p(0|x) = \frac{1}{1+\exp(\vec{w} \cdot \vec{x})}$$</p><p><strong>odds</strong>: the probability that an event occur divided by the probability that an event doesn’t occur. \(\frac{p}{1-p}\)</p><p><strong>log odds</strong>: take log of odds. \(\log \frac{p}{1-p}\). In terms of logistic regression, \(\log \frac{p}{1-p}=\vec{w} \cdot \vec{x}\).</p><p>Actually logistic regression turns the linear function \(\vec{w} \cdot \vec{x}\) into probability distribution. So logistic regression is acutually a linear classification model with some operations to turn the output into probability distribution. The final output label is the one with the highest value.</p><h3 id="Parameters-Estimation"><a href="#Parameters-Estimation" class="headerlink" title="Parameters Estimation"></a>Parameters Estimation</h3><p>Use gradient descent.</p><h2 id="Multinomial-Logistic-Regression"><a href="#Multinomial-Logistic-Regression" class="headerlink" title="Multinomial Logistic Regression"></a>Multinomial Logistic Regression</h2><p>multinomial logistic regression, sometimes referred to within language processing as MaxEnt entropy modeling, MaxEnt for short. Logistic regression belongs to the family of classifiers known as the exponential or log-linear classifiers.<br>Technically, logistic regression refers to a classifier that classifies<br>an observation into one of two classes, and multinomial logistic regression is used when classifying into more than two classes</p><p>First, wrap the exp function around the weight-feature dot-product \(w\cdot f\) , which will make the values positive.</p><p>A discriminative model discriminative<br>model takes this direct approach, computing P(y|x) by discriminating among the different possible values of the class y rather than first computing a likelihood.</p><p>Logistic Regression </p><p>$$p(c|x) = \frac{\exp(\sum_iw_if_i(c,x))}{\sum_{c’ \in C}\exp(\sum_{i=1}^N w_if_i(c’,x)}$$</p><p>In vector from:</p><p>$$p(c|x) = \frac{\exp(\vec{w} \cdot \vec{f(c,x)})}{\sum_{c’ \in C}\exp(\vec{w}\cdot \vec{f(c,x)})}$$</p><p>Here c actually range from 1 to N+1. And by default \(\exp(\sum_{i=1}^N w_if_i(N+1,x)=0\)</p><p>exp is to make to result greater than 0.<br>\(f_i(c, x)\), meaning feature i for a particular class c for a given observation x. In NLP, x is usually a document. Feature i usually means whether a specific word \(x_i\) has shown in the document for a particular class. \(w_i\) is the weight corresponding to the feature i. For example, in sentiment analysis, classes are 0 and 1 corresponding to positive and negative. The word best is a feature, namely \(\ f_1\), its value for class 1 coube be +10 and -10 for class 0.</p><p>Computing the actual probability rather than just choosing the best class is useful when the classifier is embedded in a larger system. Otherwise compute the nominater is sufficient to do classification. \(\hat{c}={argmax}<em>{c\in C}\sum</em>{i=1}^N w_if_i(c,x)\)</p><h3 id="Learning-weights"><a href="#Learning-weights" class="headerlink" title="Learning weights"></a>Learning weights</h3><p>The intuition is to choose weights that make the classes of the training examples more likely. Indeed, logistic regression is trained with conditional maximum likelihood estimation. This means we choose the parameters w that maximize the (log) probability of the y labels in the training data given the observations x.</p><p>$$\hat{w} = {argmax}_w\sum_jlogP(y^{(j)}|x^{(j)})$$</p><p>It means given a training set, we choose weights that maximize the probability of \(j^{th}\) training example \(x^{(j)}\) is classified to the lable \(y^{(j)}\).</p><p>The objective function L that we are maximizing is thus<br>$$L(w) = \frac{\exp(\sum_i^Nw_if_i(y^{(j)},x^{(j)}))}{\sum_{y’ \in Y}\exp(\sum_{i=1}^N w_if_i(y’^{(j)},x^{(j)})}$$</p><h3 id="Max-Entropy"><a href="#Max-Entropy" class="headerlink" title="Max Entropy"></a>Max Entropy</h3><p>When there is no training data available, the model assign the same probability to each class. If there is training data, the model try to reach the max entropy with the constraint that satisfy the training data.</p><h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p><a href="https://web.stanford.edu/~jurafsky/slp3/" target="_blank" rel="noopener">Speech and Language Processing</a></p><p><a href="http://net.pku.edu.cn/~course/cs410/2015/resource/book/2012-book-StatisticalLearning-LH.pdf" target="_blank" rel="noopener">统计学习方法</a></p>]]></content>
      
      
        <tags>
            
            <tag> ML </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Machine_Learning</title>
      <link href="/2018/06/29/Machine-Learning/"/>
      <url>/2018/06/29/Machine-Learning/</url>
      <content type="html"><![CDATA[<p><strong>contingency table</strong> consists of 4 entries: True Positive, True Negative, False Positive, False Negative.</p><p>Accuracy doesn’t work well when<br>the classes are unbalanced.</p><p>Precision measures the percentage of the items that the system detected that are in fact positive. In other words, precision measures the percentage that the system makes correct classfication over total samples that are classified as correct. Precision is defined as<br>$$ Precision =\frac{true\ positives}{true\ positives + false\ positives}$$</p><p>Recall measures the percentage of items actually present in the input that were<br>correctly identified by the system. In other words, recall measures the percentage that the system makes correct classfication over total correct samples. Recall is defined as<br>$$Recall =\frac{true\ positives}{true\ positives + false\ negatives}$$</p><p>precision and recall, unlike accuracy, emphasize true positives: finding the things that we are supposed to be looking for.<br>In practice, we generally combine precision and recall into a single metric called<br>F-measure the F-measure that is defined as:<br>$$F_\beta =\frac{(\beta^2 +1)PR}{\beta^2P+R}$$</p><p>The β parameter differentially weights the importance of recall and precision. Values of β &gt; 1 favor recall, while values of β &lt; 1 favor precision. When β = 1, precision and recall are equally balF1<br>anced; this is the most frequently used metric, and is called \(F_{\beta}=1\) or just \(F_1\).F-measure comes from a weighted harmonic mean of precision and recall.</p><p>Harmonic mean is used because it is a conservative metric; the harmonic mean of<br>two values is closer to the minimum of the two values than the arithmetic mean is.<br>Thus it weighs the lower of the two numbers more heavily.</p><p>In <strong>any-of</strong> or <strong>multi-label</strong> classification, each document or item can be assigned more than one label. Solve any-of classification by building separate binary classifiers for each class c. Given a test document or item d, then each classifier makes their decision independently, and we may assign multiple labels to d.</p><p><strong>one-of</strong> or <strong>multinomial</strong> classification, multinomial classification in which the classes are mutually exclusive and each document or item appears in<br>exactly one class. Build a separate binary classifier trained on positive<br>examples from c and negative examples from all other classes. Now given a test<br>document or item d, we run all the classifiers and choose the label from the classifier with the highest score. </p><p>In <strong>macroaveraging</strong>, we compute the performance for each class, and then average over classes. In <strong>microaveraging</strong>, we collect the decisions for all classes into a single contingency table, and compute precision and recall from that table(sum the number of decision like true for all classfiers and divide by total number of decision). A microaverage is dominated by the more frequent class, since the counts are pooled. The macroaverage better reflects the statistics of the smaller classes, and so is more appropriate when performance on all the classes is equally important.</p><p>The only problem with cross-validation is that because all the data is used for<br>testing, we need the whole corpus to be blind; we can’t examine any of the data<br>to suggest possible features and in general see what’s going on. But looking at the<br>corpus is often important for designing the system. For this reason, it is common<br>to create a fixed training set and test set, then do 10-fold cross-validation inside the training set, but compute error rate the normal way in the test set.</p><h3 id="regularization-used-to-penalize-large-weights"><a href="#regularization-used-to-penalize-large-weights" class="headerlink" title="regularization: used to penalize large weights"></a><strong>regularization</strong>: used to penalize large weights</h3><p>L1 regularization is called ‘the lasso’ or lasso regression and L2 regression is called ridge regression, and both are commonly used in language processing. L2 regularization is easier to optimize because of its simple derivative, while L1 regularization is more complex (the derivative of |w| is noncontinuous<br>at zero). </p><p>But where L2 prefers weight vectors with many small weights, L1 prefers sparse solutions with some larger weights but many more weights set to zero. Thus L1 regularization leads to much sparser weight vectors, that is, far fewer features.</p><p>L2 regularization:$$\sum_{j=1}^Nw_j^2$$</p><p>L1 regularization:$$\sum_{j=1}^N|w_j|$$</p><p>Both L1 and L2 regularization have Bayesian interpretations as constraints on the prior of how weights should look. L1 regularization can be viewed as a Laplace<br>prior on the weights. L2 regularization corresponds to assuming that weights are<br>distributed according to a gaussian distribution with mean µ = 0.</p><p>The regularization technique is useful for avoiding overfitting by removing or downweighting features that are unlikely to generalize well. Many kinds of classifiers including naive Bayes do not have regularization, and so instead feature selection is used to choose the important features and remove the rest. The basis of feature selection is to assign some metric<br>of goodness to each feature, rank the features, and keep the best ones. The number of features to keep is a meta-parameter that can be optimized on a dev set.</p><h3 id="Feature-Selection"><a href="#Feature-Selection" class="headerlink" title="Feature Selection"></a>Feature Selection</h3><p>Features are generally ranked by how informative they are about the classification decision. A very common metric is information gain. Information gain tells us how many bits of information the presence of the word gives us for guessing the class, and can be computed as follows (where ci is the ith class and ¯w means that a document does not contain the word \(w^-\)):</p><p>While feature selection is important for unregularized classifiers, it is sometimes<br>also used in regularized classifiers in applications where speed is critical, since it is often possible to get equivalent performance with orders of magnitude fewer features.</p><p>The overly strong conditional independence assumptions of Naive Bayes mean that if two features are correlated naive Bayes will multiply them, overestimating the evidence. Logistic regression is much more robust to correlated features; if two features f1 and f2 are perfectly correlated, regression will simply assign half the weight to w1 and half to w2.</p><p>naive Bayes works extremely well (even better than logistic regression or SVMs) on small datasets or short documents.<br>Furthermore, naive Bayes is easy to implement and very fast to train. Nonetheless, algorithms like logistic regression and SVMs generally work better on larger documents<br>or datasets.</p><h3 id="bias-variance-tradeoff"><a href="#bias-variance-tradeoff" class="headerlink" title="bias-variance tradeoff"></a>bias-variance tradeoff</h3><p>The <strong>bias of a classifier</strong> indicates how accurate it is at modeling different training sets.<br>The <strong>variance of a classifier</strong> indicates how much its decisions are affected by small changes<br>in training sets.</p><p>Models with <em>low bias</em> (like SVMs with polynomial or RBF kernels) are very accurate at modeling the training data. Models with <em>low variance</em> (like naive<br>Bayes) are likely to come to the same classification decision even from slightly different training data. </p><p>low-bias models tend to overfit, and do not generalize well to very different test sets.<br>low-variance models tend to generalize so well that they may not have sufficient accuracy.<br>Thus model trades off bias and variance. Adding more features decreases bias by making it possible to more accurately model the training data, but<br>increases variance because of overfitting. Regularization and feature selection are<br>ways to improve (lower) the variance of classifier by downweighting or removing<br>features that are likely to overfit.</p><p>In addition to the choice of a classifier, the key to successful classification is the<br>design of appropriate features. Features are generally designed by examining the<br>training set with an eye to linguistic intuitions and the linguistic literature on the domain. </p><p>For some tasks it is especially helpful to build complex features that are combinations<br>of more primitive features. For logistic regression and naive Bayes these<br>combination features or feature interactions have to be designed by hand. </p><p><strong>feature interactions</strong><br>Some other machine learning models can automatically model the interactions<br>between features. For tasks where these combinations of features are important<br>(especially when combination of categorical features and real-valued features might<br>be helpful), the most useful classifiers may be such classifiers,including Support<br>SVMs Vector Machines (SVMs) with polynomial or RBF kernels, and random forests</p><h3 id="dimensionality-reduction-PCA-SVD"><a href="#dimensionality-reduction-PCA-SVD" class="headerlink" title="dimensionality reduction(PCA,SVD)"></a>dimensionality reduction(PCA,SVD)</h3><p>First rotate the axes of the original dataset into a new space. The new space is chosen so that the highest order dimension<br>captures the most variance in the original dataset, the next dimension captures the next most variance, and so on. In this new space, the data if represented with a smaller number of dimensions and still<br>capture much of the variation in the original data.</p><p>For binary classification, sigmoid would suffice the requirement.</p><h3 id="Softmax-Logistic-Regression"><a href="#Softmax-Logistic-Regression" class="headerlink" title="Softmax(Logistic Regression)"></a>Softmax(Logistic Regression)</h3><p>Linear decision boundary.</p><h3 id="Bias-Term"><a href="#Bias-Term" class="headerlink" title="Bias Term"></a>Bias Term</h3><p>Bias is significant because it allows the activation function to shift left and right. The weight is to change the steepness of the activation function.</p><p><a href="https://stackoverflow.com/questions/2480650/role-of-bias-in-neural-networks" target="_blank" rel="noopener">Role of Bias in Neural Networks</a></p><h3 id="Max-margin-Objective-function"><a href="#Max-margin-Objective-function" class="headerlink" title="Max-margin Objective function"></a>Max-margin Objective function</h3>]]></content>
      
      
        <tags>
            
            <tag> ML </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Sentiment_Classification_Naive_Bayes</title>
      <link href="/2018/06/29/Sentiment-Classification/"/>
      <url>/2018/06/29/Sentiment-Classification/</url>
      <content type="html"><![CDATA[<p>In most text classification<br>applications, however, using a stop word list doesn’t improve performance,<br>and so it is more common to make use of the entire vocabulary and not use a stop<br>word list</p><h3 id="Naive-Bayes-Classifier-for-Sentiment-Analysis"><a href="#Naive-Bayes-Classifier-for-Sentiment-Analysis" class="headerlink" title="Naive Bayes Classifier for Sentiment Analysis"></a>Naive Bayes Classifier for Sentiment Analysis</h3><p>Correct estimation implies accurate prediction, but accurate prediction does not imply correct estimation. NB classifiers estimate badly, but often classify well.</p><p>The assumption that terms are independent does not hold. But in terms of classification, the class that a document belongs is usually irrelevant to position. This somehow reduce the influence of the dependence.</p><p>i.e.: Finance industry is promising in HK.<br>HK finance is booming.</p><p>$$C_{NB}=\underset{c\in C}{argmax}\ logP(c)+\sum_{i \in positions}logP(w_i<br>|c)$$</p><p>Each word \(w_i\) could be viewed as a feature for a specific document.</p><h3 id="Maximum-Likelihood-to-train-Naive-Bayes"><a href="#Maximum-Likelihood-to-train-Naive-Bayes" class="headerlink" title="Maximum Likelihood to train Naive Bayes"></a>Maximum Likelihood to train Naive Bayes</h3><p>$$\hat{p}(c)=\frac{N_c}{N_{doc}}$$</p><p>The standard solution for an unknown word that doesn’t show up in the training set is to ignore such words—remove them from the test document and not include any probability for them at all.</p><p>Laplace smoothing is usually replaced by more sophisticated smoothing algorithms in language modeling, it is commonly used in naive Bayes text categorization to deal with zero count.</p><p>$$\hat{P}(w_i|c) = \frac{count(w_i, c) +1}{<br>(\sum_{w\in V}(count(w, c)) +|V|}$$</p><p><strong><strong><em>Note that the vocabulary V consists of the union of all the word types in all classes, not just the words in one class. If the denominator is the word in the class \(c_i\), then given a class, the probability of the sentence shows up is 1. That is meaningless.</em></strong></strong> </p><h3 id="Binary-Multinominal-Naive-Bayes-The-Bernoulli-model"><a href="#Binary-Multinominal-Naive-Bayes-The-Bernoulli-model" class="headerlink" title="Binary Multinominal Naive Bayes(The Bernoulli model)"></a>Binary Multinominal Naive Bayes(The Bernoulli model)</h3><p>Whether a word occurs or not seems to matter more than its frequency.</p><p>The feature in this model is not term frequency anymore. It is whether a word has shown up in the sentence.</p><p>Smoothing could also be employed in this model.</p><p>First,it remove all duplicate words such that each sentence contains only one distinct word before concatenating them into the single big document. </p><p>Second deal with negation during text normalization. Typically adding negation prefix such as NOT_ to every word. i.e., like -&gt; Not_like.</p><p>In some situations we might have insufficient labeled training data. In such cases we can instead derive the positive and negative word features from sentiment lexicons, lists of words that are pre-annotated with positive or negative sentiment.</p><h3 id="Naive-Bayes-as-a-Language-Model"><a href="#Naive-Bayes-as-a-Language-Model" class="headerlink" title="Naive Bayes as a Language Model"></a>Naive Bayes as a Language Model</h3><p>If we use only individual word features, and we use all of the words in the text<br>(not a subset), then naive Bayes has an important similarity to language modeling.<br>Specifically, <strong><strong>a naive Bayes model can be viewed as a set of class-specific unigram language models</strong></strong>, in which the model for each class instantiates a unigram language model.</p><p><strong>contingency table</strong> consists of 4 entries: True Positive, True Negative, False Positive, False Negative.</p><p>Accuracy doesn’t work well when<br>the classes are unbalanced.</p><p>Precision measures the percentage of the items that the system detected that are in fact positive. In other words, precision measures the percentage that the system makes correct classfication over total samples that are classified as correct. Precision is defined as<br>$$ Precision =\frac{true\ positives}{true\ positives + false\ positives}$$</p><p>Recall measures the percentage of items actually present in the input that were<br>correctly identified by the system. In other words, recall measures the percentage that the system makes correct classfication over total correct samples. Recall is defined as<br>$$Recall =\frac{true\ positives}{true\ positives + false\ negatives}$$</p><p>precision and recall, unlike accuracy, emphasize true positives: finding the things that we are supposed to be looking for.<br>In practice, we generally combine precision and recall into a single metric called<br>F-measure the F-measure that is defined as:<br>$$F_\beta =\frac{(\beta^2 +1)PR}{\beta^2P+R}$$</p><p>The β parameter differentially weights the importance of recall and precision. Values of β &gt; 1 favor recall, while values of β &lt; 1 favor precision. When β = 1, precision and recall are equally balF1<br>anced; this is the most frequently used metric, and is called \(F_{\beta}=1\) or just \(F_1\).F-measure comes from a weighted harmonic mean of precision and recall.</p><p>Harmonic mean is used because it is a conservative metric; the harmonic mean of<br>two values is closer to the minimum of the two values than the arithmetic mean is.<br>Thus it weighs the lower of the two numbers more heavily.</p><p>In <strong>any-of</strong> or <strong>multi-label</strong> classification, each document or item can be assigned more than one label. Solve any-of classification by building separate binary classifiers for each class c. Given a test document or item d, then each classifier makes their decision independently, and we may assign multiple labels to d.</p><p><strong>one-of</strong> or <strong>multinomial</strong> classification, multinomial classification in which the classes are mutually exclusive and each document or item appears in<br>exactly one class. Build a separate binary classifier trained on positive<br>examples from c and negative examples from all other classes. Now given a test<br>document or item d, we run all the classifiers and choose the label from the classifier with the highest score. </p><p>In <strong>macroaveraging</strong>, we compute the performance for each class, and then average over classes. In <strong>microaveraging</strong>, we collect the decisions for all classes into a single contingency table, and compute precision and recall from that table(sum the number of decision like true for all classfiers and divide by total number of decision). A microaverage is dominated by the more frequent class, since the counts are pooled. The macroaverage better reflects the statistics of the smaller classes, and so is more appropriate when performance on all the classes is equally important.</p><p>The only problem with cross-validation is that because all the data is used for<br>testing, we need the whole corpus to be blind; we can’t examine any of the data<br>to suggest possible features and in general see what’s going on. But looking at the<br>corpus is often important for designing the system. For this reason, it is common<br>to create a fixed training set and test set, then do 10-fold cross-validation inside the training set, but compute error rate the normal way in the test set.</p><h5 id="Toy-Model"><a href="#Toy-Model" class="headerlink" title="Toy Model"></a>Toy Model</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> nltk</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">from</span> nltk.corpus <span class="keyword">import</span> stopwords</span><br><span class="line"><span class="keyword">from</span> nltk.tokenize <span class="keyword">import</span> RegexpTokenizer</span><br><span class="line"><span class="keyword">from</span> utils <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> copy</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">processing_raw_text</span><span class="params">(sentence)</span>:</span></span><br><span class="line">    intermediate = sentence.split(<span class="string">'\t'</span>)</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        sen, label = intermediate[<span class="number">0</span>].strip(), intermediate[<span class="number">1</span>]</span><br><span class="line">    <span class="keyword">except</span> IndexError:</span><br><span class="line">        <span class="keyword">return</span> (<span class="keyword">None</span>,<span class="keyword">None</span>)</span><br><span class="line">    <span class="comment"># print("sen", sen)</span></span><br><span class="line">    <span class="comment"># print(label)</span></span><br><span class="line">    <span class="keyword">return</span> sen, label</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">processing_sentence</span><span class="params">(sentence, tokenizer=None, stop_words=True, punctuation=True, stem=False)</span>:</span></span><br><span class="line">    <span class="string">'''Given tokenizer, please deal with punctuation yourself'''</span></span><br><span class="line">    <span class="keyword">if</span> tokenizer <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">        <span class="keyword">if</span> punctuation == <span class="keyword">True</span>:</span><br><span class="line">            tokenizer = RegexpTokenizer(<span class="string">r'\w+'</span>)</span><br><span class="line">            token = tokenizer.tokenize(sentence)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            token = nltk.word_tokenize(sentence)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        token = tokenizer.tokenize(sentence)</span><br><span class="line">    <span class="keyword">if</span> stop_words == <span class="keyword">True</span>:</span><br><span class="line">        sw_l = set(stopwords.words(<span class="string">'english'</span>))</span><br><span class="line">        filtered_token = [w <span class="keyword">for</span> w <span class="keyword">in</span> token <span class="keyword">if</span> <span class="keyword">not</span> w <span class="keyword">in</span> sw_l]</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        filtered_token = token</span><br><span class="line">    <span class="keyword">if</span> stem == <span class="keyword">True</span>:</span><br><span class="line">        porter = nltk.PorterStemmer()</span><br><span class="line">        filtered_token = [porter.stem(t) <span class="keyword">for</span> t <span class="keyword">in</span> filtered_token]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> filtered_token</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">calculate_class_probability</span><span class="params">(label_l)</span>:</span></span><br><span class="line">    label_distinct = set(label_l)</span><br><span class="line">    d = &#123;key: label_l.count(key) <span class="keyword">for</span> key <span class="keyword">in</span> label_distinct&#125;</span><br><span class="line">    d = &#123;key: d[key] / float(sum(d.values())) <span class="keyword">for</span> key <span class="keyword">in</span> label_distinct&#125;</span><br><span class="line">    <span class="keyword">return</span> d</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(test_example, class_p, word_p)</span>:</span></span><br><span class="line">    <span class="string">'''predict'''</span></span><br><span class="line">    predict_l = []</span><br><span class="line">    label_distinct = set(label_l)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(test_example)):</span><br><span class="line">        p_example = &#123;key: class_p[key] <span class="keyword">for</span> key <span class="keyword">in</span> class_p.keys()&#125;</span><br><span class="line">        <span class="keyword">for</span> w <span class="keyword">in</span> test_example[i]:</span><br><span class="line">            <span class="keyword">for</span> lab <span class="keyword">in</span> label_distinct:</span><br><span class="line">                <span class="keyword">try</span>:</span><br><span class="line">                    p_example[lab] += np.log(word_p[lab][w])</span><br><span class="line">                <span class="keyword">except</span> KeyError:</span><br><span class="line">                    p_example[lab] += np.log(word_p[lab][<span class="string">'unknown'</span>])</span><br><span class="line">                    <span class="comment"># p_example[lab] = float("inf")</span></span><br><span class="line">        predict_l.append(max(p_example, key=p_example.get))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> predict_l</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">process_dic_unknown</span><span class="params">(dic, percent=<span class="number">20</span>)</span>:</span>  <span class="comment">#The lowest 20 percent words are regarded as unknown words.</span></span><br><span class="line">    v_l = list(dic.values())</span><br><span class="line">    v_l.sort()</span><br><span class="line">    i = int(len(v_l)*percent/<span class="number">100</span>)</span><br><span class="line">    unknown_count = <span class="number">0</span></span><br><span class="line">    d = copy.deepcopy(dic)</span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> dic.keys():</span><br><span class="line">        <span class="keyword">if</span> dic[k] &lt;= v_l[i]:</span><br><span class="line">            unknown_count += dic[k]</span><br><span class="line">            <span class="keyword">del</span> d[k]</span><br><span class="line">    d[<span class="string">'unknown'</span>] = unknown_count</span><br><span class="line">    <span class="keyword">return</span> d</span><br><span class="line"></span><br><span class="line">    <span class="comment"># return d</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">add_k_smoothing</span><span class="params">(dic, k=<span class="number">1</span>)</span>:</span></span><br><span class="line">    d = dict(map(<span class="keyword">lambda</span> i: (i[<span class="number">0</span>],(i[<span class="number">1</span>]+k)/float(len(dic.keys())*k+sum(dic.values())) ) ,dic.items()))</span><br><span class="line">    <span class="comment"># print(d)</span></span><br><span class="line">    <span class="keyword">return</span> d</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_labeled_vocab</span><span class="params">(example_l, label_l, dic, sort=True,</span></span></span><br><span class="line"><span class="function"><span class="params">                        smooth=False, deal_with_unknown = True)</span>:</span></span><br><span class="line">    label_distinct = set(label_l)</span><br><span class="line">    label_index = &#123;key: [<span class="number">-1</span>] <span class="keyword">for</span> key <span class="keyword">in</span> label_distinct&#125;</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(label_l)):</span><br><span class="line">        label_index[label_l[i]].append(i)</span><br><span class="line">    label_index = &#123;k: v[<span class="number">1</span>:] <span class="keyword">for</span> k, v <span class="keyword">in</span> label_index.items()&#125;</span><br><span class="line">    dic = copy.deepcopy(dic)</span><br><span class="line">    <span class="keyword">if</span> deal_with_unknown == <span class="keyword">True</span>:</span><br><span class="line">        dic = copy.deepcopy(process_dic_unknown(dic))</span><br><span class="line"></span><br><span class="line">    d_labeled = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> lab <span class="keyword">in</span> label_distinct:</span><br><span class="line">        d = dic.fromkeys(dic.keys(), <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> ind <span class="keyword">in</span> label_index[lab]:</span><br><span class="line">            <span class="keyword">for</span> w <span class="keyword">in</span> example_l[ind]:</span><br><span class="line">                <span class="keyword">if</span> w <span class="keyword">in</span> d.keys():</span><br><span class="line">                    d[w] += <span class="number">1</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    d[w] = <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> sort==<span class="keyword">True</span>:</span><br><span class="line">            d_sorted = &#123;&#125;                   <span class="comment"># sort the key</span></span><br><span class="line">            <span class="keyword">for</span> key <span class="keyword">in</span> sorted(d.keys()):</span><br><span class="line">                d_sorted[key] = d[key]</span><br><span class="line">            d_labeled[lab] = d_sorted</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            d_labeled[lab] = d</span><br><span class="line">    <span class="keyword">if</span> isinstance(smooth,int):</span><br><span class="line">        d_labeled = dict(map(<span class="keyword">lambda</span> i: (i[<span class="number">0</span>], add_k_smoothing(i[<span class="number">1</span>], smooth)),d_labeled.items()))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> d_labeled</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">calculate_conditional_probability</span><span class="params">(dic)</span>:</span></span><br><span class="line">    <span class="string">'''calculate p(w|c)'''</span></span><br><span class="line">    label_distinct = dic.keys()</span><br><span class="line">    p_dic = &#123;key: &#123;k: dic[key][k] / float(sum(dic[key].values())) <span class="keyword">for</span> k <span class="keyword">in</span> dic[key].keys()&#125;</span><br><span class="line">             <span class="keyword">for</span> key <span class="keyword">in</span> label_distinct&#125;</span><br><span class="line">    <span class="keyword">return</span> p_dic</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read_data</span><span class="params">(file_l)</span>:</span></span><br><span class="line">    sen_l = []</span><br><span class="line">    label_l = []</span><br><span class="line">    <span class="keyword">for</span> file <span class="keyword">in</span> file_l:</span><br><span class="line">        <span class="comment"># print(file)</span></span><br><span class="line">        <span class="keyword">with</span> open(file,<span class="string">'r'</span>) <span class="keyword">as</span> f:</span><br><span class="line">            sen = <span class="number">1</span> <span class="comment">#dummy number</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">while</span> sen != <span class="string">''</span>:</span><br><span class="line">                sen = f.readline().strip()</span><br><span class="line">                <span class="comment"># print(sen)</span></span><br><span class="line">                <span class="comment"># print(sen)</span></span><br><span class="line">                s,lab = processing_raw_text(sen)</span><br><span class="line">                <span class="keyword">if</span> s <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line">                sen_l.append(s)</span><br><span class="line">                label_l.append(lab)</span><br><span class="line">        <span class="comment"># print(l)</span></span><br><span class="line">    <span class="comment"># print(len(sen_l))</span></span><br><span class="line">    <span class="keyword">return</span> sen_l, label_l</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_train_test_set</span><span class="params">(example, label, percent=<span class="number">0.2</span>)</span>:</span> <span class="comment"># % of data as test set</span></span><br><span class="line">    train_example = copy.deepcopy(example)</span><br><span class="line">    train_label = copy.deepcopy(label)</span><br><span class="line">    k = int(percent * len(example))</span><br><span class="line">    <span class="comment"># print(len(example))</span></span><br><span class="line">    index = random.sample(range(len(example)), k)</span><br><span class="line">    test_example, test_label = [], []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> index:</span><br><span class="line">        test_example.append(example[i])</span><br><span class="line">        test_label.append(label[i])</span><br><span class="line">    index.sort(reverse=<span class="keyword">True</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> index:</span><br><span class="line">        train_example.pop(i)</span><br><span class="line">        train_label.pop(i)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> train_example, train_label, test_example, test_label</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    file = <span class="string">'/Users/lmk/Documents/NLP/Datasets/sentiment labelled sentences/imdb_labelled.txt'</span></span><br><span class="line">    file1 = <span class="string">'/Users/lmk/Documents/NLP/Datasets/sentiment labelled sentences/amazon_cells_labelled.txt'</span></span><br><span class="line">    file2 = <span class="string">'/Users/lmk/Documents/NLP/Datasets/sentiment labelled sentences/yelp_labelled.txt'</span></span><br><span class="line">    f_l = [file,file1,file2]</span><br><span class="line"></span><br><span class="line">    sen_l, label_l = read_data(f_l)</span><br><span class="line"></span><br><span class="line">    token_l = [processing_sentence(s) <span class="keyword">for</span> s <span class="keyword">in</span> sen_l]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># filtered_token = list(map(lambda t: [w for w in t if not w in stop_words], token_l))</span></span><br><span class="line">    <span class="comment"># print(token_l)</span></span><br><span class="line"></span><br><span class="line">    <span class="string">'''build training set'''</span></span><br><span class="line">    <span class="comment"># train_example = token_l[:800]</span></span><br><span class="line">    <span class="comment"># train_label = label_l[:800]</span></span><br><span class="line">    <span class="comment"># test_example = token_l[800:]</span></span><br><span class="line">    <span class="comment"># test_label = label_l[800:]</span></span><br><span class="line">    accu_l = []</span><br><span class="line">    num_iterations = <span class="number">15</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(num_iterations):</span><br><span class="line">        train_example, train_label, test_example, test_label = build_train_test_set(token_l, label_l)</span><br><span class="line"></span><br><span class="line">        all_words_dic = build_vocab(train_example)</span><br><span class="line">        <span class="comment"># print(all_words_dic)</span></span><br><span class="line">        <span class="comment"># print(process_dic_unknown(all_words_dic))</span></span><br><span class="line">        label_dic = build_labeled_vocab(train_example, train_label, all_words_dic, smooth=<span class="number">1</span>)</span><br><span class="line">        class_p = calculate_class_probability(train_label)      <span class="comment">#Propability of each class</span></span><br><span class="line">        word_p = calculate_conditional_probability(label_dic)</span><br><span class="line"></span><br><span class="line">        predict_l = predict(test_example, class_p, word_p)</span><br><span class="line">        <span class="comment"># print(predict_l)</span></span><br><span class="line">        <span class="comment"># print(test_label)</span></span><br><span class="line">        accuracy = np.sum(np.array(test_label) == np.array(predict_l))/len(test_label)</span><br><span class="line">        accu_l.append(accuracy)</span><br><span class="line">        <span class="comment"># print(accuracy)</span></span><br><span class="line">    print(<span class="string">"average accuracy: "</span>, sum(accu_l)/num_iterations)</span><br></pre></td></tr></table></figure><p>without smoothing and dealing with unknown word: 0.555</p><p>without smoothing but dealing with unknown word: 0.715</p><p>add-1 smoothing and dealing with unknown word: 0.82</p><p>add-3 smoothing and dealing with unknown word: 0.785</p><p>add-5 smoothing and dealing with unknown word: 0.765</p><p>stem average accuracy:  0.784888888888889</p><p>without stem average accuracy:  0.7562222222222222</p><h2 id="Bayesian-networks"><a href="#Bayesian-networks" class="headerlink" title="Bayesian networks"></a>Bayesian networks</h2><p>Bayesian networks represent the conditional dependence in a compat way. In real life, absolute dependence is not true most time.</p><p>Bayesian networks is a Directed Acyclic Graph(DAG) that model local conditional dependence. It joint probability distribution, which turns conditional probability distribution to joint probability distribution. </p><p>Bayesian networks is assembled by causality although causality is not necessary numerically in bayesian networks. Bayesian networks that reflect causality would be simpler and easier to think about.</p><p>In Bayesian networks, each variable is a node. Edges between nodes are directed, which represent dependence.</p><p>To calculate probability, arrage the netword properly s.t. \(p(x_1,…x_n) = p(x_1)p(x_2|x_1)p(x_3|x_1,x_2)….p(x_n|x_1,x_2….x_{n-1})\). </p><h3 id="Inference"><a href="#Inference" class="headerlink" title="Inference"></a>Inference</h3><h4 id="By-Emuneration"><a href="#By-Emuneration" class="headerlink" title="By Emuneration"></a>By Emuneration</h4><p>Emunerate the variables and their states, ioin the variables to build a huge table. i.e.: N variables each with d states, the table entries would be \(d^N\).</p><h4 id="By-Variable-Elimination"><a href="#By-Variable-Elimination" class="headerlink" title="By Variable Elimination"></a>By Variable Elimination</h4><p>Join the variables and sum out the probability to eliminate the variable immediately. Do it iteratively to avoid building a big table.</p><p>i.e.:  \(p(x_1,…x_n)p(x_1)p(x_2|x_1)p(x_3|x_1,x_2)….p(x_n|x_1,x_2….x_{n-1})\). First join x1 to x2  to get \(p(x_2,x_1)\), and then sum out x1 to get \(p(x_2)\). Do it iteratively to get \(p(x_n)\).</p><p>Finding the optimal ordering is a NP problem.</p><h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p><a href="http://net.pku.edu.cn/~course/cs410/2015/resource/book/2012-book-StatisticalLearning-LH.pdf" target="_blank" rel="noopener">统计学习方法</a></p>]]></content>
      
      
        <tags>
            
            <tag> NLP </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Noisy_Channel</title>
      <link href="/2018/06/27/Noisy-Channel/"/>
      <url>/2018/06/27/Noisy-Channel/</url>
      <content type="html"><![CDATA[<h3 id="Noisy-Channel-Model"><a href="#Noisy-Channel-Model" class="headerlink" title="Noisy Channel Model"></a>Noisy Channel Model</h3><p>The intuition of the noisy channel model is to treat the misspelled word as if a correctly spelled word had been “distorted” by being passed through a noisy communication channel.</p><p>$$\hat{w} = \operatorname{arg\,max}_{w\in C} p(x|w)p(w)$$</p><p>C is the list of candidate words. Above is a kind of Bayesian inference. We see an observation x (a misspelled word) and find the word w that generated this misspelled word. Out of all possible words in the vocabulary V or just a list of candidate word C, we want to find the<br>word w such that P(w|x) is highest.</p><h3 id="Channel-Model-p-x-w"><a href="#Channel-Model-p-x-w" class="headerlink" title="Channel Model p(x|w)"></a>Channel Model p(x|w)</h3><p>It’s expensive to get a perfect channel model. But a pretty reasonable estimate<br>of P(x|w) could be generated just by looking at local context: the identity of the correct letter itself, the<br>misspelling, and the surrounding letters.</p><h3 id="confusion-matrix"><a href="#confusion-matrix" class="headerlink" title="confusion matrix"></a>confusion matrix</h3><p>Contains counts of errors. In general, each entry in a confusion matrix represents the number of times one thing was confused with another. Thus for example a substitution confusion matrix will be a square matrix of size 26×26 (or more generally |A| × |A|,<br>for an alphabet A) that represents the number of times one letter was incorrectly<br>used instead of another.</p><p>del[x, y]: count(xy typed as x)</p><p>ins[x, y]: count(x typed as xy)</p><p>sub[x, y]: count(x typed as y)</p><p>trans[x, y]: count(xy typed as yx)</p><p>Methods to get confusion matrix:</p><p>1, extract them from lists of misspellings</p><p>$$p(x|w) = \frac{ins[x_{i-1},w_i]}{count[w_{i-1}]},\quad \text{if insertion}$$</p><p>$$p(x|w) = \frac{sub[x_{i},w_i]}{count[w_{i}]},\quad \text{if substitution}$$</p><p>The probability of substitution is calculated by:<br>given the correct word w and error word x, the number of times that ith character wi and the ith character xi is substituted divided by total number of ith character wi.<br>wi is the ith character of the correct word w and xi is the ith character of the typo x</p><p>2, <em>EM algorithm</em>.<br>compute the matrices by iteratively using the spelling error correction algorithm itself. The iterative algorithm first initializes the matrices with equal values; thus, any character is equally likely to be deleted, equally likely to be substituted for any other character,<br>etc. Next, the spelling error correction algorithm is run on a set of spelling<br>errors. Given the set of typos paired with their predicted corrections, the confusion<br>matrices can now be recomputed, the spelling algorithm run again, and so on. </p><p>Evaluating spell correction algorithms is generally done by holding out a training,<br>development and test set from lists of errors like those on the Norvig and Mitton<br>sites mentioned above.</p><p><strong>Candidate words</strong>:<br>Utilize the extended minimum edit distance algorithm introduced so that in addition to insertions, deletions, and substitutions, there is transpositions, in which two letters are swapped. All words with edit distance of 1 constitutes the candidate words set.</p><p>For words with specific context, it is important to use larger language models than unigrams such that the pobability p(w) is extended to \(p(w_{i-1})*p(w_i)\) for bigram model to take the context into consideration.</p><h3 id="Real-word-spelling-errors"><a href="#Real-word-spelling-errors" class="headerlink" title="Real-word spelling errors"></a>Real-word spelling errors</h3><p>Noisy channel algorithm could also be applied. The algorithm takes the input sentence \(X = {x_1, x_2,…, x_k<br>,…, x_n}\), generates a large set of candidate correction sentences C(X),<br>then picks the sentence with the highest language model probability.</p><p>To generate candidate set C(X), each word is assigned the probability that would make an error. And score each sentence like the aforementioned way. The difference is that the probability that the word is indeed correct needs to be considered. Given a word w, let’s assume the correct probability is \(\alpha\). And the error probability is \(\frac{1-\alpha}{|C(x)|} \) if \(x \in C(x)\). The others are totally the same as normal noisy channel model for wrong words.</p>]]></content>
      
      
        <tags>
            
            <tag> NLP </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>NLP_Notation</title>
      <link href="/2018/06/26/NLP-Notation/"/>
      <url>/2018/06/26/NLP-Notation/</url>
      <content type="html"><![CDATA[<p><strong>Language models</strong> assign a probability to each sentence</p><p>\( w_1^n\) is a sequence of N words from word 1 to word N.</p><p>A <strong>held-out corpus</strong> is an additional training corpus that we use to set hyperparameters.</p><p><strong>Non-word spelling correction</strong> is the detection and correction of spelling errors that result in non-words (like graffe for giraffe). </p><p><strong>real word spelling correction</strong> is the task of detecting and correcting spelling errors even if they accidentally result in an actual word of English (real-word errors).</p><p><strong>edit probability</strong> The probability of typo like deletion, insertion respectively.</p><p><strong>text categorization</strong>: classifying an entire text by assigning it a text<br>categorization label drawn from some set of labels.</p><p><strong>classification</strong>: take a single observation, extract some useful<br>features, and thereby classify the observation into one of a set of discrete classes.</p><p><strong>Generative classifiers</strong> like naive Bayes build a model of each class. Given an observation, they return the class most likely to have generated the observation. <strong>Discriminative classifiers</strong> like logistic regression instead learn what features from the input are most useful to discriminate between the different possible classes.<br>While discriminative systems are often more accurate and hence more commonly used, generative classifiers still have a role.</p><p><strong>bag-of-words</strong>: an unordered set of words with their position ignored, keeping only their frequency in the document.</p><p><strong>linear classifiers</strong>: use a linear combination of the inputs to make a classification decision —like naive Bayes and also logistic regression.</p><p><strong>period disambiguation</strong>: deciding if a period is the end of a sentence or part<br>of a word</p><p><strong>co-occurrence matrix</strong>: a way of representing how often words co-occur.</p><p><strong>term-document matrix</strong>: each row represents a word in the vocabulary and<br>each column represents a document.</p><p><strong>vector space model</strong>:a document is represented as a count vector(column vector), each entry is the count of a specific word.</p><p><strong>Information retrieval</strong>(IR): is the task of finding the document d from the D<br>documents in some collection that best matches a query q which is also a vector of length |V|.</p><p><strong>term-context matrix</strong>: a  |V| × |V| matrix. Each entry(i,j) represent that the number of times a word i shows in the context word j. The context could be a document or a context window of length |L|.</p><p><strong>WordNet</strong>(Sense-Tagged data):WordNet is a large lexical database of English. Nouns, verbs, adjectives and adverbs are grouped into sets of synonyms , each expressing a distinct concept.</p><p><strong>part-of-speech tags</strong>:</p><ol><li>CC    Coordinating conjunction</li><li>CD    Cardinal number</li><li>DT    Determiner</li><li>EX    Existential there</li><li>FW    Foreign word</li><li>IN    Preposition or subordinating conjunction</li><li>JJ    Adjective</li><li>JJR    Adjective, comparative</li><li>JJS    Adjective, superlative</li><li>LS    List item marker</li><li>MD    Modal</li><li>NN    Noun, singular or mass</li><li>NNS    Noun, plural</li><li>NNP    Proper noun, singular</li><li>NNPS    Proper noun, plural</li><li>PDT    Predeterminer</li><li>POS    Possessive ending</li><li>PRP    Personal pronoun</li><li>PRP$    Possessive pronoun</li><li>RB    Adverb</li><li>RBR    Adverb, comparative</li><li>RBS    Adverb, superlative</li><li>RP    Particle</li><li>SYM    Symbol</li><li>TO    to</li><li>UH    Interjection</li><li>VB    Verb, base form</li><li>VBD    Verb, past tense</li><li>VBG    Verb, gerund or present participle</li><li>VBN    Verb, past participle</li><li>VBP    Verb, non-3rd person singular present</li><li>VBZ    Verb, 3rd person singular present</li><li>WDT    Wh-determiner</li><li>WP    Wh-pronoun</li><li>WP$    Possessive wh-pronoun</li><li>WRB    Wh-adverb</li></ol><p><strong>Lemmatization</strong> is the task of determining that two words have the same root, despite their surface differences. Usually including plural to singular, but the word form such as ing, ed would not change.</p><p>This naive version of morphological analysis is called <strong>stemming</strong>. Stemming usually includes turning a word to its morpheme.</p><p>Two broad classes of morphemes: </p><ul><li>stems: the central morpheme of the word, supplying the main meaning. i.e.: girls, girl and s are the morphemes. The central morpheme is girl.</li><li>affixes: adding “additional”<br>meanings of various kinds. i.e.: homegrown, ‘home’ is added before the grown. unkind: ‘un’ is added before the word kind.</li></ul><p><strong>concept drift</strong> – the gradual change over time of the con- cept underlying a class like US president from Bill Clinton to George W. Bush</p>]]></content>
      
      
        <tags>
            
            <tag> NLP </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Smoothing</title>
      <link href="/2018/06/26/Smoothing/"/>
      <url>/2018/06/26/Smoothing/</url>
      <content type="html"><![CDATA[<h1 id="Smoothing"><a href="#Smoothing" class="headerlink" title="Smoothing:"></a>Smoothing:</h1><p>basically discount the observed words to assign to words with zero count so as to deal with the zero probability words.</p><h3 id="Laplace-Smoothing"><a href="#Laplace-Smoothing" class="headerlink" title="Laplace Smoothing"></a>Laplace Smoothing</h3><p>Also called add-one smoothing.</p><p>the unsmoothed maximum likelihood estimate of the unigram probability of the word wi is its count ci normalized by the total number of word tokens N</p><p>$$ p(w_i)= \frac{c_i}{N} $$</p><p>Laplace smoothing merely adds one to each count. Denominator is also adjusted by adding V(number of observations). If the demoninator is still unchanged, the sum of all probability would exceed 1.</p><p>$$ p_{Laplace}(w_i)= \frac{c_i+1}{N+V} $$</p><p><strong>adjusted count</strong>: describe how a smoothing algorithm affects the numerator</p><p>$$ c_i^* = \frac{c_i+1}{N+V} \times{N} = p_{Laplace}(w_i) \times{N} $$</p><p>the ratio of the discounted counts to the original counts describe a smoothing algorithm in terms of a relative discount dc:</p><p>$$ d_c= \frac{c^*}{c} $$</p><p>Normal bigram probabilities are computed by normalizing each row of counts by the unigram count:</p><p>$$ p(w_n|w_{n-1})= \frac{c(w_{n-1}w_n)}{c(w_{n-1})} $$</p><p>After smoothing:</p><p>$$ p_{Laplace}(w_n|w_{n-1})= \frac{c(w_{n-1}w_n)+1}{c(w_{n-1})+V} $$</p><p>These adjusted counts can be computed by equation below to show the reconstructed counts.</p><p>$$ c^*(w_{n-1}w_n) = \frac{c(w_{n-1}w_n)+1}{c(w_{n-1)}+V} \times{c(w_{n-1})} = p_{Laplace}(w_n|w_{n-1}) \times{c(w_{n-1})} $$</p><h3 id="Add-k-smoothing"><a href="#Add-k-smoothing" class="headerlink" title="Add-k smoothing:"></a>Add-k smoothing:</h3><p>add k rather than one; </p><p>$$ p_{Add-k}^*(w_n|w_{n-1})= \frac{c(w_{n-1}w_n)+k}{c(w_{n-1})+kV} $$</p><p>chosse k by optimizing on a devset.</p><p>Although add-k is useful for some tasks (including text classification), it turns out that it still doesn’t work well for language modeling, generating counts with poor variances and often inappropriate discounts</p><h3 id="Backoff-and-Interpolation"><a href="#Backoff-and-Interpolation" class="headerlink" title="Backoff and Interpolation"></a>Backoff and Interpolation</h3><p><strong>backoff</strong>: If there is zero evidence for a higher-order N-gram, use lower-order N-gram instead. </p><p>i.e.: If we are trying to compute $$ P(w_n|w_{n−2}w_{n−1}) $$ but we have no examples of a particular trigram wn−2wn−1wn, we can instead estimate its probability by using the bigram probability $$ P(w_n|w_{n−1}) $$.</p><p><strong><em>interpolation</em></strong>: we always mix the probability estimates from all the N-gram estimators, weighing and combining the trigram, bigram, and unigram counts.</p><p>In a slightly more sophisticated version of linear interpolation, each λ weight is computed by conditioning on the context. This way, if we have particularly accurate counts for a particular bigram, we assume that the counts of the trigrams based on this bigram will be more trustworthy, so we can make the λs for those trigrams higher and thus give that trigram more weight in the interpolation.</p><p>$$ \hat{p}(w_n|w_{n-2}w_{n-1}) = \lambda_1 (w_{n-2}^{n-1})p(w_n|w_{n-2}w_{n-1}) + \lambda_2 (w_{n-2}^{n-1})p(w_n|w_{n-1}) +\lambda_3 (w_{n-2}^{n-1})p(w_n)  $$ </p><p>simple interpolation:</p><p>$$ \hat{p}(w_n|w_{n-2}w_{n-1}) = \lambda_1 p(w_n|w_{n-2}w_{n-1}) + \lambda_2 p(w_n|w_{n-1}) +\lambda_3 p(w_n) $$ </p><p>In both kinds of interpolation:</p><p>$$ \sum_i \lambda_i = 1 $$</p><p>Both the simple interpolation and conditional interpolation λ are learned from a held-out corpus. choose the λ values that maximize the likelihood of the held-out corpus.There are various ways to find this optimal set of λs. One way is to use the EM algorithm, which is an iterative learning algorithm that converges on locally optimal λs</p><p>In terms of <strong>quality of N-gram model</strong>: quadrigram &gt; trigram &gt; bigram &gt; unigram</p><p>In order for a backoff model to give a correct probability distribution, we have to discount the higher-order N-grams to save some probability mass for the lower order N-grams. In addition to this explicit discount factor, we’ll need a function α to distribute this probability mass to the lower order N-grams.</p><p>This kind of backoff with discounting is also called <strong>Katz backoff</strong>. In Katz backoff we rely on a discounted probability \(P^∗\) if we’ve seen this N-gram before (i.e., if we have non-zero counts). Otherwise, we recursively back off to the Katz probability for the shorter-history (N-1)-gram. The probability for a backoff N-gram PBO is thus computed as follows:</p><p>$$\begin{cases}<br>       P^*(w_n|w_{n-N+1}^{n-1})\quad \text{if}\;C(w_{n-N+1}^{n-1}) &gt; 0 \<br>       \alpha(w_{n-N+1}^{n-1})P_{BO}(w_n|w_{n-N+2}^{n-1})\quad \text{otherwise}<br>    \end{cases} $$</p><p>Katz backoff is often combined with a smoothing method called <strong>Good-Turing</strong>. The combined Good-Turing backoff algorithm involves quite detailed computation<br>for estimating the Good-Turing smoothing and the \(P^*\) and \(\alpha\) values.</p><h3 id="Kneser-Ney-Smoothing"><a href="#Kneser-Ney-Smoothing" class="headerlink" title="Kneser-Ney Smoothing"></a>Kneser-Ney Smoothing</h3><p>Intuition: Discount the probability from N gram model and assign it to phrase so as to take different word combinations into consideration.</p><p>Simple example:<br>Finance in _ is promissing.<br>Here you can just simply fill in a word with high probability like USA, Germany. With Kneser-Ney Smoothing, taking word combinations into consideration, it might fill in world finance centre like London and HongKong because they often appear together.</p><p>Novel continuation means the first time that the word \(w_{i-1}\) preceeds the word \(w_i\).</p><p>The number of times a word w appears as a novel continuation can be expressed as:</p><p>$$P_{continuation}(w_i)\propto \lvert {w_{i-1}:C(w_{i-1}w_i)&gt;0}\rvert$$</p><p>\(w_i\) is the current word. \(w_{i-1}\) is the words occur before the current word(also called preceeding word).</p><p>To turn this count into a probability, we normalize by the total number of bigram word. In summary:</p><p>$$P_{continuation}(w_i)=\frac{\lvert {w_{i-1}:C(w_{i-1}w_i)&gt;0}\rvert}{\lvert{(w_{j-1},w_j):c(w_{j-1}w_j)&gt;0}\rvert}$$</p><p>Or normalized by the number of words preceding all words as follows:</p><p>$$P_{continuation}(w_i)=\frac{\lvert { w_{i-1}:C(w_{i-1}w_i)&gt;0}\rvert}<br>{\sum_{w’<em>i} \lvert {w’</em>{i-1}:C(w’_{i-1}w’_i)&gt;0}\rvert}$$</p><p>The number of words preceeding all words is:<br>given word \({w’}<em>i\),the number of word \(w’</em>{i-1}\) that preceed \({w’}_i\).<br>\({w’}_i\) are all words in the corpus. So The number of words preceeding all words = the total number of bigram word.</p><p>The final equation for <strong>Interpolated Kneser-Ney smoothing</strong> for bigrams is then:</p><p>$$P_{KN}(w_i|w_{i-1})=\frac{max(C(w_{i-1}w_i)-d,0)}{C(w_{i-1})}<br>+\lambda(w_{i-1})P_{continuation}(w_i)$$</p><p>The λ is a normalizing constant that is used to distribute the probability mass that is discounted:</p><p>$$\lambda(w_{i-1})=\frac{d}{C(w_{i-1})}\cdot \lvert {w:C(w_{i-1},w)&gt;0}\rvert$$</p><p>The first term \(\frac{d}{C(w_{i-1})}\) is the normalized discount. The second term \(\lvert {w:C(w_{i-1},w)&gt;0}\rvert\)<br>is the number of word types that can follow \(w_{i−1}\) or, equivalently, the number of word types that we discounted; in other words, the number of times we applied the normalized discount.</p><p>The general recursive formulation is as follows:</p><p>$$P_{KN}(w_i|w_{i-n+1}\cdots w_{i-1})=\frac{max(0,C_{KN}(w_{i-n+1} \cdots w_i) - d)}{C_{KN}(w_{i-n+1}\cdots w_{i-1})}<br>+\lambda(w_{i-n+1}\cdots w_{i-1})\cdot P_{KN}(w_i|w_{i-n+2}\cdots w_{i-1})$$</p><p>$$\lambda(w_{i-n+1}\cdots w_{i-1})=\frac{d}{C_{KN}(w_{i-n+1}\cdots w_{i-1})}\cdot \lvert {w:C_{KN}(w_{i-n+1} \cdots w_{i-1}w)&gt;0}\rvert$$</p><p>where the definition of the count \(c_{KN}\) depends on whether we are counting the highest-order N-gram being interpolated (for example trigram if we are interpolat- ing trigram, bigram, and unigram) or one of the lower-order N-grams (bigram or unigram if we are interpolating trigram, bigram, and unigram):</p><p>$$C_{KN}(\cdot)=\begin{cases}count(\cdot) &amp;,\text{for the highest order}\<br>continuationcount(\cdot) &amp;,\text{for all other lower orders}<br>\end{cases}$$</p><p>The continuation count is the number of unique single word contexts for ·.<br>At the termination of the recursion, unigrams are interpolated with the uniform<br> distribution, where the parameter ε is the empty string:</p><p> $$P_{KN}(w)=\frac{max(c_{KN}(w)-d,0)}{\sum_{w’}c_{KN}(w’)} +\lambda(\epsilon)\frac{1}{V}$$</p><p> If we want to include an unknown word <unk>, it’s just included as a regular vo-<br>cabulary entry with count zero, and hence its probability will be a lambda-weighted<br>uniform distribution \(\frac{\lambda(\epsilon)}{V}\).</unk></p><p>The best-performing version of Kneser-Ney smoothing is called modified Kneser- Ney smoothing. Rather than use a single fixed discount d, modified Kneser-Ney uses three different discounts d1, d2, and \(d3_+\) for N-grams with counts of 1, 2 and three or more, respectively.</p><h3 id="Entropy"><a href="#Entropy" class="headerlink" title="Entropy"></a>Entropy</h3><p><strong>Entropy</strong> is the minimum number of bits(if log base 2 is used) that is needed to encode(represent) information in the optimal coding scheme.</p><p><strong>Entropy rate</strong> the entropy of a sequence divided by the number of words.</p><p>To measure entropy rate of a language, entropy rate of a infinite sequence needs to be calculated.</p><p>$$H(L) = −\lim_{n\to\infty} \frac{1}{n}H(w_1,w_2,…,w_n)<br>= −\lim_{n\to\infty}\sum_{W\in L} p(w_1,…,w_n)\frac{1}{n} \log p(w_1,…,w_n)$$</p><p>The Shannon-McMillan-Breiman theorem states that if the language is rboth stationary and ergodic</p><p>$$H(L) = \lim_{n\to\infty}-\frac{1}{n}\log p(w_1,…,w_n)$$</p><p>The intuition of the Shannon-McMillan-Breiman theorem is that a long-enough sequence of words will contain many other shorter sequences and that each of these shorter sequences will reoccur in the longer sequence according to their probabilities.That is, we can take a single sequence that is long enough instead of summing over all possible sequences. </p><p>A stochastic process is said to be stationary if the probability distribution for words at time t is the same as the probability distribution at time t + 1. Markov models, and hence N-grams, are stationary. Natural language is not stationary, the probability of upcoming words can be dependent on events that were arbitrarily distant and time dependent. Thus, our statistical models only give an approximation to the correct distributions and entropies of natural language.<br>To summarize, by making some incorrect but convenient simplifying assumptions, we can compute the entropy of some stochastic process by taking a very long sample of the output and computing its average log probability.</p><p>The cross-entropy is useful when we don’t know the actual probability distribution p that generated some data. It allows us to use some m, which is a model of p (i.e., an approximation to p) to approximate the real entropy. The<br>cross-entropy of m on p is defined by</p><p>$$H(p,m) = \lim_{n\to\infty}\sum_{W\in L}- p(w_1,…,w_n)\frac{1}{n} \log m(w_1,…,w_n)$$</p><p>That is, we draw sequences according to the probability distribution p, but sum the log of their probabilities according to m.<br>Again, following the Shannon-McMillan-Breiman theorem, for a stationary ergodic process:</p><p>$$H(p,m) = \lim_{n\to\infty}-\frac{1}{n}\log m(w_1,…,w_n)$$</p><p>This means that, as for entropy, we can estimate the cross-entropy of a model m on some distribution p by taking a single sequence that is long enough instead of summing over all possible sequences.<br>What makes the cross-entropy useful is that the cross-entropy H(p,m) is an upper bound on the entropy H(p).<br>For any model m:</p><p>$$H(p) ≤ H(p,m)$$</p><p>This means that we can use some simplified model m to estimate the true entropy of a sequence of symbols drawn according to probability p. The more accurate m is, the closer the cross-entropy H(p,m) will be to the true entropy H(p). Thus, the difference between H(p,m) and H(p) is a measure of how accurate a model is. The lower the cross-entropy, the better is the model(better approximation of the true entropy). The cross-entropy can never be lower than the true entropy, so a model cannot err by underestimating the true entropy.</p><p>Cross-entropy is defined in the limit, as the length of the observed word sequence goes to infinity. A (sufficiently long) sequence of fixed length N is employed to  approximate the cross-entropy of a model M = $ P(w_i|w_{i−N+1}…w_{i−1}) $(N is the N of a N-gram model) on a sequence of words W is</p><p>$$H(W) = -\frac{1}{N}\log p(w_1,…,w_n)$$</p><p>The perplexity of a model P on a sequence of words W is now formally defined as the exp of this cross-entropy:</p><p>$$Perplexity(W) = 2^{H(W)} = P(w_1,…,w_n)^{-\frac{1}<br>{N}}$$</p>]]></content>
      
      
        <tags>
            
            <tag> NLP </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Max_Matching</title>
      <link href="/2018/06/25/Max-Matching/"/>
      <url>/2018/06/25/Max-Matching/</url>
      <content type="html"><![CDATA[<h2 id="Max-Matching-Algorithm"><a href="#Max-Matching-Algorithm" class="headerlink" title="Max Matching Algorithm"></a>Max Matching Algorithm</h2><p>It is a kind of greedy algorithm used to tokenize sentences. It is a baseline of tokenize algorithms.</p><p>It works especially well on Chinese. I think it is because that Chinese words are single word that could not be took apart while English words are sequences of characters.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read_words</span><span class="params">(file)</span>:</span></span><br><span class="line">    <span class="keyword">with</span> open(file) <span class="keyword">as</span> f:</span><br><span class="line">        l = f.readlines()</span><br><span class="line">    <span class="keyword">return</span> l</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">max_matching</span><span class="params">(text, dictionary)</span>:</span></span><br><span class="line">    <span class="comment"># l = []</span></span><br><span class="line">    w = <span class="string">''</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(text),<span class="number">0</span>,<span class="number">-1</span>):</span><br><span class="line">        word = text[:i]</span><br><span class="line">        <span class="keyword">if</span> word <span class="keyword">in</span> dictionary:</span><br><span class="line">            w += word+<span class="string">' '</span></span><br><span class="line"></span><br><span class="line">            w += max_matching(text[i:],dictionary) + <span class="string">' '</span></span><br><span class="line">            <span class="keyword">return</span> w</span><br><span class="line">    <span class="keyword">if</span> len(text) != <span class="number">0</span>:</span><br><span class="line">        w = text[<span class="number">0</span>]+<span class="string">' '</span></span><br><span class="line">        w += max_matching(text[<span class="number">1</span>:],dictionary) + <span class="string">' '</span></span><br><span class="line">        <span class="keyword">return</span> w</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">''</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    file = <span class="string">'/Users/lmk/Documents/NLP/word.csv'</span></span><br><span class="line">    l = read_words(file)</span><br><span class="line">    <span class="comment"># l = read_words(file)</span></span><br><span class="line">    l = list(map(<span class="keyword">lambda</span> i: i[<span class="number">3</span>:<span class="number">-1</span>], l))</span><br><span class="line">    l[<span class="number">0</span>] = l[<span class="number">0</span>][<span class="number">1</span>:]</span><br><span class="line">    dic = l</span><br><span class="line">    <span class="comment"># s = "ilovechina"</span></span><br><span class="line">    s = <span class="string">"is also possible to use a list as a queue, where the first"</span></span><br><span class="line">    sentence = max_matching(s,dic)</span><br><span class="line">    token = sentence.split()</span><br><span class="line">    <span class="comment"># flatten = lambda l: [item for sublist in l for item in sentence]</span></span><br><span class="line">    <span class="comment"># flat_list = [item for sublist in l for item in sublist]</span></span><br><span class="line">    print(sentence)</span><br><span class="line">    print(token)</span><br></pre></td></tr></table></figure>]]></content>
      
      
        <tags>
            
            <tag> NLP </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Minimum_Edit_Distance</title>
      <link href="/2018/06/25/Minimum-Edit-Distance/"/>
      <url>/2018/06/25/Minimum-Edit-Distance/</url>
      <content type="html"><![CDATA[<h2 id="Minimum-Edit-Distance"><a href="#Minimum-Edit-Distance" class="headerlink" title="Minimum Edit Distance"></a>Minimum Edit Distance</h2><p>minimum edit distance between two strings is defined as the minimum number of editing operations (operations like insertion, deletion, substitution) needed to transform one string into another. It’s useful in terms of portential splleing checking and string alignment which is significant in terms of machine translation and speech recognition.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">insertion_cost</span><span class="params">(self,c1)</span>:</span></span><br><span class="line">        <span class="string">'''customize your insertion cost'''</span></span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">deletion_cost</span><span class="params">(self,c1)</span>:</span></span><br><span class="line">        <span class="string">'''customize your deletion cost'''</span></span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">substitution_cost</span><span class="params">(self,c1,c2)</span>:</span></span><br><span class="line">        <span class="string">'''customize your substitution cost'''</span></span><br><span class="line">        <span class="keyword">if</span> c1 == c2:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">minDistance</span><span class="params">(self, word1, word2)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        :type word1: str</span></span><br><span class="line"><span class="string">        :type word2: str</span></span><br><span class="line"><span class="string">        :rtype: int</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        n = len(word1)+<span class="number">1</span>    <span class="comment">#row of matrix</span></span><br><span class="line">        m = len(word2)+<span class="number">1</span>    <span class="comment">#column of matrix</span></span><br><span class="line">        l = np.zeros((m,n))</span><br><span class="line">        <span class="comment"># l = [n*[0] for i in range(m)]</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(m):</span><br><span class="line">            l[i,<span class="number">0</span>] = i</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(n):</span><br><span class="line">            l[<span class="number">0</span>,i] = i</span><br><span class="line">        <span class="comment"># print(l)</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,m):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">1</span>,n):</span><br><span class="line">                <span class="comment"># print(i,j)</span></span><br><span class="line">                l[i][j] = min(l[i<span class="number">-1</span>][j]+self.insertion_cost(word2[i<span class="number">-1</span>]), l[i][j<span class="number">-1</span>]+self.deletion_cost(word1[j<span class="number">-1</span>]), l[i<span class="number">-1</span>][j<span class="number">-1</span>]+self.substitution_cost(word1[j<span class="number">-1</span>],word2[i<span class="number">-1</span>]))</span><br><span class="line">        <span class="comment"># l = [list(range(n)) for i in range(m)]</span></span><br><span class="line">        <span class="comment"># print(l)</span></span><br><span class="line">        <span class="keyword">return</span> l[<span class="number">-1</span>][<span class="number">-1</span>]</span><br></pre></td></tr></table></figure><h4 id="minimum-edit-distance-with-backtrace"><a href="#minimum-edit-distance-with-backtrace" class="headerlink" title="minimum edit distance with backtrace"></a>minimum edit distance with backtrace</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Edit_Distance</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.back_trace = <span class="keyword">None</span></span><br><span class="line">        self.n = <span class="number">0</span></span><br><span class="line">        self.m = <span class="number">0</span></span><br><span class="line">        self.l = <span class="keyword">None</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">insertion_cost</span><span class="params">(self,c1)</span>:</span></span><br><span class="line">        <span class="string">'''customize your insertion cost'''</span></span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">deletion_cost</span><span class="params">(self,c1)</span>:</span></span><br><span class="line">        <span class="string">'''customize your deletion cost'''</span></span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">substitution_cost</span><span class="params">(self,c1,c2)</span>:</span></span><br><span class="line">        <span class="string">'''customize your substitution cost'''</span></span><br><span class="line">        <span class="keyword">if</span> c1 == c2:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        <span class="keyword">return</span> <span class="number">2</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">minDistance</span><span class="params">(self, word1, word2)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        :type word1: str</span></span><br><span class="line"><span class="string">        :type word2: str</span></span><br><span class="line"><span class="string">        :rtype: int</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        n = len(word1)+<span class="number">1</span>    <span class="comment">#row of matrix</span></span><br><span class="line">        m = len(word2)+<span class="number">1</span>    <span class="comment">#column of matrix</span></span><br><span class="line">        self.n = n</span><br><span class="line">        self.m = m</span><br><span class="line">        l = np.zeros((m,n))</span><br><span class="line">        <span class="comment"># back_trace = np.zeros((m,n))</span></span><br><span class="line">        back_trace = [n*[<span class="number">0</span>] <span class="keyword">for</span> i <span class="keyword">in</span> range(m)]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(m):</span><br><span class="line">            l[i,<span class="number">0</span>] = i</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(n):</span><br><span class="line">            l[<span class="number">0</span>,i] = i</span><br><span class="line">        <span class="comment"># print(l)</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,m):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">1</span>,n):</span><br><span class="line">                <span class="comment"># print(i,j)</span></span><br><span class="line">                cost = [l[i<span class="number">-1</span>][j]+self.insertion_cost(word2[i<span class="number">-1</span>]), l[i][j<span class="number">-1</span>]+self.deletion_cost(word1[j<span class="number">-1</span>]), l[i<span class="number">-1</span>][j<span class="number">-1</span>]+self.substitution_cost(word1[j<span class="number">-1</span>],word2[i<span class="number">-1</span>])]</span><br><span class="line">                min_cost = min(cost)</span><br><span class="line">                print((i,j),min_cost)</span><br><span class="line">                back_trace[i][j] = [i <span class="keyword">for</span> i,j <span class="keyword">in</span> enumerate(cost) <span class="keyword">if</span> j == min_cost]</span><br><span class="line">                l[i][j] = min_cost</span><br><span class="line">        <span class="comment"># l = [list(range(n)) for i in range(m)]</span></span><br><span class="line">        <span class="comment"># print(l)</span></span><br><span class="line">        <span class="comment"># print(back_trace)</span></span><br><span class="line">        self.l = l</span><br><span class="line">        self.back_trace = back_trace</span><br><span class="line">        <span class="keyword">return</span> l[<span class="number">-1</span>][<span class="number">-1</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># def print_direction(self,l):</span></span><br><span class="line">    <span class="comment">#     if</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">output_back_trace</span><span class="params">(self)</span>:</span></span><br><span class="line">        i = self.n<span class="number">-1</span></span><br><span class="line">        j = self.m<span class="number">-1</span></span><br><span class="line">        <span class="keyword">while</span> i &gt;= <span class="number">0</span> <span class="keyword">and</span> j &gt;= <span class="number">0</span>:</span><br><span class="line"></span><br><span class="line">            <span class="comment"># print((i,j))</span></span><br><span class="line">            direction_list = self.back_trace[i][j]   <span class="comment">#choose the last direction, here every direction has the same cost</span></span><br><span class="line">            print(direction_list)</span><br><span class="line">            <span class="keyword">if</span> isinstance(direction_list,list):</span><br><span class="line">                direction = direction_list[<span class="number">0</span>]</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                direction = direction_list</span><br><span class="line">            <span class="keyword">if</span> direction == <span class="number">2</span>:</span><br><span class="line">                i -= <span class="number">1</span></span><br><span class="line">                j -= <span class="number">1</span></span><br><span class="line">            <span class="keyword">elif</span> direction == <span class="number">1</span>:</span><br><span class="line">                j -= <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                i -= <span class="number">1</span></span><br><span class="line">            <span class="comment"># print(self.l[i][j])</span></span><br><span class="line"></span><br><span class="line">s = Edit_Distance()</span><br><span class="line"><span class="comment"># word1 = "intention"</span></span><br><span class="line"><span class="comment"># word2 = "execution"</span></span><br><span class="line">word1 = <span class="string">"execution"</span></span><br><span class="line">word2 = <span class="string">"intention"</span></span><br><span class="line">leg = s.minDistance(word1,word2)</span><br><span class="line">print(leg)</span><br><span class="line">s.output_back_trace()</span><br><span class="line">print(s.l)</span><br></pre></td></tr></table></figure>]]></content>
      
      
        <tags>
            
            <tag> NLP </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Port_Stemmer</title>
      <link href="/2018/06/25/Port-Stemmer/"/>
      <url>/2018/06/25/Port-Stemmer/</url>
      <content type="html"><![CDATA[<h2 id="Lemmatization"><a href="#Lemmatization" class="headerlink" title="Lemmatization"></a>Lemmatization</h2><p>Lemmatization is the task to determine whether two words have the same root. If proper lemmatization has been applied, number of tokens could be reduced significantly and understanding of the text could also be facilitated.</p><h4 id="Problem-of-suffix-stripping"><a href="#Problem-of-suffix-stripping" class="headerlink" title="Problem of suffix stripping"></a>Problem of suffix stripping</h4><p><em>probe</em> and <em>probate</em><br><em>wand</em> and <em>wander</em><br>Sometimes removal of suffix could affect the original meaning and degrade the performance.</p>]]></content>
      
      
        <tags>
            
            <tag> NLP </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Sort</title>
      <link href="/2018/06/07/Sort/"/>
      <url>/2018/06/07/Sort/</url>
      <content type="html"><![CDATA[<h2 id="Quick-Sort"><a href="#Quick-Sort" class="headerlink" title="Quick Sort"></a>Quick Sort</h2><p>Partition the array into two parts such that elements in part a &lt; that of part b. Recursively invoke quick sort to do in-place sorting. Average performance is the best in practice. O(nlogn). The worst case happens when the array is inversely sorted, which leads the subarray after partition is extremely imbalanced. Time complexity is O(n^2).</p><h2 id="Merge-Sort"><a href="#Merge-Sort" class="headerlink" title="Merge Sort"></a>Merge Sort</h2><p>Divide and conquer. Divide the array into two parts and then merge recursively. The process of sorting is just like building a binary tree in a top-down manner and then merge the array bottom-up.</p><h2 id="Heap-Sort"><a href="#Heap-Sort" class="headerlink" title="Heap Sort"></a>Heap Sort</h2><p>build a max heap so that the first element in the heap is always the largest. Sorting is just switching the largest value with the last element in the array and maintain a heap. after poping the element, reduce the heap size by one.</p><p>##Performance<br>Qucik sort is the fastest. After it is merge sort. And then heap sort. build a heap takes considerable time. Buble sort and insertion sort are far slower.<br>Random an array of length 1000000, quick sort took 5.30535101890564 seconds and merge sort took 5.918827056884766 seconds. Their perfomance are quite good and close to each other. Heap sort took 13.471954822540283 seconds.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Sort</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, l = None)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> l <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">            <span class="keyword">assert</span> type(l) == list,(<span class="string">"please input a list"</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            l = self._generate()</span><br><span class="line">        self.l = l</span><br><span class="line">        self.result = <span class="keyword">None</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">insert_sort</span><span class="params">(self)</span>:</span></span><br><span class="line">        l = self.l      <span class="comment">#add new reference to self.l, change l would change self.l</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,len(l)):   <span class="comment">#use built-in methods to insert</span></span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> range(i<span class="number">-1</span>,<span class="number">-1</span>,<span class="number">-1</span>):</span><br><span class="line">                <span class="keyword">if</span> l[i] &lt; l[j]:</span><br><span class="line">                    <span class="keyword">if</span> j == <span class="number">0</span>:</span><br><span class="line">                        l.insert(j,l[i])</span><br><span class="line">                        <span class="keyword">del</span>(l[i+<span class="number">1</span>])</span><br><span class="line">                    <span class="keyword">elif</span> l[i] &gt;= l[j<span class="number">-1</span>]:</span><br><span class="line">                        l.insert(j, l[i])</span><br><span class="line">                        <span class="keyword">del</span> (l[i + <span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">insert_sort_v1</span><span class="params">(self)</span>:</span>   <span class="comment">#much slower than using built-in method</span></span><br><span class="line">        l = self.l      <span class="comment">#add new reference to self.l, change l would change self.l</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,len(l)):   <span class="comment">#switch position</span></span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> range(i<span class="number">-1</span>,<span class="number">-1</span>,<span class="number">-1</span>):</span><br><span class="line">                <span class="keyword">if</span> l[j+<span class="number">1</span>] &lt; l[j]:</span><br><span class="line">                    l[j], l[j+<span class="number">1</span>] = l[j+<span class="number">1</span>], l[j]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">bubble_sort</span><span class="params">(self)</span>:</span></span><br><span class="line">        l = self.l</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,len(l)<span class="number">-1</span>):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">0</span>,len(l)-i<span class="number">-1</span>):</span><br><span class="line">                <span class="keyword">if</span> l[j] &gt; l[j+<span class="number">1</span>]:</span><br><span class="line">                    l[j], l[j+<span class="number">1</span>] = l[j+<span class="number">1</span>], l[j]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">quick_sort</span><span class="params">(self, p=None, r=None)</span>:</span></span><br><span class="line">        <span class="string">'''extra space usage'''</span></span><br><span class="line">        <span class="string">'''divide the original into two parts such that elements in part a &lt; that of part b'''</span></span><br><span class="line">        <span class="keyword">if</span> p <span class="keyword">is</span> <span class="keyword">None</span> <span class="keyword">or</span> r <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">            p = <span class="number">0</span></span><br><span class="line">            r = len(self.l)</span><br><span class="line">        <span class="comment"># print("p ",p)</span></span><br><span class="line">        <span class="comment"># print("r ", r)</span></span><br><span class="line">        <span class="keyword">if</span> p&lt;r<span class="number">-1</span>:</span><br><span class="line">            q = self._quick_sort_partition(p, r)</span><br><span class="line">            <span class="comment"># print("q ", q)</span></span><br><span class="line">            self.quick_sort(p,q)</span><br><span class="line">            self.quick_sort(q,r)</span><br><span class="line">            <span class="comment"># self._quick_sort_partition(p, q)</span></span><br><span class="line">            <span class="comment"># self._quick_sort_partition(q, r)</span></span><br><span class="line">        <span class="comment"># q = self._quick_sort_partition(p, r)</span></span><br><span class="line">        <span class="comment"># print(q)</span></span><br><span class="line">        <span class="comment"># while True:</span></span><br><span class="line">        <span class="comment">#     if self._quick_sort_partition(p, q) == 0:</span></span><br><span class="line">        <span class="comment">#         break</span></span><br><span class="line">        <span class="comment"># while True:</span></span><br><span class="line">        <span class="comment">#     if self._quick_sort_partition(q, r) == r-1:</span></span><br><span class="line">        <span class="comment">#         break</span></span><br><span class="line">            <span class="comment"># q = self._quick_sort_partition(0,len(self.l))</span></span><br><span class="line">        <span class="comment"># self.quick_sort(p,q)</span></span><br><span class="line">        <span class="comment"># self.quick_sort(q,r)</span></span><br><span class="line">        <span class="comment"># else:</span></span><br><span class="line">        <span class="comment">#     q = self._quick_sort_partition(p, r)</span></span><br><span class="line">        <span class="comment">#     self.quick_sort(p, q - 1)</span></span><br><span class="line">        <span class="comment">#     self.quick_sort(q, r)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_quick_sort_partition</span><span class="params">(self, p, r)</span>:</span></span><br><span class="line">        <span class="comment"># l = list(self.l)</span></span><br><span class="line">        l = self.l</span><br><span class="line">        i = p<span class="number">-1</span></span><br><span class="line">        pivot = l[r<span class="number">-1</span>]</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(p,r<span class="number">-1</span>):      <span class="comment">#in-place exchange without memory overhead</span></span><br><span class="line">            <span class="keyword">if</span> l[j] &lt;= pivot:</span><br><span class="line">                i += <span class="number">1</span></span><br><span class="line">                l[i], l[j] = l[j], l[i]</span><br><span class="line">        <span class="comment"># print(i)</span></span><br><span class="line">        <span class="comment"># print(l)</span></span><br><span class="line">        l[i+<span class="number">1</span>], l[r<span class="number">-1</span>] = l[r<span class="number">-1</span>], l[i+<span class="number">1</span>]</span><br><span class="line">        <span class="comment"># print(l)</span></span><br><span class="line">        <span class="comment"># print(self.l)</span></span><br><span class="line">        <span class="comment"># print("i ",i)</span></span><br><span class="line">        <span class="keyword">return</span> i+<span class="number">1</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">merge_sort</span><span class="params">(self, p=None, r=None)</span>:</span></span><br><span class="line">        l = self.l</span><br><span class="line">        <span class="keyword">if</span> p <span class="keyword">is</span> <span class="keyword">None</span> <span class="keyword">or</span> r <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">            p = <span class="number">0</span></span><br><span class="line">            r = len(l)      <span class="comment">#not include r</span></span><br><span class="line">        <span class="keyword">if</span> p &lt; r<span class="number">-1</span>:</span><br><span class="line">            q = int((p+r)/<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">            self.merge_sort(p,q)</span><br><span class="line">            self.merge_sort(q, r)</span><br><span class="line">            self.merge(p,q,r)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">merge</span><span class="params">(self, p,q,r)</span>:</span></span><br><span class="line">        l = self.l</span><br><span class="line">        L = l[p:q]</span><br><span class="line">        R = l[q:r]</span><br><span class="line">        L.append(float(<span class="string">'inf'</span>))</span><br><span class="line">        R.append(float(<span class="string">'inf'</span>))</span><br><span class="line">        i,j = <span class="number">0</span>,<span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> range(p,r):    <span class="comment">#r = len(list), not include r</span></span><br><span class="line">            <span class="keyword">if</span> L[i] &lt; R[j]:</span><br><span class="line">                l[k] = L[i]</span><br><span class="line">                i+=<span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                l[k] = R[j]</span><br><span class="line">                j += <span class="number">1</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">merge_two_lists</span><span class="params">(self,l1,l2)</span>:</span></span><br><span class="line">        <span class="keyword">assert</span> l1 <span class="keyword">is</span> <span class="keyword">None</span> <span class="keyword">or</span> l2 <span class="keyword">is</span> <span class="keyword">None</span>,(<span class="string">"empty list"</span>)</span><br><span class="line">        l = []</span><br><span class="line">        i = <span class="number">0</span></span><br><span class="line">        j = <span class="number">0</span></span><br><span class="line">        <span class="keyword">while</span> i&lt;len(l1) <span class="keyword">and</span> j&lt;len(l2):</span><br><span class="line">            <span class="keyword">if</span> l1[i] &lt; l2[j]:</span><br><span class="line">                l.append(l1[i])</span><br><span class="line">                i+=<span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                l.append(l2[j])</span><br><span class="line">                j += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> i == len(l1):</span><br><span class="line">            l.extend(l2[j:])</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            l.extend(l1[i:])</span><br><span class="line">        <span class="keyword">return</span> l</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">heap_sort</span><span class="params">(self)</span>:</span></span><br><span class="line">        l = self.l</span><br><span class="line">        self.heap_size = len(l)</span><br><span class="line">        self.build_heap()</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(l)<span class="number">-1</span>,<span class="number">0</span>,<span class="number">-1</span>):  <span class="comment">#no need to include 0. change with itself is meaningless</span></span><br><span class="line">            l[i], l[<span class="number">0</span>] = l[<span class="number">0</span>], l[i]</span><br><span class="line">            self.heap_size -= <span class="number">1</span></span><br><span class="line">            self.max_heaplify(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">build_heap</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="comment">#bottom up. the first level of the tree has no child, no need to maintain</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(int(self.heap_size/<span class="number">2</span>),<span class="number">-1</span>,<span class="number">-1</span>):</span><br><span class="line">            self.max_heaplify(i)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">max_heaplify</span><span class="params">(self,i)</span>:</span></span><br><span class="line">        l = self.l</span><br><span class="line">        left = <span class="number">2</span>*i +<span class="number">1</span></span><br><span class="line">        right = <span class="number">2</span>*i +<span class="number">2</span></span><br><span class="line">        largest = i</span><br><span class="line">        <span class="keyword">if</span> left &lt; self.heap_size <span class="keyword">and</span> l[left] &gt; l[i]:</span><br><span class="line">            largest = left</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> right &lt; self.heap_size <span class="keyword">and</span> l[right] &gt; l[largest]:</span><br><span class="line">            largest = right</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> largest != i:</span><br><span class="line">            <span class="string">'''if position changes, need to recursively run max_heaplify to guarantee</span></span><br><span class="line"><span class="string">            the descendant are also max heap'''</span></span><br><span class="line">            l[i], l[largest] = l[largest], l[i]</span><br><span class="line">            self.max_heaplify(largest)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_evaluate</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> self.result <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">            self.result = self.l</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,len(self.result)):</span><br><span class="line">            <span class="keyword">if</span> self.result[i] &lt; self.result[i<span class="number">-1</span>]:</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">False</span></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">True</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_generate</span><span class="params">(self,length = None)</span>:</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            <span class="keyword">import</span> random</span><br><span class="line">            <span class="keyword">if</span> length <span class="keyword">is</span> <span class="keyword">None</span>:</span><br><span class="line">                length = random.randint(<span class="number">0</span>, <span class="number">1000</span>)</span><br><span class="line">                <span class="comment"># length = random.randint(0,100000)</span></span><br><span class="line">            l = []</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(length):</span><br><span class="line">                l.append(random.randint(-length,length))</span><br><span class="line">            <span class="keyword">return</span> l</span><br><span class="line">        <span class="keyword">except</span> ImportError:</span><br><span class="line">            print(<span class="string">"no random module, please input a sequence"</span>)</span><br><span class="line"></span><br><span class="line">l = [<span class="number">4</span>,<span class="number">6</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">5</span>,<span class="number">-9</span>,<span class="number">0</span>,<span class="number">5</span>,]</span><br><span class="line"><span class="comment"># l = [4,6,10,23,-1,-6]</span></span><br><span class="line"><span class="comment"># s = Sort(l)</span></span><br><span class="line"><span class="comment"># print(s._quick_sort_partition(0,len(l)))</span></span><br><span class="line"><span class="comment"># print(s.l)</span></span><br><span class="line">s = Sort()</span><br><span class="line"><span class="comment"># s.quick_sort()</span></span><br><span class="line">print(<span class="string">"length "</span>,len(s.l))</span><br><span class="line">s.heap_sort()</span><br><span class="line"><span class="comment"># s.build_heap()</span></span><br><span class="line"><span class="comment"># s.merge_sort()</span></span><br><span class="line"><span class="comment"># s.insert_sort_v1()</span></span><br><span class="line"><span class="comment"># s.insert_sort()</span></span><br><span class="line">print(s._evaluate())</span><br><span class="line"><span class="comment"># s._quick_sort_partition(0,len(l))</span></span><br><span class="line">print(s.l)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compare_time</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">import</span> time</span><br><span class="line">    print(<span class="string">"**************compare time**************"</span>)</span><br><span class="line">    s = Sort()</span><br><span class="line">    l = s._generate(<span class="number">1000000</span>)</span><br><span class="line">    start_time = time.time()</span><br><span class="line">    Sort(l).quick_sort()</span><br><span class="line">    print(<span class="string">"--- %s seconds ---"</span> % (time.time() - start_time))</span><br><span class="line">    start_time = time.time()</span><br><span class="line">    Sort(l).merge_sort()</span><br><span class="line">    print(<span class="string">'--- &#123;&#125; seconds ---'</span>.format(time.time() - start_time))</span><br><span class="line">    start_time = time.time()</span><br><span class="line">    Sort(l).heap_sort()</span><br><span class="line">    print(<span class="string">'--- &#123;&#125; seconds ---'</span>.format(time.time() - start_time))</span><br><span class="line"></span><br><span class="line">compare_time()</span><br></pre></td></tr></table></figure><p>###Reference: Introduction to Algorithms</p>]]></content>
      
      
    </entry>
    
    <entry>
      <title>Remove_Duplicates_from_Sorted_List_II</title>
      <link href="/2018/06/05/Remove-Duplicates-from-Sorted-List-II/"/>
      <url>/2018/06/05/Remove-Duplicates-from-Sorted-List-II/</url>
      <content type="html"><![CDATA[<p>##Remove Duplicates from Sorted List II:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Definition for singly-linked list.</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ListNode</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        self.val = x</span><br><span class="line">        self.next = <span class="keyword">None</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">deleteDuplicates</span><span class="params">(self, head)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        :type head: ListNode</span></span><br><span class="line"><span class="string">        :rtype: ListNode</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        node = head</span><br><span class="line">        <span class="keyword">if</span> head == <span class="keyword">None</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">None</span></span><br><span class="line">        <span class="keyword">if</span> head.next == <span class="keyword">None</span>:</span><br><span class="line">            <span class="keyword">return</span> head</span><br><span class="line">        <span class="keyword">if</span> head.next.val != head.val:   <span class="comment">#the first two elements are not the same</span></span><br><span class="line">            current_node = node</span><br><span class="line">            node = node.next</span><br><span class="line">            <span class="keyword">while</span> node != <span class="keyword">None</span>:</span><br><span class="line">                <span class="keyword">if</span> node.next == <span class="keyword">None</span>:</span><br><span class="line">                    current_node.next = node</span><br><span class="line">                    <span class="keyword">return</span> head</span><br><span class="line">                <span class="keyword">if</span> node.next.val != node.val:</span><br><span class="line">                    current_node.next = node</span><br><span class="line">                    current_node = node</span><br><span class="line">                <span class="keyword">else</span>:   <span class="comment"># when next node is the same as the current node</span></span><br><span class="line">                    <span class="keyword">while</span> node != <span class="keyword">None</span>:</span><br><span class="line">                        <span class="keyword">if</span> node.next == <span class="keyword">None</span>:</span><br><span class="line">                            current_node.next = <span class="keyword">None</span></span><br><span class="line">                            <span class="keyword">return</span> head</span><br><span class="line">                        <span class="keyword">else</span>:</span><br><span class="line">                            node = node.next</span><br><span class="line">                        <span class="keyword">if</span> node.next == <span class="keyword">None</span>:</span><br><span class="line">                            current_node.next = <span class="keyword">None</span></span><br><span class="line">                            <span class="keyword">return</span> head</span><br><span class="line">                        <span class="keyword">if</span> node.val != node.next.val:</span><br><span class="line">                            <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">                node = node.next</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            current_node = <span class="keyword">None</span>     <span class="comment">#the first two elements are same, pointers point to None</span></span><br><span class="line">            <span class="keyword">while</span> node != <span class="keyword">None</span>:</span><br><span class="line">                <span class="keyword">if</span> node.next == <span class="keyword">None</span>:</span><br><span class="line">                    <span class="keyword">if</span> current_node == <span class="keyword">None</span>:    <span class="comment"># all elements includes the first few elements are same</span></span><br><span class="line">                        <span class="keyword">return</span> node             <span class="comment">#return None</span></span><br><span class="line">                    current_node.next = node    <span class="comment">#add the last node to the linked list</span></span><br><span class="line">                    <span class="keyword">return</span> head</span><br><span class="line">                <span class="keyword">if</span> node.next.val != node.val:   <span class="comment">#current node is to record the last node in the linked list</span></span><br><span class="line">                    <span class="keyword">if</span> current_node == <span class="keyword">None</span>:    <span class="comment">#which is identical in the list</span></span><br><span class="line">                        current_node = node</span><br><span class="line">                        head = current_node</span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        current_node.next = node</span><br><span class="line">                        current_node = node</span><br><span class="line">                <span class="keyword">else</span>:   <span class="comment"># when next node is the same as the current node</span></span><br><span class="line">                    <span class="keyword">while</span> node != <span class="keyword">None</span>:         <span class="comment"># if the node is the same with next node</span></span><br><span class="line">                        <span class="keyword">if</span> node.next == <span class="keyword">None</span>:   <span class="comment"># this loop is to skip the node</span></span><br><span class="line">                            current_node.next = <span class="keyword">None</span></span><br><span class="line">                            <span class="keyword">return</span> head</span><br><span class="line">                        <span class="keyword">else</span>:</span><br><span class="line">                            node = node.next</span><br><span class="line">                        <span class="keyword">if</span> node.next == <span class="keyword">None</span>:</span><br><span class="line">                            <span class="keyword">if</span> current_node == <span class="keyword">None</span>:</span><br><span class="line">                                <span class="keyword">return</span> <span class="keyword">None</span></span><br><span class="line">                            current_node.next = <span class="keyword">None</span></span><br><span class="line">                            <span class="keyword">return</span> head</span><br><span class="line">                        <span class="keyword">if</span> node.val != node.next.val:</span><br><span class="line">                            <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">                node = node.next</span><br><span class="line"></span><br><span class="line">s = Solution()</span><br><span class="line">l = [<span class="number">1</span>,<span class="number">1</span>,<span class="number">2</span>]</span><br><span class="line"><span class="comment"># l = [1,2,3,3,4,4,5,5]</span></span><br><span class="line"><span class="comment"># l = [2,2,3,4,5,5]</span></span><br><span class="line">LN = ListNode(l[<span class="number">0</span>])</span><br><span class="line"><span class="comment"># for i in range(1,len(l)):</span></span><br><span class="line"><span class="comment">#     LN.next</span></span><br><span class="line">node_list = list(map(ListNode,l))</span><br><span class="line"><span class="comment"># print(node_list[0])</span></span><br><span class="line"><span class="comment"># print(ListNode(l[0]))</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(node_list)<span class="number">-1</span>):</span><br><span class="line">    node_list[i].next = node_list[i+<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">h = s.deleteDuplicates(node_list[<span class="number">0</span>])</span><br><span class="line"><span class="keyword">while</span> h!= <span class="keyword">None</span>:</span><br><span class="line">    print(h.val)</span><br><span class="line">    h = h.next</span><br></pre></td></tr></table></figure><p>This version uses three pointer to do the same thing. From leetcode.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ListNode</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        self.val = x</span><br><span class="line">        self.next = <span class="keyword">None</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">deleteDuplicates</span><span class="params">(self, head)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        :type head: ListNode</span></span><br><span class="line"><span class="string">        :rtype: ListNode</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> head <span class="keyword">or</span> <span class="keyword">not</span> head.next:</span><br><span class="line">            <span class="keyword">return</span> head</span><br><span class="line">        fakehead = ListNode(<span class="number">0</span>)</span><br><span class="line">        fakehead.next = head</span><br><span class="line">        prev = fakehead</span><br><span class="line">        slow = head</span><br><span class="line">        fast = head.next</span><br><span class="line">        <span class="keyword">while</span> fast:</span><br><span class="line">            <span class="keyword">if</span> fast.val == slow.val:</span><br><span class="line">                <span class="keyword">while</span> fast <span class="keyword">and</span> fast.val == slow.val:</span><br><span class="line">                    fast = fast.next</span><br><span class="line">                slow = prev</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                prev = slow</span><br><span class="line">                slow = slow.next</span><br><span class="line">                slow.val = fast.val</span><br><span class="line">                fast = fast.next</span><br><span class="line">        slow.next = <span class="keyword">None</span></span><br><span class="line">        <span class="keyword">return</span> fakehead.next</span><br></pre></td></tr></table></figure>]]></content>
      
      
        <tags>
            
            <tag> Algorithm </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Sentence_Similarity</title>
      <link href="/2018/05/27/Sentence-Similarity/"/>
      <url>/2018/05/27/Sentence-Similarity/</url>
      <content type="html"><![CDATA[<h2 id="NLP-typical-Step"><a href="#NLP-typical-Step" class="headerlink" title="NLP typical Step:"></a>NLP typical Step:</h2><p>Tokenize: separate the words in the sentence</p><p>Convert the sentence to vector: the sentence has been divided into several words, and load word2vec model and convert each word to a vector</p><h2 id="Similarity-Measurement"><a href="#Similarity-Measurement" class="headerlink" title="Similarity Measurement"></a>Similarity Measurement</h2><p>TF-IDF model: convert the sentence to a vector of words, use cosine similarity to measure. In this applicatoin, not very good.</p><p>Bag of words:</p><p>Modern way: NLP step as above. Use pre-train word vectors to represent a sentence. Compute distance. Huge amount of computation. In this application, extract several keywords first as heuristic to rule out a lot of sentences and then start using this method to reduce computation amount. The best accuracy in this application. Change pre-train vectors and brute-force computation would increase the accuracy.</p><h2 id="Some-Notes"><a href="#Some-Notes" class="headerlink" title="Some Notes"></a>Some Notes</h2><p>Tokenize: separate the words in the sentence </p><p>Bag of words: just count the frequency of words that appear in the sentence and neglect the sequence of words</p><p>Word representation: one-hot representation<br>Not easy to extract connection because dot product between any two words are 0</p><p>Featurized representation: word embedding. Using a matrix to represent values of features, and stand for a word. It could be understood as a word embedded in a high dimensional space </p><p>Analogy of word embedding. Use cosine similarity to measure whether two words are similar. Take the dot product of two words vectors and divide multiplication of their lengths.</p><p>Embedding matrix: num of features * number of words. Each column is a feature vector. Use one-hot vector to multiply embedding matrix get the corresponding feature vector</p><p>Word2vec:<br>Skip-gram: randomly choose a context word and corresponding target word. Target word is in the window(like 5 words before or after the context word) of context word<br>Target is to learn good word embedding rather than perform good supervised learning<br>How to sample context word? Employ some techniques to avoid commonly appeared word like the ,a and so on</p><p>Negative sampling: one positive sample and k randomly chosen negative sample to simplify computation </p><p>Content of word d: means the range of plus or minus 5 words</p><p>Sequence to sequence:<br>Machine translation: input sentence to encoder, and output is a decoder. Conditional language model. Green part is encoder, purple is decoder</p><p>Beam search: a kind of approximate optimization algorithm<br>beam width n: track The most possible n sequences with the highest probability. Larger n, the algorithm runs better but need more memory. Smaller n: more efficient, less accurate<br>unlike BFS and DFS, beam search do not guarantee to find the best solution. It’s not complete because it only track a few states.<br>Start by choosing the first word for n sentences, and then second…….</p><p>Maximize this probability to find the most possible sequence<br>Multiplication of several values that are less than one leads to numerical problem. Take Log on it solve this problem.</p><p>Error analysis: working to optimize some sort of cost function/objective function that is output by a learning algorithm like RNN<br>RNN output the p(y|x) for sentences and beam search choose argmaxP(y|x). if RNN output the correct probability but beam search choose the wrong one, beam is at fault. And vise versa, if RNN output the wrong probability for sentences, RNN is at fault. Correct probability means P(correct sentence | x) &gt; P(wrong sentence | x)<br>Compare beam search with RNN, find which one is at fault. And then modify and improve it.</p><p>Attention model:<br>Just focus on a few words around rather than the whole sentence to translate. Divide and conquer, get better result.</p><p>Speech recognition:<br>Turn time domain signal to frequency domain signal<br>Usually input is much larger than output</p><p>CTC cost:<br>Basic idea: collapse repeated characters not separated by “blank”</p><h3 id="Normalization"><a href="#Normalization" class="headerlink" title="Normalization"></a>Normalization</h3><p>puts pieces of information in a standard format, so that they can be compared to other pieces of information. </p><p>An example of nor- malization is formatting dates and times in a stan- dard way, so that “12pm”, “noon” and “12.00h” all map to the same representation.</p><h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p><a href="https://web.stanford.edu/~jurafsky/slp3/" target="_blank" rel="noopener">Speech and Language Processing</a></p>]]></content>
      
      
        <tags>
            
            <tag> NLP </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>String_Matching</title>
      <link href="/2018/05/25/String-Matching/"/>
      <url>/2018/05/25/String-Matching/</url>
      <content type="html"><![CDATA[<p>##String Matching:</p><p>###The Rabin-Karp algorithm<br>Intuition:<br>Use the values of strings as heuristic, if they are equal, they matches, else they don’t. Because the string may be very long to do the computation efficiently, we induce mod so as to reduce the computation complexity dramatically. </p><p>In general, with a d-ary alphabet {0,1,2… d-1}, we choose q so that d*q fits within a computer word.<br>d is the length of the alphabet set.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'''please input pattern and string'''</span></span><br><span class="line">p = input()</span><br><span class="line">s = input()</span><br><span class="line">d = int(input())</span><br><span class="line">q = int(input())</span><br><span class="line">l_p = len(p)</span><br><span class="line">h = d**(l_p<span class="number">-1</span>) % q</span><br><span class="line"><span class="string">'''Preprocessing'''</span></span><br><span class="line">p_sum, s_sum = <span class="number">0</span>,<span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,l_p):</span><br><span class="line">    p_sum = (d*p_sum + int(p[i])) %q</span><br><span class="line">    s_sum = (d * s_sum + int(s[i])) %q</span><br><span class="line">    <span class="comment"># p_sum = (p_sum+(d*p_sum + int(p[i]))) % q</span></span><br><span class="line">    <span class="comment"># s_sum = (s_sum+(d * s_sum + int(s[i]))) % q</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">0</span>,len(s)-l_p+<span class="number">1</span>):</span><br><span class="line">    <span class="keyword">if</span> p_sum == s_sum:</span><br><span class="line">        <span class="keyword">if</span> s[j:j+l_p] == p:</span><br><span class="line">            print(s[j:j+l_p])</span><br><span class="line">    <span class="keyword">if</span> j &lt; len(s)-l_p:</span><br><span class="line">        s_sum = (d*(s_sum-int(s[j])*h) + int(s[j+l_p])) % q</span><br></pre></td></tr></table></figure><p>Worst case: the string and pattern have all same character. O((n-m+1)*m)<br>Best case: O(n) + O(m(v+n/q))</p><p>###KMP algorithm</p><p>Each time the given string match with the pattern, by utilizing the information contains in the pattern string, the algorithm may skip several matching without affecting the correctness. Let’s assume current position of the string is s. Length of matched string is q. There may exists a k&lt;q(if k &gt; q, we don’t know what’s them outside the pattern window) such that P[1…k] = T[s’+1…s’+k]. s’ is the new position of pointer. K is the length that the substring T[s’] starting from s’ matches with P[1..k].<br>So s’ = s+q-k</p><p>Preprocessing:<br>Find the longest prefix of the matched string such that it is also the suffix of the matched string.</p><p>Time complexity: O(n)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_prefix</span><span class="params">(p)</span>:</span></span><br><span class="line">    l = [<span class="number">0</span>] * len(p)</span><br><span class="line">    k = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,len(p)):</span><br><span class="line">        <span class="string">'''#This line decrease k. because 0 &lt; k &lt; i, the total time that i has been increased &lt; len(p),</span></span><br><span class="line"><span class="string">        so the total time that while loop execute would &lt; len(p)'''</span></span><br><span class="line">        <span class="keyword">while</span> k&gt;<span class="number">0</span> <span class="keyword">and</span> p[i] != p[k]:</span><br><span class="line">            k = l[k]</span><br><span class="line">        <span class="keyword">if</span> p[i] == p[k]:</span><br><span class="line">            k += <span class="number">1</span>                          <span class="comment"># this increase k</span></span><br><span class="line">        l[i] = k</span><br><span class="line">    <span class="keyword">return</span> l</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">KMP_Match</span><span class="params">(s,p)</span>:</span></span><br><span class="line">    l = compute_prefix(p)</span><br><span class="line">    <span class="comment"># print(l)</span></span><br><span class="line">    q = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,len(s)):</span><br><span class="line">        <span class="keyword">while</span> q &gt; <span class="number">0</span> <span class="keyword">and</span> p[q] != s[i]:</span><br><span class="line">            q = l[q]</span><br><span class="line">        <span class="keyword">if</span> p[q] == s[i]:</span><br><span class="line">            q += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> q == len(p):</span><br><span class="line">            print(s[i-q+<span class="number">1</span>:i+<span class="number">1</span>])</span><br><span class="line">            q = l[q<span class="number">-1</span>]</span><br></pre></td></tr></table></figure>]]></content>
      
      
        <tags>
            
            <tag> Algorithm </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Recommendation_System</title>
      <link href="/2018/05/24/Recommendation-System/"/>
      <url>/2018/05/24/Recommendation-System/</url>
      <content type="html"><![CDATA[<p>Advertisement recommendation is important! It is a significant source of income for many companies. Abuse of advertisement would annoy user. How to choose potential interested user is a challenging problem.</p><p>Our application is an advertisement recommending system, which simulates the process of recommend advertisements to users who may need them. Different people have different appetites, this works same on advertisements.</p><p><img src="../alitaobaoV3/Slide13.jpeg" alt="" title="System Design"></p><table><thead><tr><th>Packages</th><th style="text-align:center">Descriptions</th></tr></thead><tbody><tr><td>Xen 4.4.1</td><td style="text-align:center">Hypervisor for virtual machines</td></tr><tr><td>Hadoop 2.6.0</td><td style="text-align:center">open-source software framework for storage and large scale processing of data_sets on clusters of commodity hardware.</td></tr><tr><td>Spark 2.1.0</td><td style="text-align:center">A fast and general engine for large-scala data processing</td></tr><tr><td>Spark MLlib</td><td style="text-align:center">An apache Spark’s scalable machine learning library.</td></tr><tr><td>Hive</td><td style="text-align:center">A data warehouse software facilitates reading, writing, and managing large datasets residing in distributed storage using SQL. Structure can be projected onto data already in storage</td></tr><tr><td>SparkSql</td><td style="text-align:center">An Apache Spark’s module for working with structured data</td></tr><tr><td>Tomcat 8.5.29</td><td style="text-align:center">Web server</td></tr></tbody></table><h4 id="Key-Algorithms"><a href="#Key-Algorithms" class="headerlink" title="Key Algorithms"></a>Key Algorithms</h4><ul><li>Collaborative Filtering</li><li>Metric Learning</li><li>K-means</li></ul><h4 id="Key-Features"><a href="#Key-Features" class="headerlink" title="Key Features"></a>Key Features</h4><ul><li>K-means clustering with Mahalanobis Distance</li><li>SQL to form a utility matrix according to user behavior</li><li>Employ clustering to estimate empty entries in the matrix</li><li>Recommend to user who have bought similar items</li></ul><h4 id="Xen-Configuration"><a href="#Xen-Configuration" class="headerlink" title="Xen Configuration"></a>Xen Configuration</h4><ul><li>Pin CPUs to virtual machines</li><li>Migrate some memory to virtual machines to optimize performance</li></ul><h4 id="Optimization-of-Performance"><a href="#Optimization-of-Performance" class="headerlink" title="Optimization of Performance"></a>Optimization of Performance</h4><p>Small dataset is employed to optimize parameters.</p><table><thead><tr><th>Parameters</th><th style="text-align:center">Running Time</th></tr></thead><tbody><tr><td>Num-execution  5—-7</td><td style="text-align:center">3 mins 45 sec -&gt; 3 mins 13 sec</td></tr><tr><td>Parallelism          8—-16</td><td style="text-align:center">3 mins 13 sec -&gt; 1 min 38 sec</td></tr><tr><td>Executor memory 1000m-2000m</td><td style="text-align:center">3 mins 22 sec -&gt; 2 mins 54 sec</td></tr></tbody></table><h4 id="Novelty"><a href="#Novelty" class="headerlink" title="Novelty"></a>Novelty</h4><ul><li>In clustering, the distance functionis Mahalanobis Distance rather than euclidean distance.</li><li>Traditional collaborative filtering utilizes rows and columns of utility matrix to estimate similarity of items and users as well as empty entries in the utility matrix.In our algorithm, we use clustering to estimate the empty entries.</li></ul><h3 id="Algorithm-Introduction"><a href="#Algorithm-Introduction" class="headerlink" title="Algorithm Introduction"></a>Algorithm Introduction</h3><h4 id="Clustering"><a href="#Clustering" class="headerlink" title="Clustering"></a>Clustering</h4><p>Two kinds of clustering: hierarchica and point assignment.</p><p>Hierarchical:<br>Merge clusters. Each unassigned point is a cluster.<br>The measurements are diameter, radius, average distance, minimum distance.<br>Radius: the maximum distance from any points to centroid.<br>Diameter: maximum distance between any two points.</p><p>Point assignment: Assign each point to the nearest cluster.</p><p>K-means++:<br>initialize several points which are as far away as possible from each other as centroid of clusters.<br>Assign the points to these different clusters and recompute the centroids.</p><p><strong>Complexity</strong>:O(n <em> K </em> I * d )<br>n = number of records, K = number of clusters,I = number of iterations, d = number of attributes</p><h4 id="Recommendation-System"><a href="#Recommendation-System" class="headerlink" title="Recommendation System"></a>Recommendation System</h4><p>The ultimate goal of a recommendation system is to estimate those empty entries in the utility matrix.</p><p>To estimate empty entry, one possible way is to find n similar users and count their normalized ratings. Another possible way is to find the rating of similar items given by the same user.</p><p><strong>Methods</strong>:</p><ul><li><p>Collaborative filtering: use columns and rows of utility matrix to identify similar items or users and then do recommendation</p></li><li><p>Content based:<br>Utility matrix: ranked item is 1(Boolean) or actual rating(numerical) * normalizing factor. Others are represented by 0 or blank. </p></li><li><p>Association Analysis.</p></li></ul><h5 id="Characteristics-of-different-methords"><a href="#Characteristics-of-different-methords" class="headerlink" title="Characteristics of different methords"></a>Characteristics of different methords</h5><p>User-based: tailer-made, accurate. Not easy to measure similarity.<br>Content-based: Reliable, wider-range of recommendation. Construction of item profiles are tedious.</p><h2 id="Notes"><a href="#Notes" class="headerlink" title="Notes"></a>Notes</h2><h5 id="Below-are-just-notes-of-this-project-feel-free-to-skip-it"><a href="#Below-are-just-notes-of-this-project-feel-free-to-skip-it" class="headerlink" title="Below are just notes of this project, feel free to skip it."></a>Below are just notes of this project, feel free to skip it.</h5><p>Item features could also be represented by tags. But it is tedious to get tags data.</p><p>Content-based recommendation is to create both an item profile consisting of feature-value pairs and a user profile summarizing the preferences of the user, based of their row of the utility matrix. </p><p>Discretize numerical data to nominal data would lose the structure implicit in numbers. That is, two ratings that are close but not identical should be considered more similar than widely differing ratings. </p><p>There is no harm if some components of the vectors are Boolean and others are real-valued or integer-valued. But it is necessary to somehow normalize the data so that the scale would not affect the result too much.</p><p>Machine learning technique: ML algorithm to predict the empty entries in the utility matrix. Training set is the data. Optimize the loss. i.e. classification algorithm: build a decision tree to classify the data as like or don’t like for a particular user group.</p><p>Recommendation System:<br>Our recommendation system employs a modified version of collaborative filtering. In traditional recommendation system, in order to avoid constructing user and item profile which is a tedious and tricky step, rows and columns of utility matrix are utilized to estimate similarity of item and user as well as empty entries in the utility matrix.</p><p>a utility matrix, giving for each user-item pair, a value that represents what is known about the degree of preference of that user for that item. Values come from an ordered set. We assume that the matrix is sparse, meaning that most entries are “unknown.” An unknown rating implies that we have no explicit information about the user’s preference for the item. </p><p>Target of recommendation system:<br>It is not necessary to predict every blank entry in a utility matrix. Rather, it is only necessary to discover some entries in each row that are likely to be high. In most applications, the recommendation system does not offer users a ranking of all items, but rather suggests a few that the user should value highly. It may not even be necessary to find all items with the highest expected ratings, but only to find a large subset of those with the highest ratings. </p><p>User Profile: aggregation of utility matrix which represent connection between users and items.</p><p>After getting user profile, make recommendation according to proximity between unseen object and content in user profile. (cosine similarity)</p><p>The process of identifying similar users and recommending what similar users like is called collaborative filtering.<br>Cosine distance treat empty entries as 0.<br>Preprocessing:</p><ul><li>Round the data: round ratings to 0 or 1.</li><li>Normalize the data and apply proximity measure.</li></ul><p>Measuring similarity:<br>Jaccard distance: may emit important information like the scale of rating.<br>Cosine distance</p><p>The Duality of Similarity </p><p>To estimate an entry, for item-based, find the most similar m items, and average them to get an estimate of rating for the entry(item).</p><p>After cluster, get the entry for that item clusters by averaging the item</p><p>Since there is user and ad profile, try to do clustering first.</p><p>Data is large, initialize small cluster first to summarize the data points.</p><p>Curse of dimensionality: in high dimension, cosine similarity approaches to 0, which means that random vectors are orthogonal. Distance and density become meaningless because distance is very far away compared to low dimensionality.</p><p>Clustering:<br>Euclidean space in which the cluster could be represented by a center.<br>Clustroid: the closest point to other points in the cluster<br>Centroid: the arithmetic center point calculated.</p><p>Mahalanobis distance is distance between x and y divided by square root of covariance, which is undistorting the ellipse to make a circle</p><h3 id="Extention"><a href="#Extention" class="headerlink" title="Extention"></a>Extention</h3><p>Word2Vec to do recomendation: sequence of actions of a user in a specific time range(within 30 minutes) is regarded as a context like the context words in word2vec. The search /query/clicked item is the center. As what has been done in word2vec, train the model s.t. the center item is close to context item and far away than other items.</p><p>The learnt embeddings have been shown to correctly encode information like style,price and so on.</p><h5 id="The-Airbnb-makes-some-other-modification"><a href="#The-Airbnb-makes-some-other-modification" class="headerlink" title="The Airbnb makes some other modification:"></a>The Airbnb makes some other modification:</h5><ul><li>The final booking item is added s.t. the objective is to make the center item close to final booking item too.</li><li>Sample items from the same location but different style or other condition as negative samples.</li></ul><h4 id="Clustering-1"><a href="#Clustering-1" class="headerlink" title="Clustering"></a>Clustering</h4><p>Clustering is employed to promote diversity of recommendation. After the vectors of products are learnt, they are clustered together. If a customer buy something in a cluster, the system would choose items in another cluster in which other or similar users usually buy items after buying items in the same cluster. This avoid the problem of recommending the similar item with the same function to users. After choosing the cluster, recommend the top k items that are similar to the purchased item.</p><h4 id="Cold-Start-Problem"><a href="#Cold-Start-Problem" class="headerlink" title="Cold Start Problem"></a>Cold Start Problem</h4><p>Average 3 geographically closest listings accoding to location or age or something like that.</p><h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p><a href="http://mccormickml.com/2018/06/15/applying-word2vec-to-recommenders-and-advertising/" target="_blank" rel="noopener">Applying word2vec to Recommenders and Advertising</a></p><p><a href="https://medium.com/airbnb-engineering/listing-embeddings-for-similar-listing-recommendations-and-real-time-personalization-in-search-601172f7603e" target="_blank" rel="noopener">Listing Embeddings in Search Ranking</a></p>]]></content>
      
      
        <tags>
            
            <tag> Project </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>Maximum_Subarray</title>
      <link href="/2018/05/24/Maximum-Subarray/"/>
      <url>/2018/05/24/Maximum-Subarray/</url>
      <content type="html"><![CDATA[<h3 id="Dynamic-Programming"><a href="#Dynamic-Programming" class="headerlink" title="Dynamic Programming"></a>Dynamic Programming</h3><p>Time Complexity: O(n)</p><p>Store the first value. Traverse the array. If the last value of maximum subarray l is greater than 0, add the current value to it and store it. Else store it directly. Because if the last value of maximum subarray l is less than 0, no need to add the current value to it. If the last value of maximum subarray l is greater than 0, add the current value to it. Next time we check it, if it greater than 0, we add next value to it, else we discard it because it could not be the maximum subarray.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def maxSubArray(self, nums):</span><br><span class="line">        <span class="string">""</span><span class="string">"</span></span><br><span class="line"><span class="string">        :type nums: List[int]</span></span><br><span class="line"><span class="string">        :type k: int</span></span><br><span class="line"><span class="string">        :rtype: float</span></span><br><span class="line"><span class="string">        "</span><span class="string">""</span></span><br><span class="line">        <span class="keyword">if</span> len(nums) == 1:</span><br><span class="line">            <span class="built_in">return</span> nums[0]</span><br><span class="line">        l = [nums[0]]</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(1,len(nums)):</span><br><span class="line">            <span class="comment"># if nums[i] &lt;0:</span></span><br><span class="line">            <span class="keyword">if</span> l[i-1] &gt;0:</span><br><span class="line">                l.append(nums[i] + l[i-1])</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                l.append(nums[i])</span><br><span class="line">        <span class="built_in">return</span> max(l)</span><br><span class="line">            <span class="comment"># else:</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">s = Solution()</span><br><span class="line"><span class="comment"># leg = s.maxSubArray([-1,2,3,-6,8])</span></span><br><span class="line">leg = s.maxSubArray([-2,1,-3,4,-1,2,1,-5,4])</span><br><span class="line"><span class="comment"># leg = s.max_cross([-2,1,-3,4,-1,2,1,-5,4])</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(leg)</span><br></pre></td></tr></table></figure><h3 id="divide-and-conquer"><a href="#divide-and-conquer" class="headerlink" title="divide and conquer"></a>divide and conquer</h3><p>recursively divide a problem into subproblems.<br>Time complexity: O(nlogn)<br>logn: Each time divide the problem into two parts, so an array of size N could construct a log2N levels tree. Each level needs at most N time to solve.</p><h4 id="Reference-Introduction-to-Algorithm-Cha-4-1"><a href="#Reference-Introduction-to-Algorithm-Cha-4-1" class="headerlink" title="Reference: Introduction to Algorithm Cha 4.1"></a>Reference: Introduction to Algorithm Cha 4.1</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">class Solution:</span><br><span class="line">    def maxSubArray(self, nums):</span><br><span class="line">        <span class="string">""</span><span class="string">"</span></span><br><span class="line"><span class="string">        :type nums: List[int]</span></span><br><span class="line"><span class="string">        :type k: int</span></span><br><span class="line"><span class="string">        :rtype: float</span></span><br><span class="line"><span class="string">        "</span><span class="string">""</span></span><br><span class="line">        left = 0</span><br><span class="line">        right = len(nums)-1     <span class="comment">#index of the last item</span></span><br><span class="line">        <span class="comment"># if right == 0:</span></span><br><span class="line">        <span class="comment">#     return None</span></span><br><span class="line">        <span class="keyword">if</span> right == left:     <span class="comment">#only one element</span></span><br><span class="line">            <span class="built_in">return</span> nums[0]</span><br><span class="line">        mid = int(len(nums) / 2)</span><br><span class="line">        <span class="comment"># print("mid",mid, left, right)</span></span><br><span class="line">        <span class="comment"># print(self.max_cross(nums),</span></span><br><span class="line">        <span class="comment">#       self.maxSubArray(nums[left:mid]), self.maxSubArray(nums[mid:right]),)</span></span><br><span class="line">        m = self.max_cross(nums)</span><br><span class="line">        l = self.maxSubArray(nums[left:mid])</span><br><span class="line">        r = self.maxSubArray(nums[mid:right+1])</span><br><span class="line">        <span class="built_in">return</span> max(m,l,r)</span><br><span class="line">        <span class="comment"># return r</span></span><br><span class="line"></span><br><span class="line">    def max_cross(self, nums):</span><br><span class="line">        mid = int(len(nums)/2)</span><br><span class="line">        left = 0</span><br><span class="line">        right = len(nums)-1</span><br><span class="line">        left_sum_max, right_sum_max = <span class="built_in">float</span>(<span class="string">"-inf"</span>), <span class="built_in">float</span>(<span class="string">"-inf"</span>)</span><br><span class="line">        left_sum, right_sum = 0,0</span><br><span class="line">        left_index, right_index = -1,-1</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(mid-1,left-1,-1):</span><br><span class="line">            left_sum += nums[i]</span><br><span class="line">            <span class="keyword">if</span> left_sum&gt;left_sum_max:</span><br><span class="line">                left_index = i</span><br><span class="line">                left_sum_max = left_sum</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(mid,right+1):</span><br><span class="line">            right_sum += nums[i]</span><br><span class="line">            <span class="keyword">if</span> right_sum&gt;right_sum_max:</span><br><span class="line">                right_index = i</span><br><span class="line">                right_sum_max = right_sum</span><br><span class="line">        <span class="built_in">return</span> left_sum_max+right_sum_max</span><br></pre></td></tr></table></figure>]]></content>
      
      
        <tags>
            
            <tag> Algorithm </tag>
            
        </tags>
      
    </entry>
    
  
  
</search>
